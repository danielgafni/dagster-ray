{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to dagster-ray","text":"<p>Ray integration for Dagster - Orchestrate distributed Ray compute from Dagster pipelines with seamless integration between Dagster's orchestration capabilities and Ray's distributed computing power.</p> <p> </p> <p>Info</p> <p>This project is ready for production use, but some APIs may change between minor releases.</p>"},{"location":"#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>\ud83c\udfaf Run Launchers &amp; Executors: Submit Dagster runs or individual steps as Ray jobs</li> <li>\ud83d\udd27 Ray Resources: Connect to Ray cluster in client mode and manage their lifecycle</li> <li>\ud83d\udce1 Dagster Pipes Integration: Execute external Ray scripts with rich logging and metadata</li> <li>\u2638\ufe0f KubeRay Support: Utilize <code>RayJob</code> and <code>RayCluster</code> custom resources in client or job mode (tutorial)</li> <li>\ud83c\udfed Production Ready: Tested against a matrix of core dependencies, integrated with Dagster+</li> </ul>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"BasicWith KubeRay <pre><code>pip install dagster-ray\n</code></pre> <pre><code>pip install 'dagster-ray[kuberay]'\n</code></pre> <p>Example</p> <pre><code>import dagster as dg\nfrom dagster_ray import LocalRay, RayResource, KubeRayInteractiveJob\nimport ray\n\n\n@ray.remote\ndef compute_square(x: int) -&gt; int:\n    return x**2\n\n\n@dg.asset\ndef my_distributed_computation(ray_cluster: RayResource) -&gt; int:  # (2)!\n    futures = [compute_square.remote(i) for i in range(10)]  # (1)!\n    return sum(ray.get(futures))\n\n\nray_cluster = LocalRay() if not IN_KUBERNETES else KubeRayInteractiveJob()\n\ndefinitions = dg.Definitions(\n    assets=[my_distributed_computation],\n    resources={\"ray_cluster\": ray_cluster},\n)\n</code></pre> <ol> <li> I am already running in Ray!</li> <li> <code>RayResource</code> is a type annotation that provides a common interface for Ray resources</li> </ol>"},{"location":"#choosing-your-integration","title":"\ud83d\udee0\ufe0f Choosing Your Integration","text":"<p><code>dagster-ray</code> offers multiple ways to integrate Ray with your Dagster pipelines. The right choice depends on your deployment setup and use case:</p>"},{"location":"#key-questions-to-consider","title":"\ud83e\udd14 Key Questions to Consider","text":"<ul> <li>Do you want to manage Ray clusters automatically? If yes, use KubeRay components</li> <li>Do you prefer to submit external scripts or run code directly? External scripts offer better separation of concerns and environments, but interactive code is more convenient</li> <li>Do you need per-asset configuration? Some components allow fine-grained control per asset</li> </ul>"},{"location":"#feature-comparison","title":"\ud83d\udcca Feature Comparison","text":"Feature <code>RayRunLauncher</code> <code>ray_executor</code> <code>PipesRayJobClient</code> <code>PipesKubeRayJobClient</code> <code>KubeRayCluster</code> <code>KubeRayInteractiveJob</code> Manages the cluster \u274c \u274c \u274c \u2705 \u2705 \u2705 Uses Ray Jobs API \u2705 \u2705 \u2705 \u2705 \u274c \u274c Enabled per-asset \u274c \u274c \u2705 \u2705 \u2705 \u2705 Configurable per-asset \u274c \u2705 \u2705 \u2705 \u2705 \u2705 No external script needed \u2705 \u2705 \u274c \u274c \u2705 \u2705 No Dagster DB access needed \u274c \u274c \u2705 \u2705 \u2705 \u2705"},{"location":"#which-one-should-you-use","title":"\ud83c\udfaf Which One Should You Use?","text":"\ud83c\udfe2 External Ray Cluster\u2638\ufe0f Dagster-owned Ray Cluster (KubeRay) <p>You have a Ray cluster already running</p> <ul> <li>Use <code>RayRunLauncher</code> to run the entire Dagster deployment on Ray</li> <li>Use <code>ray_executor</code> to run specific jobs on Ray</li> <li>Use <code>PipesRayJobClient</code> to submit external Python scripts as Ray jobs</li> </ul> <p>Tip</p> <p>See external cluster tutorial</p> <p>You want <code>dagster-ray</code> to handle cluster lifecycle</p> <p><code>dagster-ray</code> supports running Ray on Kubernetes with KubeRay.</p> <ul> <li>Use <code>KubeRayInteractiveJob</code> to create a <code>RayJob</code> and connect in client mode</li> <li>Use <code>PipesKubeRayJobClient</code> to submit external scripts as <code>RayJob</code></li> </ul> <p>Tip</p> <p>See KubeRay tutorial</p>"},{"location":"#whats-next","title":"\ud83d\udcda What's Next?","text":"<ul> <li> <p> Tutorial</p> <p>Step-by-step guide with practical examples to get you started with <code>dagster-ray</code></p> </li> <li> <p> API Reference</p> <p>Complete documentation of all classes, methods, and configuration options</p> </li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for <code>dagster-ray</code> components, organized by functionality. Learn how to use <code>dagster-ray</code> here.</p>"},{"location":"api/#key-components","title":"Key Components","text":""},{"location":"api/#core-api","title":"Core API","text":"<ul> <li>RayRunLauncher</li> <li>ray_executor</li> <li>PipesRayJobClient</li> </ul>"},{"location":"api/#kuberay-api","title":"KubeRay API","text":"<ul> <li>KubeRayInteractiveJob</li> <li>PipesKubeRayJobClient</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable user-facing changes to <code>dagster-ray</code> will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#021","title":"0.2.1","text":""},{"location":"changelog/#fixes","title":"Fixes","text":"<ul> <li>Fixed broken wheel on PyPI</li> </ul>"},{"location":"changelog/#020","title":"0.2.0","text":""},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li><code>KubeRayInteractiveJob.deletion_strategy</code> now defaults to <code>DeleteCluster</code> for both successful and failed executions. This is a reasonable default for the use case.</li> <li><code>KubeRayInteractiveJob.ttl_seconds_after_finished</code> now defaults to <code>600</code> seconds.</li> <li><code>KubeRayCluster.lifecycle.cleanup</code> now defaults to <code>always</code></li> <li>[ breaking] <code>RayJob</code> and <code>RayCluster</code> clients and resources Kubernetes init parameters have been renamed to <code>kube_config</code> and <code>kube_context</code>.</li> </ul>"},{"location":"changelog/#added","title":"Added","text":"<ul> <li>new <code>enable_legacy_debugger</code> configuration parameter to subclasses of <code>RayResource</code></li> <li>new <code>on_exception</code> option for <code>lifecycle.cleanup</code> policy. It's triggered during resource setup/cleanup (including <code>KeyboardInterrupt</code>), but not by user <code>@op</code>/<code>@asset</code> code.</li> <li><code>KubeRayInteractiveJob</code> now respects <code>lifecycle.cleanup</code>. It defaults to <code>on_exception</code>. Users are advised to rely on built-in <code>RayJob</code> cleanup mechanisms, such as <code>ttlSecondsAfterFinished</code> and <code>deletionStrategy</code>.</li> </ul>"},{"location":"changelog/#fixes_1","title":"Fixes","text":"<ul> <li>removed <code>ignore_reinit_error</code> from <code>RayResource</code> init options: it's potentially dangerous, for example in case the user has accidentally connected to another Ray cluster (including local ray) before initializing the resource.</li> </ul>"},{"location":"changelog/#010","title":"0.1.0","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li>[ breaking] <code>RayResource</code>: top-level <code>skip_init</code> and <code>skip_setup</code> configuration parameters have been removed. The <code>lifecycle</code> field is the new way of configuring steps performed during resource initialization. <code>KubeRayCluster</code>'s <code>skip_cleanup</code> has been moved to <code>lifecycle</code> as well.</li> <li>[ breaking] injected <code>dagster.io/run_id</code> Kubernetes label has been renamed to <code>dagster/run-id</code>. Keys starting with <code>dagster.io/</code> have been converted to <code>dagster/</code> to match how <code>dagster-k8s</code> does it.</li> <li>[ breaking] <code>dagster_ray.kuberay</code> Configurations have been unified with KubeRay APIs.</li> <li><code>dagster-ray</code> now populates Kubernetes labels with more values (including some useful Dagster Cloud values such as <code>git-sha</code>)</li> </ul>"},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li><code>KubeRayInteractiveJob</code> -- a new resource that utililizes the new <code>InteractiveMode</code> for <code>RayJob</code>. It can be used to connect to Ray in Client mode -- like <code>KubeRayCluster</code> -- but gives access to <code>RayJob</code> features, such as automatic cleanup (<code>ttlSecondsAfterFinished</code>), retries (<code>backoffLimit</code>) and timeouts (<code>activeDeadlineSeconds</code>).</li> <li><code>RayResource</code> setup lifecycle has been overhauled: resources now has an <code>actions</code> parameter with 3 configuration options: <code>create</code>, <code>wait</code> and <code>connect</code>. The user can disable them and run <code>.create()</code>, <code>.wait()</code> and <code>.connect()</code> manually if needed.</li> </ul>"},{"location":"api/core/","title":"Core API Reference","text":"<p>Core <code>dagster-ray</code> APIs for using external Ray clusters. Learn how to use it here.</p>"},{"location":"api/core/#misc","title":"Misc","text":""},{"location":"api/core/#dagster_ray.resources.LocalRay","title":"LocalRay  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseRayResource</code></p> <p>Dummy Resource. Is useful for testing and local development. Provides the same interface as actual Resources.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Dummy Resource.\\nIs useful for testing and local development.\\nProvides the same interface as actual Resources.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"LocalRay\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.resources.LocalRay-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.resources.LocalRay.host","title":"host  <code>property</code>","text":"<pre><code>host: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.LocalRay.ray_address","title":"ray_address  <code>property</code>","text":"<pre><code>ray_address: None\n</code></pre>"},{"location":"api/core/#run-launcher","title":"Run Launcher","text":""},{"location":"api/core/#dagster_ray.run_launcher.RayRunLauncher","title":"RayRunLauncher","text":"<pre><code>RayRunLauncher(\n    address: str,\n    metadata: dict[str, Any] | None = None,\n    headers: dict[str, Any] | None = None,\n    cookies: dict[str, Any] | None = None,\n    env_vars: list[str] | None = None,\n    runtime_env: dict[str, Any] | None = None,\n    num_cpus: int | None = None,\n    num_gpus: int | None = None,\n    memory: int | None = None,\n    resources: dict[str, float] | None = None,\n    inst_data: ConfigurableClassData | None = None,\n)\n</code></pre> <p>               Bases: <code>RunLauncher</code>, <code>ConfigurableClass</code></p> <p>RunLauncher that submits Dagster runs as isolated Ray jobs to a Ray cluster.</p> <p>Configuration can be provided via <code>dagster.yaml</code> and individual runs can override settings using the <code>dagster-ray/config</code> tag.</p> Example <p>Configure via <code>dagster.yaml</code> <pre><code>run_launcher:\n  module: dagster_ray\n  class: RayRunLauncher\n  config:\n    address: \"ray://head-node:10001\"\n    num_cpus: 2\n    num_gpus: 0\n</code></pre></p> Example <p>Override settings per job <pre><code>import dagster as dg\n\n@dg.job(\n    tags={\n        \"dagster-ray/config\": {\n            \"num_cpus\": 16,\n            \"num_gpus\": 1,\n            \"runtime_env\": {\"pip\": {\"packages\": [\"torch\"]}},\n        }\n    }\n)\ndef my_job():\n    return my_op()\n</code></pre></p> Source code in <code>src/dagster_ray/run_launcher.py</code> <pre><code>def __init__(\n    self,\n    address: str,\n    metadata: dict[str, Any] | None = None,\n    headers: dict[str, Any] | None = None,\n    cookies: dict[str, Any] | None = None,\n    env_vars: list[str] | None = None,\n    runtime_env: dict[str, Any] | None = None,\n    num_cpus: int | None = None,\n    num_gpus: int | None = None,\n    memory: int | None = None,\n    resources: dict[str, float] | None = None,\n    inst_data: ConfigurableClassData | None = None,\n):\n    self._inst_data = dg._check.opt_inst_param(inst_data, \"inst_data\", ConfigurableClassData)\n\n    self.address = address\n    self.metadata = metadata\n    self.headers = headers\n    self.cookies = cookies\n    self.env_vars = env_vars\n    self.runtime_env = runtime_env\n    self.num_cpus = num_cpus\n    self.num_gpus = num_gpus\n    self.memory = memory\n    self.resources = resources\n\n    super().__init__()\n</code></pre>"},{"location":"api/core/#dagster_ray.run_launcher.RayRunLauncher-functions","title":"Functions","text":""},{"location":"api/core/#executor","title":"Executor","text":""},{"location":"api/core/#dagster_ray.executor.ray_executor","title":"ray_executor","text":"<pre><code>ray_executor(init_context: InitExecutorContext) -&gt; Executor\n</code></pre> <p>Executes steps by submitting them as Ray jobs.</p> <p>The steps are started inside the Ray cluster directly. When used together with the <code>RayRunLauncher</code>, the executor can inherit the job submission client configuration. This behavior can be disabled by setting <code>inherit_job_submission_client_from_ray_run_launcher</code> to <code>False</code>.</p> Example <p>Use <code>ray_executor</code> for the entire code location <pre><code>import dagster as dg\nfrom dagster_ray import ray_executor\n\nray_executor = ray_executor.configured(\n    {\"address\": EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n)\n\ndefs = dg.Definitions(..., executor=ray_executor])\n</code></pre></p> Example <p>Override configuration for a specific asset <pre><code>import dagster as dg\n\n@dg.asset(\n    op_tags={\"dagster-ray/config\": {\"num_cpus\": 2}}\n)\ndef my_asset(): ...\n</code></pre></p> Source code in <code>src/dagster_ray/executor.py</code> <pre><code>@dg.executor(\n    name=\"ray\",\n    config_schema=_RAY_EXECUTOR_CONFIG_SCHEMA,\n    requirements=multiple_process_executor_requirements(),\n)\ndef ray_executor(init_context: InitExecutorContext) -&gt; Executor:\n    \"\"\"Executes steps by submitting them as Ray jobs.\n\n    The steps are started inside the Ray cluster directly.\n    When used together with the `RayRunLauncher`, the executor can inherit the job submission client configuration.\n    This behavior can be disabled by setting `inherit_job_submission_client_from_ray_run_launcher` to `False`.\n\n    Example:\n        Use `ray_executor` for the entire code location\n        ```python\n        import dagster as dg\n        from dagster_ray import ray_executor\n\n        ray_executor = ray_executor.configured(\n            {\"address\": EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n        )\n\n        defs = dg.Definitions(..., executor=ray_executor])\n        ```\n\n    Example:\n        Override configuration for a specific asset\n        ```python\n        import dagster as dg\n\n        @dg.asset(\n            op_tags={\"dagster-ray/config\": {\"num_cpus\": 2}}\n        )\n        def my_asset(): ...\n        ```\n    \"\"\"\n    from ray.job_submission import JobSubmissionClient\n\n    exc_cfg = init_context.executor_config\n    ray_cfg = RayExecutorConfig(**exc_cfg[\"ray\"])  # type: ignore\n\n    if ray_cfg.inherit_job_submission_client_from_ray_run_launcher and isinstance(\n        init_context.instance.run_launcher, RayRunLauncher\n    ):\n        # TODO: some RunLauncher config values can be automatically passed to the executor\n        client = init_context.instance.run_launcher.client\n    else:\n        client = JobSubmissionClient(\n            ray_cfg.address, metadata=ray_cfg.metadata, headers=ray_cfg.headers, cookies=ray_cfg.cookies\n        )\n\n    return StepDelegatingExecutor(\n        RayStepHandler(\n            client=client,\n            env_vars=ray_cfg.env_vars,\n            runtime_env=ray_cfg.runtime_env,\n            num_cpus=ray_cfg.num_cpus,\n            num_gpus=ray_cfg.num_gpus,\n            memory=ray_cfg.memory,\n            resources=ray_cfg.resources,\n        ),\n        retries=RetryMode.from_config(exc_cfg[\"retries\"]),  # type: ignore\n        max_concurrent=dg._check.opt_int_elem(exc_cfg, \"max_concurrent\"),\n        tag_concurrency_limits=dg._check.opt_list_elem(exc_cfg, \"tag_concurrency_limits\"),\n        should_verify_step=True,\n    )\n</code></pre>"},{"location":"api/core/#pipes","title":"Pipes","text":"<p>Run external Ray scripts as Ray jobs while streaming back logs and metadata into Dagster.</p>"},{"location":"api/core/#dagster_ray.pipes.PipesRayJobClient","title":"PipesRayJobClient","text":"<pre><code>PipesRayJobClient(\n    client: JobSubmissionClient,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n)\n</code></pre> <p>               Bases: <code>PipesClient</code>, <code>TreatAsResourceParam</code></p> <p>A Pipes client for running Ray jobs on remote clusters.</p> <p>Starts the job directly on the Ray cluster and reads the logs from the job.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>JobSubmissionClient</code> <p>The Ray job submission client</p> required <code>context_injector</code> <code>Optional[PipesContextInjector]</code> <p>A context injector to use to inject context into the Ray job. Defaults to <code>PipesEnvContextInjector</code>.</p> <code>None</code> <code>message_reader</code> <code>Optional[PipesMessageReader]</code> <p>A message reader to use to read messages from the glue job run. Defaults to <code>PipesRayJobMessageReader</code>.</p> <code>None</code> <code>forward_termination</code> <code>bool</code> <p>Whether to cancel the <code>RayJob</code> job run when the Dagster process receives a termination signal.</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for various internal interactions with the Kubernetes RayJob.</p> <code>600</code> <code>poll_interval</code> <code>int</code> <p>Interval at which to poll the Kubernetes for status updates.</p> <code>1</code> Source code in <code>src/dagster_ray/pipes.py</code> <pre><code>def __init__(\n    self,\n    client: JobSubmissionClient,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n):\n    self.client = client\n    self._context_injector = context_injector or PipesEnvContextInjector()\n    self._message_reader = message_reader or PipesRayJobMessageReader()\n\n    self.forward_termination = check.bool_param(forward_termination, \"forward_termination\")\n    self.timeout = check.int_param(timeout, \"timeout\")\n    self.poll_interval = check.int_param(poll_interval, \"poll_interval\")\n\n    self._job_submission_client: JobSubmissionClient | None = None\n</code></pre>"},{"location":"api/core/#dagster_ray.pipes.PipesRayJobClient-functions","title":"Functions","text":""},{"location":"api/core/#dagster_ray.pipes.PipesRayJobClient.run","title":"run","text":"<pre><code>run(\n    *, context: OpOrAssetExecutionContext, submit_job_params: SubmitJobParams, extras: PipesExtras | None = None\n) -&gt; PipesClientCompletedInvocation\n</code></pre> <p>Execute a RayJob, enriched with the Pipes protocol.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>OpExecutionContext</code> <p>Current Dagster op or asset context.</p> required <code>submit_job_params</code> <code>Dict[str, Any]</code> <p>RayJob specification. <code>API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;</code>_.</p> required <code>extras</code> <code>Optional[Dict[str, Any]]</code> <p>Additional information to pass to the Pipes session.</p> <code>None</code> Source code in <code>src/dagster_ray/pipes.py</code> <pre><code>def run(  # type: ignore\n    self,\n    *,\n    context: OpOrAssetExecutionContext,\n    submit_job_params: SubmitJobParams,\n    extras: PipesExtras | None = None,\n) -&gt; PipesClientCompletedInvocation:\n    \"\"\"\n    Execute a RayJob, enriched with the Pipes protocol.\n\n    Args:\n        context (OpExecutionContext): Current Dagster op or asset context.\n        submit_job_params (Dict[str, Any]): RayJob specification. `API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;`_.\n        extras (Optional[Dict[str, Any]]): Additional information to pass to the Pipes session.\n    \"\"\"\n\n    with open_pipes_session(\n        context=context,\n        message_reader=self._message_reader,\n        context_injector=self._context_injector,\n        extras=extras,\n    ) as session:\n        enriched_submit_job_params = self._enrich_submit_job_params(context, session, submit_job_params)\n\n        job_id = self._start(context, session, enriched_submit_job_params)\n\n        try:\n            # self._read_messages(context, job_id)\n            self._wait_for_completion(context, job_id)\n            return PipesClientCompletedInvocation(session, metadata={\"Ray Job ID\": job_id})\n\n        except DagsterExecutionInterruptedError:\n            if self.forward_termination:\n                context.log.warning(f\"[pipes] Dagster process interrupted! Will terminate RayJob {job_id}.\")\n                self._terminate(context, job_id)\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.pipes.PipesRayJobMessageReader","title":"PipesRayJobMessageReader","text":"<pre><code>PipesRayJobMessageReader(job_submission_client_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>               Bases: <code>PipesMessageReader</code></p> Source code in <code>src/dagster_ray/pipes.py</code> <pre><code>def __init__(self, job_submission_client_kwargs: dict[str, Any] | None = None):\n    self._job_submission_client_kwargs = job_submission_client_kwargs\n    self._thread: threading.Thread | None = None\n    self.session_closed = threading.Event()\n    self._job_id = None\n    self._client = None\n    self.thread_ready = threading.Event()\n\n    self.completed = threading.Event()\n</code></pre>"},{"location":"api/core/#dagster_ray.pipes.PipesRayJobMessageReader-functions","title":"Functions","text":""},{"location":"api/core/#io-manager","title":"IO Manager","text":""},{"location":"api/core/#dagster_ray.io_manager.RayIOManager","title":"RayIOManager","text":"<p>               Bases: <code>ConfigurableIOManager</code></p> <p>IO Manager that stores intermediate values in Ray's object store.</p> <p>The RayIOManager allows storing and retrieving intermediate values in Ray's distributed object store, making it ideal for use with RayRunLauncher and ray_executor. It works by storing Dagster step keys in a global Ray actor that maintains a mapping between step keys and Ray ObjectRefs.</p> <p>Parameters:</p> Name Type Description Default <code>address</code> <p>Ray cluster address. If provided, will initialize Ray connection.     If None, assumes Ray is already initialized.</p> required Example <p>Basic usage <pre><code>import dagster as dg\nfrom dagster_ray import RayIOManager\n\n@dg.asset(io_manager_key=\"ray_io_manager\")\ndef upstream() -&gt; int:\n    return 42\n\n@dg.asset\ndef downstream(upstream: int):\n    return upstream * 2\n\ndefinitions = dg.Definitions(\n    assets=[upstream, downstream],\n    resources={\"ray_io_manager\": RayIOManager()}\n)\n</code></pre></p> Example <p>With Ray cluster address <pre><code>ray_io_manager = RayIOManager(address=\"ray://head-node:10001\")\n</code></pre></p> Info <ul> <li>Works with any pickable Python objects</li> <li>Supports partitioned assets and partition mappings</li> <li>Uses Ray's automatic object movement for fault tolerance</li> <li>Objects are stored with the Ray actor as owner for lifecycle management</li> </ul>"},{"location":"api/core/#types","title":"Types","text":""},{"location":"api/core/#dagster_ray.Lifecycle","title":"Lifecycle  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"create\": {\n      \"default\": true,\n      \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n      \"title\": \"Create\",\n      \"type\": \"boolean\"\n    },\n    \"wait\": {\n      \"default\": true,\n      \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n      \"title\": \"Wait\",\n      \"type\": \"boolean\"\n    },\n    \"connect\": {\n      \"default\": true,\n      \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n      \"title\": \"Connect\",\n      \"type\": \"boolean\"\n    },\n    \"cleanup\": {\n      \"default\": \"always\",\n      \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n      \"enum\": [\n        \"never\",\n        \"always\",\n        \"on_exception\"\n      ],\n      \"title\": \"Cleanup\",\n      \"type\": \"string\"\n    }\n  },\n  \"title\": \"Lifecycle\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>create</code>                 (<code>bool</code>)             </li> <li> <code>wait</code>                 (<code>bool</code>)             </li> <li> <code>connect</code>                 (<code>bool</code>)             </li> <li> <code>cleanup</code>                 (<code>Literal['never', 'always', 'on_exception']</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.Lifecycle-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.Lifecycle.create","title":"create  <code>pydantic-field</code>","text":"<pre><code>create: bool = True\n</code></pre> <p>Whether to create the resource. If set to <code>False</code>, the user can manually call <code>.create</code> instead.</p>"},{"location":"api/core/#dagster_ray.Lifecycle.wait","title":"wait  <code>pydantic-field</code>","text":"<pre><code>wait: bool = True\n</code></pre> <p>Whether to wait for the remote Ray cluster to become ready to accept connections. If set to <code>False</code>, the user can manually call <code>.wait</code> instead.</p>"},{"location":"api/core/#dagster_ray.Lifecycle.connect","title":"connect  <code>pydantic-field</code>","text":"<pre><code>connect: bool = True\n</code></pre> <p>Whether to run <code>ray.init</code> against the remote Ray cluster. If set to <code>False</code>, the user can manually call <code>.connect</code> instead.</p>"},{"location":"api/core/#dagster_ray.Lifecycle.cleanup","title":"cleanup  <code>pydantic-field</code>","text":"<pre><code>cleanup: Literal['never', 'always', 'on_exception'] = 'always'\n</code></pre> <p>Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.</p>"},{"location":"api/core/#dagster_ray.types.AnyDagsterContext","title":"AnyDagsterContext  <code>module-attribute</code>","text":"<pre><code>AnyDagsterContext: TypeAlias = OpExecutionContext | AssetExecutionContext | InitResourceContext\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource","title":"BaseRayResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource</code>, <code>ABC</code></p> <p>Base class for Ray Resources providing a common interface for Ray cluster management.</p> <p>This abstract base class defines the interface that all Ray resources must implement, providing a backend-agnostic way to interact with Ray clusters. Concrete implementations include LocalRay for local development and KubeRay resources for Kubernetes deployments.</p> <p>The BaseRayResource handles the lifecycle of Ray clusters including creation, connection, and cleanup, with configurable policies for each stage.</p> Example <p>Use as a type annotation for backend-agnostic code <pre><code>import dagster as dg\nfrom dagster_ray import RayResource\n\n@dg.asset\ndef my_asset(ray_cluster: RayResource):\n    # Works with any Ray backend\n    import ray\n    return ray.get(ray.put(\"hello\"))\n</code></pre></p> Example <p>Manual lifecycle management <pre><code>from dagster_ray import Lifecycle\n\nray_resource = SomeRayResource(\n    lifecycle=Lifecycle(\n        create=False,  # Don't auto-create\n        connect=False  # Don't auto-connect\n    )\n)\n</code></pre></p> Note <p>This is an abstract class and cannot be instantiated directly. Use concrete implementations like LocalRay or KubeRayCluster instead.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Base class for Ray Resources providing a common interface for Ray cluster management.\\n\\nThis abstract base class defines the interface that all Ray resources must implement,\\nproviding a backend-agnostic way to interact with Ray clusters. Concrete implementations\\ninclude LocalRay for local development and KubeRay resources for Kubernetes deployments.\\n\\nThe BaseRayResource handles the lifecycle of Ray clusters including creation, connection,\\nand cleanup, with configurable policies for each stage.\\n\\nExample:\\n    Use as a type annotation for backend-agnostic code\\n    ```python\\n    import dagster as dg\\n    from dagster_ray import RayResource\\n\\n    @dg.asset\\n    def my_asset(ray_cluster: RayResource):\\n        # Works with any Ray backend\\n        import ray\\n        return ray.get(ray.put(\\\"hello\\\"))\\n    ```\\n\\nExample:\\n    Manual lifecycle management\\n    ```python\\n    from dagster_ray import Lifecycle\\n\\n    ray_resource = SomeRayResource(\\n        lifecycle=Lifecycle(\\n            create=False,  # Don't auto-create\\n            connect=False  # Don't auto-connect\\n        )\\n    )\\n    ```\\n\\nNote:\\n    This is an abstract class and cannot be instantiated directly. Use concrete\\n    implementations like LocalRay or KubeRayCluster instead.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"BaseRayResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.resources.BaseRayResource.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.timeout","title":"timeout  <code>pydantic-field</code>","text":"<pre><code>timeout: float = 600.0\n</code></pre> <p>Timeout for Ray readiness in seconds</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.ray_init_options","title":"ray_init_options  <code>pydantic-field</code>","text":"<pre><code>ray_init_options: dict[str, Any]\n</code></pre> <p>Additional keyword arguments to pass to <code>ray.init()</code> call, such as <code>runtime_env</code>, <code>num_cpus</code>, etc. Dagster's <code>EnvVar</code> is supported. More details in Ray docs.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.data_execution_options","title":"data_execution_options  <code>pydantic-field</code>","text":"<pre><code>data_execution_options: RayDataExecutionOptions\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.redis_port","title":"redis_port  <code>pydantic-field</code>","text":"<pre><code>redis_port: int = 10001\n</code></pre> <p>Redis port for connection. Make sure to match with the actual available port.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.dashboard_port","title":"dashboard_port  <code>pydantic-field</code>","text":"<pre><code>dashboard_port: int = 8265\n</code></pre> <p>Dashboard port for connection. Make sure to match with the actual available port.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.env_vars","title":"env_vars  <code>pydantic-field</code>","text":"<pre><code>env_vars: dict[str, str] | None\n</code></pre> <p>Environment variables to pass to the Ray cluster.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.enable_tracing","title":"enable_tracing  <code>pydantic-field</code>","text":"<pre><code>enable_tracing: bool = False\n</code></pre> <p>Enable tracing: inject <code>RAY_PROFILING=1</code> and <code>RAY_task_events_report_interval_ms=0</code> into the Ray cluster configuration. This allows using <code>ray.timeline()</code> to fetch recorded task events. Learn more: https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.enable_actor_task_logging","title":"enable_actor_task_logging  <code>pydantic-field</code>","text":"<pre><code>enable_actor_task_logging: bool = False\n</code></pre> <p>Enable actor task logging: inject <code>RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1</code> into the Ray cluster configuration.</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.enable_debug_post_mortem","title":"enable_debug_post_mortem  <code>pydantic-field</code>","text":"<pre><code>enable_debug_post_mortem: bool = False\n</code></pre> <p>Enable post-mortem debugging: inject <code>RAY_DEBUG_POST_MORTEM=1</code> into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.enable_legacy_debugger","title":"enable_legacy_debugger  <code>pydantic-field</code>","text":"<pre><code>enable_legacy_debugger: bool = False\n</code></pre> <p>Enable legacy debugger: inject <code>RAY_DEBUG=legacy</code> into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource._context","title":"_context  <code>pydantic-field</code>","text":"<pre><code>_context: BaseContext | None\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.context","title":"context  <code>property</code>","text":"<pre><code>context: BaseContext\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.host","title":"host  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>host: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.name","title":"name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.display_name","title":"display_name  <code>property</code>","text":"<pre><code>display_name: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.ray_address","title":"ray_address  <code>property</code>","text":"<pre><code>ray_address: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.dashboard_url","title":"dashboard_url  <code>property</code>","text":"<pre><code>dashboard_url: str\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.runtime_job_id","title":"runtime_job_id  <code>property</code>","text":"<pre><code>runtime_job_id: str\n</code></pre> <p>Returns the Ray Job ID for the current job which was created with <code>ray.init()</code>. :return:</p>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.ready","title":"ready  <code>property</code>","text":"<pre><code>ready: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.connected","title":"connected  <code>property</code>","text":"<pre><code>connected: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource-functions","title":"Functions","text":""},{"location":"api/core/#dagster_ray.resources.BaseRayResource.yield_for_execution","title":"yield_for_execution","text":"<pre><code>yield_for_execution(context: InitResourceContext) -&gt; Generator[Self, None, None]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>@contextlib.contextmanager\ndef yield_for_execution(self, context: dg.InitResourceContext) -&gt; Generator[Self, None, None]:\n    exception_occurred = None\n    try:\n        if self.lifecycle.create:\n            self._create(context)\n            if self.lifecycle.wait:\n                self._wait(context)\n                if self.lifecycle.connect:\n                    self._connect(context)\n        yield self\n    except BaseException as e:\n        exception_occurred = e\n        raise\n    finally:\n        self.cleanup(context, exception_occurred)\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource._create","title":"_create","text":"<pre><code>_create(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _create(self, context: AnyDagsterContext):\n    assert context.log is not None\n    if not self.created:\n        try:\n            self.create(context)\n            context.log.info(f\"Created {self.display_name}.\")\n        except BaseException:\n            context.log.exception(f\"Failed to create {self.display_name}\")\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource._wait","title":"_wait","text":"<pre><code>_wait(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _wait(self, context: AnyDagsterContext):\n    assert context.log is not None\n    self._create(context)\n    if not self.ready:\n        context.log.info(f\"Waiting for {self.display_name} to become ready (timeout={self.timeout:.0f}s)...\")\n        try:\n            self.wait(context)\n        except BaseException:\n            context.log.exception(f\"Failed to wait for {self.display_name} readiness\")\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource._connect","title":"_connect","text":"<pre><code>_connect(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _connect(self, context: AnyDagsterContext):\n    assert context.log is not None\n    self._wait(context)\n    if not self.connected:\n        try:\n            self.connect(context)\n        except BaseException:\n            context.log.exception(f\"Failed to connect to {self.display_name}\")\n            raise\n        context.log.info(f\"Initialized Ray Client with {self.display_name}\")\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.create","title":"create","text":"<pre><code>create(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def create(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.wait","title":"wait","text":"<pre><code>wait(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def wait(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.connect","title":"connect","text":"<pre><code>connect(context: AnyDagsterContext) -&gt; BaseContext\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>@retry(stop=stop_after_delay(120), retry=retry_if_exception_type(ConnectionError), reraise=True)\ndef connect(self, context: AnyDagsterContext) -&gt; RayBaseContext:\n    assert context.log is not None\n\n    import ray\n\n    init_options = _process_dagster_env_vars(self.ray_init_options.copy())\n\n    # cleanup None values from runtime_env.env_vars since Ray doesn't like them\n\n    if \"runtime_env\" in init_options and \"env_vars\" in init_options[\"runtime_env\"]:\n        init_options[\"runtime_env\"][\"env_vars\"] = {\n            k: v for k, v in init_options[\"runtime_env\"][\"env_vars\"].items() if v is not None\n        }\n\n    init_options[\"runtime_env\"] = init_options.get(\"runtime_env\", {})\n    init_options[\"runtime_env\"][\"env_vars\"] = init_options[\"runtime_env\"].get(\"env_vars\", {})\n\n    for var, value in self.get_env_vars_to_inject().items():\n        init_options[\"runtime_env\"][\"env_vars\"][var] = value\n\n    self.data_execution_options.apply()\n\n    self._context = ray.init(\n        address=self.ray_address,\n        **init_options,\n    )\n    self.data_execution_options.apply()\n    self.data_execution_options.apply_remote()\n    context.log.info(\"Initialized Ray in client mode!\")\n    return cast(\"RayBaseContext\", self._context)\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.delete","title":"delete","text":"<pre><code>delete(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def delete(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.cleanup","title":"cleanup","text":"<pre><code>cleanup(context: AnyDagsterContext, exception: BaseException | None)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def cleanup(self, context: AnyDagsterContext, exception: BaseException | None):  # noqa: UP007\n    assert context.log is not None\n\n    if self.lifecycle.cleanup == \"never\":\n        to_delete = False\n    elif not self.created:\n        to_delete = False\n    elif self.lifecycle.cleanup == \"always\":\n        to_delete = True\n    elif self.lifecycle.cleanup == \"on_exception\":\n        to_delete = exception is not None\n    else:\n        to_delete = False\n\n    if to_delete:\n        self.delete(context)\n        context.log.info(f'Deleted {self.display_name} according to cleanup policy \"{self.lifecycle.cleanup}\"')\n\n    if self.connected and hasattr(self, \"_context\") and self._context is not None:\n        self._context.disconnect()\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.get_dagster_tags","title":"get_dagster_tags","text":"<pre><code>get_dagster_tags(context: AnyDagsterContext) -&gt; dict[str, str]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def get_dagster_tags(self, context: AnyDagsterContext) -&gt; dict[str, str]:\n    tags = get_dagster_tags(context)\n    return tags\n</code></pre>"},{"location":"api/core/#dagster_ray.resources.BaseRayResource.get_env_vars_to_inject","title":"get_env_vars_to_inject","text":"<pre><code>get_env_vars_to_inject() -&gt; dict[str, str]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def get_env_vars_to_inject(self) -&gt; dict[str, str]:\n    vars: dict[str, str] = self.env_vars or {}\n    if self.enable_debug_post_mortem:\n        vars[\"RAY_DEBUG_POST_MORTEM\"] = \"1\"\n    if self.enable_tracing:\n        vars[\"RAY_PROFILING\"] = \"1\"\n        vars[\"RAY_task_events_report_interval_ms\"] = \"0\"\n    if self.enable_actor_task_logging:\n        vars[\"RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING\"] = \"1\"\n    if self.enable_legacy_debugger:\n        vars[\"RAY_DEBUG\"] = \"legacy\"\n    return vars\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions","title":"RayDataExecutionOptions  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"execution_options\": {\n      \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n    },\n    \"cpu_limit\": {\n      \"default\": 5000,\n      \"title\": \"Cpu Limit\",\n      \"type\": \"integer\"\n    },\n    \"gpu_limit\": {\n      \"default\": 0,\n      \"title\": \"Gpu Limit\",\n      \"type\": \"integer\"\n    },\n    \"verbose_progress\": {\n      \"default\": true,\n      \"title\": \"Verbose Progress\",\n      \"type\": \"boolean\"\n    },\n    \"use_polars\": {\n      \"default\": true,\n      \"title\": \"Use Polars\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"RayDataExecutionOptions\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>execution_options</code>                 (<code>ExecutionOptionsConfig</code>)             </li> <li> <code>cpu_limit</code>                 (<code>int</code>)             </li> <li> <code>gpu_limit</code>                 (<code>int</code>)             </li> <li> <code>verbose_progress</code>                 (<code>bool</code>)             </li> <li> <code>use_polars</code>                 (<code>bool</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.execution_options","title":"execution_options  <code>pydantic-field</code>","text":"<pre><code>execution_options: ExecutionOptionsConfig\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.cpu_limit","title":"cpu_limit  <code>pydantic-field</code>","text":"<pre><code>cpu_limit: int = 5000\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.gpu_limit","title":"gpu_limit  <code>pydantic-field</code>","text":"<pre><code>gpu_limit: int = 0\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.verbose_progress","title":"verbose_progress  <code>pydantic-field</code>","text":"<pre><code>verbose_progress: bool = True\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.use_polars","title":"use_polars  <code>pydantic-field</code>","text":"<pre><code>use_polars: bool = True\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions-functions","title":"Functions","text":""},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.apply","title":"apply","text":"<pre><code>apply()\n</code></pre> Source code in <code>src/dagster_ray/config.py</code> <pre><code>def apply(self):\n    import ray\n    from ray.data import ExecutionResources\n\n    ctx = ray.data.DatasetContext.get_current()\n\n    ctx.execution_options.resource_limits = ExecutionResources.for_limits(\n        cpu=self.execution_options.cpu,\n        gpu=self.execution_options.gpu,\n        object_store_memory=self.execution_options.object_store_memory,\n    )\n\n    ctx.verbose_progress = self.verbose_progress\n    ctx.use_polars = self.use_polars\n</code></pre>"},{"location":"api/core/#dagster_ray.config.RayDataExecutionOptions.apply_remote","title":"apply_remote","text":"<pre><code>apply_remote()\n</code></pre> Source code in <code>src/dagster_ray/config.py</code> <pre><code>def apply_remote(self):\n    import ray\n\n    @ray.remote\n    def apply():\n        self.apply()\n\n    ray.get(apply.remote())\n</code></pre>"},{"location":"api/core/#dagster_ray.config.ExecutionOptionsConfig","title":"ExecutionOptionsConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"cpu\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Cpu\"\n    },\n    \"gpu\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Gpu\"\n    },\n    \"object_store_memory\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Object Store Memory\"\n    }\n  },\n  \"title\": \"ExecutionOptionsConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>cpu</code>                 (<code>int | None</code>)             </li> <li> <code>gpu</code>                 (<code>int | None</code>)             </li> <li> <code>object_store_memory</code>                 (<code>int | None</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.config.ExecutionOptionsConfig-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.config.ExecutionOptionsConfig.cpu","title":"cpu  <code>pydantic-field</code>","text":"<pre><code>cpu: int | None = None\n</code></pre>"},{"location":"api/core/#dagster_ray.config.ExecutionOptionsConfig.gpu","title":"gpu  <code>pydantic-field</code>","text":"<pre><code>gpu: int | None = None\n</code></pre>"},{"location":"api/core/#dagster_ray.config.ExecutionOptionsConfig.object_store_memory","title":"object_store_memory  <code>pydantic-field</code>","text":"<pre><code>object_store_memory: int | None = None\n</code></pre>"},{"location":"api/kuberay/","title":"KubeRay API Reference","text":"<p>KubeRay integration components for running Ray on Kubernetes.  Learn how to use it here.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay","title":"kuberay","text":""},{"location":"api/kuberay/#client-mode-resources","title":"Client Mode Resources","text":"<p>These resources initialize Ray client connection with a remote cluster.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob","title":"KubeRayInteractiveJob  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseRayResource</code>, <code>BaseKubeRayResourceConfig</code></p> <p>Provides a <code>RayJob</code> for Dagster steps.</p> <p>Is the recommended way to run Ray workloads with automatic cluster management. It creates a <code>RayJob</code>, connects to it in client mode and sets the <code>jobId</code> field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.</p> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"InteractiveRayJobConfig\": {\n      \"description\": \"Same as `dagster_ray.kuberay.resources.rayjob.RayJobConfig`, but `spec.submission_mode` mode has to be `InteractiveMode`\",\n      \"properties\": {\n        \"kind\": {\n          \"default\": \"RayJob\",\n          \"title\": \"Kind\",\n          \"type\": \"string\"\n        },\n        \"api_version\": {\n          \"default\": \"ray.io/v1\",\n          \"title\": \"Api Version\",\n          \"type\": \"string\"\n        },\n        \"metadata\": {\n          \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n          \"title\": \"Metadata\",\n          \"type\": \"object\"\n        },\n        \"spec\": {\n          \"$ref\": \"#/$defs/InteractiveRayJobSpec\"\n        }\n      },\n      \"title\": \"InteractiveRayJobConfig\",\n      \"type\": \"object\"\n    },\n    \"InteractiveRayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"Same as `dagster_ray.kuberay.resources.rayjob.RayJobSpec`, but submission mode has to be `InteractiveMode`\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"const\": \"InteractiveMode\",\n          \"default\": \"InteractiveMode\",\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"InteractiveRayJobSpec\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Provides a `RayJob` for Dagster steps.\\n\\nIs the recommended way to run Ray workloads with automatic cluster management. It creates a `RayJob`, connects to it in client mode and sets the `jobId` field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.\\n\\nInfo:\\n    Image defaults to `dagster/image` run tag.\\n\\nTip:\\n    Make sure `ray[full]` is available in the image.\",\n  \"properties\": {\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    },\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"ray_job\": {\n      \"$ref\": \"#/$defs/InteractiveRayJobConfig\",\n      \"description\": \"Configuration for the Kubernetes `RayJob` CR\"\n    },\n    \"client\": {\n      \"description\": \"Kubernetes `RayJob` client\",\n      \"title\": \"Client\"\n    },\n    \"log_cluster_conditions\": {\n      \"default\": true,\n      \"description\": \"Whether to log `RayCluster` conditions while waiting for the RayCluster to become ready. For more information, see https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions.\",\n      \"title\": \"Log Cluster Conditions\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"KubeRayInteractiveJob\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>ray_job</code>                 (<code>InteractiveRayJobConfig</code>)             </li> <li> <code>client</code>                 (<code>ResourceDependency[RayJobClient]</code>)             </li> <li> <code>log_cluster_conditions</code>                 (<code>bool</code>)             </li> <li> <code>_name</code>                 (<code>str</code>)             </li> <li> <code>_cluster_name</code>                 (<code>str</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.ray_job","title":"ray_job  <code>pydantic-field</code>","text":"<pre><code>ray_job: InteractiveRayJobConfig\n</code></pre> <p>Configuration for the Kubernetes <code>RayJob</code> CR</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.client","title":"client  <code>pydantic-field</code>","text":"<pre><code>client: ResourceDependency[RayJobClient]\n</code></pre> <p>Kubernetes <code>RayJob</code> client</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.log_cluster_conditions","title":"log_cluster_conditions  <code>pydantic-field</code>","text":"<pre><code>log_cluster_conditions: bool = True\n</code></pre> <p>Whether to log <code>RayCluster</code> conditions while waiting for the RayCluster to become ready. For more information, see https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster","title":"KubeRayCluster  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseKubeRayResourceConfig</code>, <code>BaseRayResource</code></p> <p>Provides a <code>RayCluster</code> for Dagster steps.</p> <p>It is advised to use <code>dagster_ray.kuberay.KubeRayInteractiveJob</code> with KubeRay &gt;= 1.3.0 instead.</p> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayClusterConfig\": {\n      \"properties\": {\n        \"kind\": {\n          \"default\": \"RayCluster\",\n          \"title\": \"Kind\",\n          \"type\": \"string\"\n        },\n        \"api_version\": {\n          \"default\": \"ray.io/v1\",\n          \"title\": \"Api Version\",\n          \"type\": \"string\"\n        },\n        \"metadata\": {\n          \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n          \"title\": \"Metadata\",\n          \"type\": \"object\"\n        },\n        \"spec\": {\n          \"$ref\": \"#/$defs/RayClusterSpec\"\n        }\n      },\n      \"title\": \"RayClusterConfig\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Provides a `RayCluster` for Dagster steps.\\n\\nIt is advised to use `dagster_ray.kuberay.KubeRayInteractiveJob` with KubeRay &gt;= 1.3.0 instead.\\n\\nInfo:\\n    Image defaults to `dagster/image` run tag.\\n\\nTip:\\n    Make sure `ray[full]` is available in the image.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    },\n    \"ray_cluster\": {\n      \"$ref\": \"#/$defs/RayClusterConfig\",\n      \"description\": \"Kubernetes `RayCluster` CR configuration.\"\n    },\n    \"client\": {\n      \"description\": \"Kubernetes `RayCluster` client\",\n      \"title\": \"Client\"\n    },\n    \"log_cluster_conditions\": {\n      \"default\": true,\n      \"description\": \"Whether to log RayCluster conditions while waiting for the RayCluster to become ready. For more information, see https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions.\",\n      \"title\": \"Log Cluster Conditions\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"KubeRayCluster\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>ray_cluster</code>                 (<code>RayClusterConfig</code>)             </li> <li> <code>client</code>                 (<code>ResourceDependency[RayClusterClient]</code>)             </li> <li> <code>log_cluster_conditions</code>                 (<code>bool</code>)             </li> <li> <code>_name</code>                 (<code>str</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.ray_cluster","title":"ray_cluster  <code>pydantic-field</code>","text":"<pre><code>ray_cluster: RayClusterConfig\n</code></pre> <p>Kubernetes <code>RayCluster</code> CR configuration.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.client","title":"client  <code>pydantic-field</code>","text":"<pre><code>client: ResourceDependency[RayClusterClient]\n</code></pre> <p>Kubernetes <code>RayCluster</code> client</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.log_cluster_conditions","title":"log_cluster_conditions  <code>pydantic-field</code>","text":"<pre><code>log_cluster_conditions: bool = True\n</code></pre> <p>Whether to log RayCluster conditions while waiting for the RayCluster to become ready. For more information, see https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions.</p>"},{"location":"api/kuberay/#job-submission-resources","title":"Job Submission Resources","text":"<p>These resources submit Ray jobs to a remote cluster.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient","title":"PipesKubeRayJobClient","text":"<pre><code>PipesKubeRayJobClient(\n    client: RayJobClient | None = None,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n    port_forward: bool = False,\n)\n</code></pre> <p>               Bases: <code>PipesClient</code>, <code>TreatAsResourceParam</code></p> <p>A pipes client for running <code>RayJob</code> on Kubernetes.</p> <p>Parameters:</p> Name Type Description Default <code>context_injector</code> <code>Optional[PipesContextInjector]</code> <p>A context injector to use to inject context into the <code>RayJob</code>. Defaults to <code>PipesEnvContextInjector</code>.</p> <code>None</code> <code>message_reader</code> <code>Optional[PipesMessageReader]</code> <p>A message reader to use to read messages from the glue job run. Defaults to <code>PipesRayJobMessageReader</code>.</p> <code>None</code> <code>client</code> <code>Optional[client]</code> <p>The Kubernetes API client.</p> <code>None</code> <code>forward_termination</code> <code>bool</code> <p>Whether to terminate the Ray job when the Dagster process receives a termination signal, or if the startup timeout is reached. Defaults to <code>True</code>.</p> <code>True</code> <code>timeout</code> <code>int</code> <p>Timeout for various internal interactions with the Kubernetes RayJob.</p> <code>600</code> <code>poll_interval</code> <code>int</code> <p>Interval at which to poll the Kubernetes for status updates.</p> <code>1</code> <code>port_forward</code> <code>bool</code> <p>Whether to use Kubernetes port-forwarding to connect to the KubeRay cluster.</p> <code>False</code> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Source code in <code>src/dagster_ray/kuberay/pipes.py</code> <pre><code>def __init__(\n    self,\n    client: RayJobClient | None = None,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n    port_forward: bool = False,\n):\n    self.client: RayJobClient = client or RayJobClient()\n\n    self._context_injector = context_injector or PipesEnvContextInjector()\n    self._message_reader = message_reader or PipesRayJobMessageReader()\n\n    self.forward_termination = check.bool_param(forward_termination, \"forward_termination\")\n    self.timeout = check.int_param(timeout, \"timeout\")\n    self.poll_interval = check.int_param(poll_interval, \"poll_interval\")\n    self.port_forward = check.bool_param(port_forward, \"port_forward\")\n\n    self._job_submission_client: JobSubmissionClient | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient.run","title":"run","text":"<pre><code>run(\n    *, context: OpOrAssetExecutionContext, ray_job: dict[str, Any], extras: PipesExtras | None = None\n) -&gt; PipesClientCompletedInvocation\n</code></pre> <p>Execute a RayJob, enriched with the Pipes protocol.</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>OpExecutionContext</code> <p>Current Dagster op or asset context.</p> required <code>ray_job</code> <code>Dict[str, Any]</code> <p>RayJob specification. <code>API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;</code>_.</p> required <code>extras</code> <code>Optional[Dict[str, Any]]</code> <p>Additional information to pass to the Pipes session.</p> <code>None</code> Source code in <code>src/dagster_ray/kuberay/pipes.py</code> <pre><code>def run(  # type: ignore\n    self,\n    *,\n    context: OpOrAssetExecutionContext,\n    ray_job: dict[str, Any],\n    extras: PipesExtras | None = None,\n) -&gt; PipesClientCompletedInvocation:\n    \"\"\"\n    Execute a RayJob, enriched with the Pipes protocol.\n\n    Args:\n        context (OpExecutionContext): Current Dagster op or asset context.\n        ray_job (Dict[str, Any]): RayJob specification. `API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;`_.\n        extras (Optional[Dict[str, Any]]): Additional information to pass to the Pipes session.\n    \"\"\"\n    with open_pipes_session(\n        context=context,\n        message_reader=self._message_reader,\n        context_injector=self._context_injector,\n        extras=extras,\n    ) as session:\n        ray_job = self._enrich_ray_job(context, session, ray_job)\n        start_response = self._start(context, session, ray_job)\n        start_status = cast(RayJobStatus, start_response[\"status\"])\n        ray_job_id = start_status[\"jobId\"]  # pyright: ignore[reportTypedDictNotRequiredAccess]\n\n        name = ray_job[\"metadata\"][\"name\"]\n        namespace = ray_job[\"metadata\"][\"namespace\"]\n\n        with self.client.ray_cluster_client.job_submission_client(\n            name=self.client.get_ray_cluster_name(\n                name=name, namespace=namespace, timeout=self.timeout, poll_interval=self.poll_interval\n            ),\n            namespace=namespace,\n            port_forward=self.port_forward,\n        ) as job_submission_client:\n            self._job_submission_client = job_submission_client\n\n            session.report_launched(\n                {\n                    \"extras\": {\n                        PIPES_LAUNCHED_EXTRAS_RAY_JOB_ID_KEY: ray_job_id,\n                        PIPES_LAUNCHED_EXTRAS_RAY_ADDRESS_KEY: job_submission_client.get_address(),\n                    }\n                }\n            )\n\n            try:\n                self._wait_for_completion(context, start_response)\n\n                if isinstance(self._message_reader, PipesRayJobMessageReader) and self.port_forward:\n                    # in this case the message reader will fail once port forwarding is finished\n                    # TODO: merge https://github.com/danielgafni/dagster-ray/pull/123\n                    # to avoid this work-around\n                    self._message_reader.thread_ready.wait()\n                    context.log.debug(\n                        \"[pipes] waiting for PipesRayJobMessageReader to complete before stopping port-forwarding\"\n                    )\n                    self._message_reader.session_closed.set()\n                    self._message_reader.completed.wait()\n\n                return PipesClientCompletedInvocation(\n                    session, metadata={\"RayJob\": f\"{namespace}/{name}\", \"Ray Job ID\": ray_job_id}\n                )\n\n            except DagsterExecutionInterruptedError:\n                if self.forward_termination:\n                    context.log.warning(\n                        f\"[pipes] Dagster process interrupted! Will terminate RayJob {namespace}/{name}.\"\n                    )\n                    self._terminate(context, start_response)\n                raise\n</code></pre>"},{"location":"api/kuberay/#configuration-and-types","title":"Configuration and Types","text":"<p>--</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig","title":"RayJobConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayJob spec](https://ray-project.github.io/kuberay/reference/api/#rayjobspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"default\": \"K8sJobMode\",\n          \"enum\": [\n            \"K8sJobMode\",\n            \"HTTPMode\",\n            \"InteractiveMode\"\n          ],\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"RayJobSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayJob\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/RayJobSpec\"\n    }\n  },\n  \"title\": \"RayJobConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>RayJobSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: RayJobSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(\n            context=context,\n            image=image,\n            env_vars=env_vars,\n        ),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec","title":"RayJobSpec","text":"<p>               Bases: <code>PermissiveConfig</code></p> <p>RayJob spec configuration options. A few sensible defaults are provided for convenience.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.ray_cluster_spec","title":"ray_cluster_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_cluster_spec: RayClusterSpec | None = Field(default_factory=RayClusterSpec)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_num_cpus","title":"entrypoint_num_cpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_cpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_num_gpus","title":"entrypoint_num_gpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_gpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_memory","title":"entrypoint_memory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_memory: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_resources","title":"entrypoint_resources  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_resources: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n    return remove_none_from_dict(\n        {\n            \"activeDeadlineSeconds\": self.active_deadline_seconds,\n            \"backoffLimit\": self.backoff_limit,\n            \"submitterPodTemplate\": self.submitter_pod_template,\n            \"metadata\": self.metadata,\n            \"clusterSelector\": self.cluster_selector,\n            \"managedBy\": self.managed_by,\n            \"deletionStrategy\": self.deletion_strategy,\n            \"runtimeEnvYAML\": self.runtime_env_yaml,\n            \"jobId\": self.job_id,\n            \"submissionMode\": self.submission_mode,\n            \"entrypointResources\": self.entrypoint_resources,\n            \"entrypointNumCpus\": self.entrypoint_num_cpus,\n            \"entrypointMemory\": self.entrypoint_memory,\n            \"entrypointNumGpus\": self.entrypoint_num_gpus,\n            \"ttlSecondsAfterFinished\": self.ttl_seconds_after_finished,\n            \"shutdownAfterJobFinishes\": self.shutdown_after_job_finishes,\n            \"suspend\": self.suspend,\n            \"rayClusterSpec\": self.ray_cluster_spec.to_k8s(context=context, image=image, env_vars=env_vars)\n            if self.ray_cluster_spec is not None\n            else None,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig","title":"InteractiveRayJobConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>RayJobConfig</code></p> <p>Same as <code>dagster_ray.kuberay.resources.rayjob.RayJobConfig</code>, but <code>spec.submission_mode</code> mode has to be <code>InteractiveMode</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"InteractiveRayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"Same as `dagster_ray.kuberay.resources.rayjob.RayJobSpec`, but submission mode has to be `InteractiveMode`\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"const\": \"InteractiveMode\",\n          \"default\": \"InteractiveMode\",\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"InteractiveRayJobSpec\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Same as `dagster_ray.kuberay.resources.rayjob.RayJobConfig`, but `spec.submission_mode` mode has to be `InteractiveMode`\",\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayJob\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/InteractiveRayJobSpec\"\n    }\n  },\n  \"title\": \"InteractiveRayJobConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>InteractiveRayJobSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: InteractiveRayJobSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(\n            context=context,\n            image=image,\n            env_vars=env_vars,\n        ),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec","title":"InteractiveRayJobSpec","text":"<p>               Bases: <code>RayJobSpec</code></p> <p>Same as <code>dagster_ray.kuberay.resources.rayjob.RayJobSpec</code>, but submission mode has to be <code>InteractiveMode</code></p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.submission_mode","title":"submission_mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>submission_mode: Literal['InteractiveMode'] = 'InteractiveMode'\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.active_deadline_seconds","title":"active_deadline_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>active_deadline_seconds: int = 60 * 60 * 24\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.backoff_limit","title":"backoff_limit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backoff_limit: int = 0\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.ray_cluster_spec","title":"ray_cluster_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_cluster_spec: RayClusterSpec | None = Field(default_factory=RayClusterSpec)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.submitter_pod_template","title":"submitter_pod_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>submitter_pod_template: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.cluster_selector","title":"cluster_selector  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cluster_selector: dict[str, str] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.managed_by","title":"managed_by  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>managed_by: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.deletion_strategy","title":"deletion_strategy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>deletion_strategy: dict[str, Any] | None = Field(\n    default_factory=lambda: {\"onFailure\": {\"policy\": \"DeleteCluster\"}, \"onSuccess\": {\"policy\": \"DeleteCluster\"}}\n)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.runtime_env_yaml","title":"runtime_env_yaml  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>runtime_env_yaml: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.job_id","title":"job_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>job_id: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_resources","title":"entrypoint_resources  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_resources: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_num_cpus","title":"entrypoint_num_cpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_cpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_memory","title":"entrypoint_memory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_memory: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_num_gpus","title":"entrypoint_num_gpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_gpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.ttl_seconds_after_finished","title":"ttl_seconds_after_finished  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ttl_seconds_after_finished: int | None = 5 * 60\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.shutdown_after_job_finishes","title":"shutdown_after_job_finishes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shutdown_after_job_finishes: bool = True\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.suspend","title":"suspend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>suspend: bool | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n    return remove_none_from_dict(\n        {\n            \"activeDeadlineSeconds\": self.active_deadline_seconds,\n            \"backoffLimit\": self.backoff_limit,\n            \"submitterPodTemplate\": self.submitter_pod_template,\n            \"metadata\": self.metadata,\n            \"clusterSelector\": self.cluster_selector,\n            \"managedBy\": self.managed_by,\n            \"deletionStrategy\": self.deletion_strategy,\n            \"runtimeEnvYAML\": self.runtime_env_yaml,\n            \"jobId\": self.job_id,\n            \"submissionMode\": self.submission_mode,\n            \"entrypointResources\": self.entrypoint_resources,\n            \"entrypointNumCpus\": self.entrypoint_num_cpus,\n            \"entrypointMemory\": self.entrypoint_memory,\n            \"entrypointNumGpus\": self.entrypoint_num_gpus,\n            \"ttlSecondsAfterFinished\": self.ttl_seconds_after_finished,\n            \"shutdownAfterJobFinishes\": self.shutdown_after_job_finishes,\n            \"suspend\": self.suspend,\n            \"rayClusterSpec\": self.ray_cluster_spec.to_k8s(context=context, image=image, env_vars=env_vars)\n            if self.ray_cluster_spec is not None\n            else None,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig","title":"RayClusterConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayCluster\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/RayClusterSpec\"\n    }\n  },\n  \"title\": \"RayClusterConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>RayClusterSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: RayClusterSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    assert context.log is not None\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(context=context, image=image, env_vars=env_vars),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec","title":"RayClusterSpec","text":"<p>               Bases: <code>PermissiveConfig</code></p> <p>RayCluster spec configuration options. A few sensible defaults are provided for convenience.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.suspend","title":"suspend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>suspend: bool | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.managed_by","title":"managed_by  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>managed_by: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.autoscaler_options","title":"autoscaler_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>autoscaler_options: dict[str, Any] = DEFAULT_AUTOSCALER_OPTIONS\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.head_service_annotations","title":"head_service_annotations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>head_service_annotations: dict[str, str] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.enable_in_tree_autoscaling","title":"enable_in_tree_autoscaling  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enable_in_tree_autoscaling: bool = False\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.gcs_fault_tolerance_options","title":"gcs_fault_tolerance_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>gcs_fault_tolerance_options: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.head_group_spec","title":"head_group_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>head_group_spec: dict[str, Any] = DEFAULT_HEAD_GROUP_SPEC\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.ray_version","title":"ray_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_version: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.worker_group_specs","title":"worker_group_specs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>worker_group_specs: list[dict[str, Any]] = DEFAULT_WORKER_GROUP_SPECS\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    assert context.log is not None\n\n    # TODO: inject self.redis_port and self.dashboard_port into the RayCluster configuration\n    # TODO: auto-apply some tags from dagster-k8s/config\n\n    head_group_spec = self.head_group_spec.copy()\n    worker_group_specs = self.worker_group_specs.copy()\n\n    k8s_env_vars: list[dict[str, Any]] = []\n\n    if env_vars:\n        for key, value in env_vars.items():\n            k8s_env_vars.append({\"name\": key, \"value\": value})\n\n    def update_group_spec(group_spec: dict[str, Any]):\n        # TODO: only inject if the container has a `dagster.io/inject-image` annotation or smth\n        if group_spec[\"template\"][\"spec\"][\"containers\"][0].get(\"image\") is None:\n            if image is None:\n                raise ValueError(MISSING_IMAGE_MESSAGE)\n            else:\n                group_spec[\"template\"][\"spec\"][\"containers\"][0][\"image\"] = image\n\n        for container in group_spec[\"template\"][\"spec\"][\"containers\"]:\n            container[\"env\"] = container.get(\"env\", []) + k8s_env_vars\n\n    update_group_spec(head_group_spec)\n    for worker_group_spec in worker_group_specs:\n        update_group_spec(worker_group_spec)\n\n    return remove_none_from_dict(\n        {\n            \"enableInTreeAutoscaling\": self.enable_in_tree_autoscaling,\n            \"autoscalerOptions\": self.autoscaler_options,\n            \"headGroupSpec\": head_group_spec,\n            \"workerGroupSpecs\": worker_group_specs,\n            \"suspend\": self.suspend,\n            \"managedBy\": self.managed_by,\n            \"headServiceAnnotations\": self.head_service_annotations,\n            \"gcsFaultToleranceOptions\": self.gcs_fault_tolerance_options,\n            \"rayVersion\": self.ray_version,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResourceConfig","title":"BaseKubeRayResourceConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    }\n  },\n  \"title\": \"BaseKubeRayResourceConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResourceConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResourceConfig.image","title":"image  <code>pydantic-field</code>","text":"<pre><code>image: str | None = None\n</code></pre> <p>Image to inject into the <code>RayCluster</code> spec. Defaults to <code>dagster/image</code> run tag. Images already provided in the <code>RayCluster</code> spec won't be overridden.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResourceConfig.deployment_name","title":"deployment_name  <code>pydantic-field</code>","text":"<pre><code>deployment_name: str = DEFAULT_DEPLOYMENT_NAME\n</code></pre> <p>Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResourceConfig.poll_interval","title":"poll_interval  <code>pydantic-field</code>","text":"<pre><code>poll_interval: float = 1.0\n</code></pre> <p>Poll interval for various API requests</p>"},{"location":"api/kuberay/#resources","title":"Resources","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayJobClientResource","title":"KubeRayJobClientResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource[RayJobClient]</code></p> <p>This configurable resource provides a <code>dagster_ray.kuberay.client.RayJobClient</code>.</p> Show JSON schema: <pre><code>{\n  \"description\": \"This configurable resource provides a `dagster_ray.kuberay.client.RayJobClient`.\",\n  \"properties\": {\n    \"kube_context\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Context\"\n    },\n    \"kube_config\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Config\"\n    }\n  },\n  \"title\": \"KubeRayJobClientResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kube_context</code>                 (<code>str | None</code>)             </li> <li> <code>kube_config</code>                 (<code>str | None</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayClusterClientResource","title":"KubeRayClusterClientResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource[RayClusterClient]</code></p> <p>This configurable resource provides a <code>dagster_ray.kuberay.client.RayClusterClient</code>.</p> Show JSON schema: <pre><code>{\n  \"description\": \"This configurable resource provides a `dagster_ray.kuberay.client.RayClusterClient`.\",\n  \"properties\": {\n    \"kube_context\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Context\"\n    },\n    \"kube_config\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Config\"\n    }\n  },\n  \"title\": \"KubeRayClusterClientResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kube_context</code>                 (<code>str | None</code>)             </li> <li> <code>kube_config</code>                 (<code>str | None</code>)             </li> </ul>"},{"location":"api/kuberay/#kubernetes-api-clients","title":"Kubernetes API Clients","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient","title":"RayClusterClient","text":"<pre><code>RayClusterClient(kube_config: str | None = None, kube_context: str | None = None, api_client: ApiClient | None = None)\n</code></pre> <p>               Bases: <code>BaseKubeRayClient[RayClusterStatus]</code></p> Source code in <code>src/dagster_ray/kuberay/client/raycluster/client.py</code> <pre><code>def __init__(\n    self,\n    kube_config: str | None = None,\n    kube_context: str | None = None,\n    api_client: ApiClient | None = None,\n) -&gt; None:\n    super().__init__(group=GROUP, version=VERSION, kind=KIND, plural=PLURAL, api_client=api_client)\n\n    # these are only used because of kubectl port-forward CLI command\n    # TODO: remove kubectl usage and remove these attributes\n    self.config_file = kube_config\n    self.context = kube_context\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.create","title":"create","text":"<pre><code>create(body: dict[str, Any], namespace: str) -&gt; Any\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def create(self, body: dict[str, Any], namespace: str) -&gt; Any:\n    return self._api.create_namespaced_custom_object(\n        group=self.group,\n        version=body.get(\"apiVersion\", f\"{self.group}/{self.version}\").split(\"/\")[1],\n        plural=self.plural,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.delete","title":"delete","text":"<pre><code>delete(name: str, namespace: str)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def delete(self, name: str, namespace: str):\n    return self._api.delete_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.get","title":"get","text":"<pre><code>get(name: str, namespace: str) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def get(self, name: str, namespace: str) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.get_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            name=name,\n            namespace=namespace,\n        )\n        return resource\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.list","title":"list","text":"<pre><code>list(namespace: str, label_selector: str = '', async_req: bool = False) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def list(self, namespace: str, label_selector: str = \"\", async_req: bool = False) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.list_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            namespace=namespace,\n            label_selector=label_selector,\n            async_req=async_req,\n        )\n        if \"items\" in resource:\n            return resource\n        else:\n            return {}\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.update","title":"update","text":"<pre><code>update(name: str, namespace: str, body: Any)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def update(self, name: str, namespace: str, body: Any):\n    return self._api.patch_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient","title":"RayJobClient","text":"<pre><code>RayJobClient(kube_config: str | None = None, kube_context: str | None = None, api_client: ApiClient | None = None)\n</code></pre> <p>               Bases: <code>BaseKubeRayClient[RayJobStatus]</code></p> Source code in <code>src/dagster_ray/kuberay/client/rayjob/client.py</code> <pre><code>def __init__(\n    self,\n    kube_config: str | None = None,\n    kube_context: str | None = None,\n    api_client: ApiClient | None = None,\n) -&gt; None:\n    # this call must happen BEFORE creating K8s apis\n    load_kubeconfig(config_file=kube_config, context=kube_context)\n\n    self.config_file = kube_config\n    self.context = kube_context\n\n    super().__init__(group=GROUP, version=VERSION, kind=KIND, plural=PLURAL, api_client=api_client)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.create","title":"create","text":"<pre><code>create(body: dict[str, Any], namespace: str) -&gt; Any\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def create(self, body: dict[str, Any], namespace: str) -&gt; Any:\n    return self._api.create_namespaced_custom_object(\n        group=self.group,\n        version=body.get(\"apiVersion\", f\"{self.group}/{self.version}\").split(\"/\")[1],\n        plural=self.plural,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.delete","title":"delete","text":"<pre><code>delete(name: str, namespace: str)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def delete(self, name: str, namespace: str):\n    return self._api.delete_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.get","title":"get","text":"<pre><code>get(name: str, namespace: str) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def get(self, name: str, namespace: str) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.get_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            name=name,\n            namespace=namespace,\n        )\n        return resource\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.list","title":"list","text":"<pre><code>list(namespace: str, label_selector: str = '', async_req: bool = False) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def list(self, namespace: str, label_selector: str = \"\", async_req: bool = False) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.list_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            namespace=namespace,\n            label_selector=label_selector,\n            async_req=async_req,\n        )\n        if \"items\" in resource:\n            return resource\n        else:\n            return {}\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.update","title":"update","text":"<pre><code>update(name: str, namespace: str, body: Any)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def update(self, name: str, namespace: str, body: Any):\n    return self._api.patch_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"contributing/documentation/","title":"Documentation Guide","text":"<p>This guide covers everything you need to know about writing, maintaining, and deploying documentation for dagster-ray.</p>"},{"location":"contributing/documentation/#overview","title":"Overview","text":"<p>The dagster-ray documentation is built with MkDocs and Material for MkDocs, with automatic API reference generation using mkdocstrings.</p>"},{"location":"contributing/documentation/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 api/                    # API reference documentation\n\u2502   \u251c\u2500\u2500 core.md            # Core components\n\u2502   \u2514\u2500\u2500 kuberay.md         # KubeRay integration\n\u251c\u2500\u2500 assets/                # Static assets (images, stylesheets)\n\u251c\u2500\u2500 contributing/          # Contributor guides\n\u251c\u2500\u2500 includes/              # Reusable content snippets\n\u251c\u2500\u2500 tutorial/              # User tutorials\n\u251c\u2500\u2500 api.md                 # API overview\n\u2514\u2500\u2500 index.md               # Home page\n</code></pre>"},{"location":"contributing/documentation/#local-development-setup","title":"Local Development Setup","text":""},{"location":"contributing/documentation/#prerequisites","title":"Prerequisites","text":"<ol> <li>Python Environment: Ensure you have Python 3.10+ installed</li> <li>UV Package Manager: The project uses <code>uv</code> for dependency management</li> </ol>"},{"location":"contributing/documentation/#setup-steps","title":"Setup Steps","text":"<ol> <li> <p>Clone and Setup Environment:    <pre><code>git clone https://github.com/danielgafni/dagster-ray.git\ncd dagster-ray\nuv sync --all-extras\n</code></pre></p> </li> <li> <p>Serve Documentation Locally:    <pre><code>uv run mkdocs serve\n</code></pre></p> </li> </ol> <p>This starts a development server at <code>http://localhost:8000</code> with live-reload.</p> <ol> <li>Build Documentation:    <pre><code>uv run mkdocs build --clean\n</code></pre></li> </ol>"},{"location":"contributing/documentation/#development-workflow","title":"Development Workflow","text":"<ol> <li>Make Changes: Edit markdown files in the <code>docs/</code> directory</li> <li>Preview: Use <code>mkdocs serve</code> to preview changes locally</li> <li>Validate: Run documentation validation (see below)</li> <li>Test Build: Ensure <code>mkdocs build --strict</code> passes</li> <li>Commit and Push: Create a pull request</li> </ol>"},{"location":"contributing/documentation/#writing-documentation","title":"Writing Documentation","text":""},{"location":"contributing/documentation/#markdown-guidelines","title":"Markdown Guidelines","text":"<ul> <li>Use consistent heading hierarchy: Start with <code>#</code> for page titles, <code>##</code> for main sections</li> <li>Add proper spacing: Leave blank lines around headings and code blocks</li> <li>Use descriptive link text: Avoid \"click here\" or bare URLs</li> <li>Include code examples: Show practical usage where appropriate</li> </ul>"},{"location":"contributing/documentation/#code-examples","title":"Code Examples","text":"<p>Always test code examples before including them:</p> <pre><code>import dagster as dg\nfrom dagster_ray import ray_resource\n\n\n@dg.asset(resource_defs={\"ray\": ray_resource})\ndef my_asset(context):\n    ray = context.resources.ray\n    # Your code here\n    return result\n</code></pre>"},{"location":"contributing/documentation/#cross-references","title":"Cross-References","text":"<p>Use mkdocstrings' cross-reference syntax for linking to API elements:</p> <ul> <li><code>[RayResource][dagster_ray.resources.RayResource]</code></li> <li><code>[ray_resource][dagster_ray.resources.ray_resource]</code></li> </ul>"},{"location":"contributing/documentation/#api-documentation","title":"API Documentation","text":"<p>API documentation is automatically generated from docstrings. Follow these guidelines:</p>"},{"location":"contributing/documentation/#docstring-format","title":"Docstring Format","text":"<p>Use Google-style docstrings:</p> <pre><code>def my_function(param1: str, param2: int = 0) -&gt; bool:\n    \"\"\"Brief description of the function.\n\n    Longer description with more details about what the function does,\n    how it works, and any important considerations.\n\n    Args:\n        param1: Description of the first parameter.\n        param2: Description of the second parameter. Defaults to 0.\n\n    Returns:\n        Description of the return value.\n\n    Raises:\n        ValueError: When param1 is empty.\n\n    Examples:\n        Basic usage:\n\n        ```python\n        result = my_function(\"hello\", 42)\n        ```\n    \"\"\"\n    # Implementation here\n</code></pre>"},{"location":"contributing/documentation/#what-to-document","title":"What to Document","text":"<ul> <li>All public classes and functions</li> <li>Parameters and return values</li> <li>Exceptions that can be raised</li> <li>Usage examples</li> <li>Important notes or warnings</li> </ul>"},{"location":"contributing/documentation/#testing-documentation","title":"Testing Documentation","text":""},{"location":"contributing/documentation/#automated-validation","title":"Automated Validation","text":"<p>Run the documentation validation script:</p> <pre><code>uv run python scripts/validate_docs.py\n</code></pre> <p>This checks for: - Markdown syntax issues - Broken internal links - Missing API references - Python syntax errors in code examples</p>"},{"location":"contributing/documentation/#manual-testing","title":"Manual Testing","text":"<ol> <li> <p>Build with strict mode:    <pre><code>uv run mkdocs build --strict\n</code></pre>    This fails on any warnings or errors.</p> </li> <li> <p>Check specific pages:    <pre><code>uv run mkdocs serve\n# Navigate to your changed pages\n</code></pre></p> </li> <li> <p>Test all internal links: Browse through the documentation and click internal links.</p> </li> </ol>"},{"location":"contributing/documentation/#cicd-testing","title":"CI/CD Testing","text":"<p>Every pull request automatically: - Builds documentation with strict mode - Validates configuration - Checks for broken links - Deploys a preview at <code>https://danielgafni.github.io/dagster-ray/pr-preview/pr-&lt;number&gt;/</code></p>"},{"location":"contributing/documentation/#deployment-process","title":"Deployment Process","text":""},{"location":"contributing/documentation/#automatic-deployment","title":"Automatic Deployment","text":"<p>Documentation is automatically deployed when:</p> <ol> <li>Pull Request: Preview deployment to <code>/pr-preview/pr-&lt;number&gt;/</code></li> <li>Main Branch: Production deployment to <code>https://danielgafni.github.io/dagster-ray/</code></li> <li>Releases: Updated documentation with release-specific content</li> </ol>"},{"location":"contributing/documentation/#manual-deployment","title":"Manual Deployment","text":"<p>If needed, you can manually trigger deployment:</p> <pre><code># Via GitHub CLI\ngh workflow run docs.yml\n\n# Or through GitHub web interface\n# Go to Actions &gt; Documentation &gt; Run workflow\n</code></pre>"},{"location":"contributing/documentation/#deployment-architecture","title":"Deployment Architecture","text":"<pre><code>graph TD\n    A[Push to main] --&gt; B[GitHub Actions]\n    B --&gt; C[Build docs]\n    C --&gt; D[Deploy to GitHub Pages]\n\n    E[Pull Request] --&gt; F[GitHub Actions]\n    F --&gt; G[Build docs preview]\n    G --&gt; H[Deploy to pr-preview]</code></pre>"},{"location":"contributing/documentation/#configuration","title":"Configuration","text":""},{"location":"contributing/documentation/#mkdocs-configuration","title":"MkDocs Configuration","text":"<p>Key configuration in <code>mkdocs.yml</code>:</p> <ul> <li>Theme: Material theme with custom colors</li> <li>Plugins: Search, git info, mkdocstrings, minification</li> <li>Navigation: Organized by user journey</li> <li>Extensions: Enhanced markdown features</li> </ul>"},{"location":"contributing/documentation/#github-actions","title":"GitHub Actions","text":"<p>Three main workflows:</p> <ol> <li>CI.yml: Runs tests and deploys PR previews</li> <li>docs.yml: Deploys production documentation</li> <li>release.yml: Handles package releases</li> </ol>"},{"location":"contributing/documentation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"contributing/documentation/#common-issues","title":"Common Issues","text":""},{"location":"contributing/documentation/#build-failures","title":"Build Failures","text":"<p>Error: <code>ModuleNotFoundError</code> during mkdocstrings processing <pre><code>Solution: Ensure all dependencies are installed:\nuv sync --all-extras\n</code></pre></p> <p>Error: <code>Configuration error</code> in mkdocs <pre><code>Solution: Validate configuration:\nuv run mkdocs config\n</code></pre></p> <p>Error: Broken cross-references <pre><code>Solution: Check module paths and ensure they're importable:\npython -c \"import dagster_ray.resources\"\n</code></pre></p>"},{"location":"contributing/documentation/#preview-deployment-issues","title":"Preview Deployment Issues","text":"<p>Issue: PR preview not updating <pre><code>Solution: Check GitHub Actions logs and ensure permissions are set correctly\n</code></pre></p> <p>Issue: Preview shows 404 errors <pre><code>Solution: Check that base_url is configured correctly for preview deployment\n</code></pre></p>"},{"location":"contributing/documentation/#getting-help","title":"Getting Help","text":"<ol> <li>Check GitHub Actions logs for detailed error messages</li> <li>Run validation script locally to catch issues early</li> <li>Test build locally with <code>mkdocs build --strict</code></li> <li>Ask in issues if you encounter persistent problems</li> </ol>"},{"location":"contributing/documentation/#maintenance-tasks","title":"Maintenance Tasks","text":""},{"location":"contributing/documentation/#regular-maintenance","title":"Regular Maintenance","text":"<ul> <li>Monthly: Review and update outdated examples</li> <li>Per Release: Update version-specific documentation</li> <li>Quarterly: Audit internal links and fix broken ones</li> <li>**As</li> </ul>"},{"location":"tutorial/","title":"Tutorial","text":""},{"location":"tutorial/#dagster-external-ray-clusters","title":"Dagster + External Ray Clusters","text":"<p>Check out External Ray Clusters tutorial if you want to run Ray jobs on existing external Ray clusters.</p>"},{"location":"tutorial/#dagster-kuberay","title":"Dagster + KubeRay","text":"<p>See KubeRay tutorial if you want to use KubeRay's <code>RayJob</code> and <code>RayCluster</code> managed from Dagster</p>"},{"location":"tutorial/external/","title":"Dagster + External Ray Clusters Tutorial","text":"<p>This tutorial covers how to use dagster-ray with external Ray clusters - clusters that are managed outside of Dagster. This approach is ideal when you have existing Ray infrastructure or want to separate cluster management from your data pipelines.</p>"},{"location":"tutorial/external/#when-to-use-each-approach","title":"When to Use Each Approach","text":""},{"location":"tutorial/external/#use-localray-when","title":"Use <code>LocalRay</code> when:","text":"<ul> <li>Developing and testing locally</li> </ul>"},{"location":"tutorial/external/#use-rayrunlauncher-when","title":"Use <code>RayRunLauncher</code> when:","text":"<ul> <li>You want to run all Dagster pipelines on Ray</li> <li>You want very fast Dagster run submission</li> </ul>"},{"location":"tutorial/external/#use-ray_executor-when","title":"Use <code>ray_executor</code> when:","text":"<ul> <li>You want selective Ray execution for specific assets</li> <li>You want very fast Dagster step submission</li> </ul>"},{"location":"tutorial/external/#use-pipesrayjobclient-when","title":"Use <code>PipesRayJobClient</code> when:","text":"<ul> <li>You want to decouple Ray workloads from orchestration code</li> <li>You have existing Ray scripts you want to integrate</li> <li>You want full separation between Dagster and Ray environments</li> </ul>"},{"location":"tutorial/external/#prerequisites","title":"Prerequisites","text":"<p>Before getting started, you'll need:</p> <ul> <li>A Ray cluster (can be local Ray for development, or remote Ray cluster for production)</li> <li>dagster-ray installed:   <pre><code>pip install dagster-ray\n</code></pre></li> <li>For remote clusters: Ray cluster address and appropriate network access</li> </ul>"},{"location":"tutorial/external/#localray-development-and-testing","title":"LocalRay - Development and Testing","text":"<p><code>LocalRay</code> is perfect for local development and testing. It provides the same interface as other Ray resources but runs Ray locally on your machine.</p> <pre><code>import dagster as dg\nfrom dagster_ray import LocalRay\nimport ray\n\n\n@dg.asset\ndef batch_processing_results(ray_cluster: LocalRay) -&gt; dict:\n    \"\"\"Process multiple batches in parallel using local Ray.\"\"\"\n    refs = [process_batch.remote(i, size) for i, size in enumerate(batch_sizes)]\n\n    # Collect results\n    results = ray.get(refs)\n\n    return aggregate(results)\n\n\ndefinitions = dg.Definitions(\n    assets=[batch_processing_results], resources={\"ray_cluster\": LocalRay()}\n)\n</code></pre> <p>You can customize the local Ray configuration:</p> <pre><code>from dagster_ray import LocalRay\n\nlocal_ray = LocalRay(\n    # Ray initialization options\n    ray_init_options={\n        \"num_cpus\": 8,\n        \"num_gpus\": 1,\n        \"object_store_memory\": 1000000000,  # 1GB\n        \"runtime_env\": {\"pip\": [\"numpy\", \"polars\", \"scikit-learn\"]},\n    },\n)\n</code></pre>"},{"location":"tutorial/external/#rayrunlauncher","title":"RayRunLauncher","text":"<p><code>RayRunLauncher</code> executes entire Dagster runs as Ray jobs. This is useful for Dagster deployments that need to be fully executed on Ray.</p> <p>Tip</p> <p>Make sure the Ray cluster has access to Dagster's metadata database!</p>"},{"location":"tutorial/external/#usage","title":"Usage","text":"<p>Configure the run launcher in your <code>dagster.yaml</code>:</p> <pre><code>run_launcher:\n  module: dagster_ray\n  class: RayRunLauncher\n  config:\n    address:\n      env: RAY_ADDRESS\n    timeout: 1800\n    metadata:\n      foo: bar\n      runtime_env:\n      env_vars:\n        FOO: bar\n      pip:\n        - polars\n</code></pre> <p>With <code>RayRunLauncher</code> enabled, your regular Dagster assets will automatically run on Ray:</p> <pre><code>import dagster as dg\n\n\n@dg.asset\ndef regular_asset():\n    \"\"\"This asset will be submitted as a Ray job.\"\"\"\n    ...\n</code></pre> <p>All the steps will be executed in a single Ray job, unless a custom executor is used.</p> <p>It's possible to provide additional runtime configuration via the <code>dagster-ray/config</code> run tag.</p>"},{"location":"tutorial/external/#ray_executor","title":"ray_executor","text":"<p><code>ray_executor</code> runs Dagster steps (ops or assets) as Ray jobs (in parallel).</p> <p>Tip</p> <p>Make sure the Ray cluster has access to Dagster's metadata database!</p>"},{"location":"tutorial/external/#usage_1","title":"Usage","text":"<p>The executor can be enabled at <code>Definitions</code> level:</p> <pre><code>import dagster as dg\nfrom dagster_ray import ray_executor\n\n\ndefinitions = dg.Definitions(\n    executor=ray_executor.configured(\n        {\"address\": dg.EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n    )\n)\n</code></pre> <p>It's possible to configure individual assets via the <code>dagster-ray/config</code> op tag:</p> <pre><code>@dg.asset(\n    op_tags={\n        \"dagster-ray/config\": {\n            \"num_cpus\": 2,\n        }\n    }\n)\ndef my_asset(): ...\n</code></pre>"},{"location":"tutorial/external/#pipesrayjobclient-external-script-execution","title":"PipesRayJobClient - External Script Execution","text":"<p><code>PipesRayJobClient</code> lets you submit external Python scripts to Ray clusters as Ray jobs. This is perfect for decoupling your Ray workloads from Dagster orchestration code and Python environment.</p>"},{"location":"tutorial/external/#external-ray-script","title":"External Ray Script","text":"<p>First, create a script that will run on the Ray cluster:</p> ml_training.py<pre><code># ml_training.py - External Ray script\nimport ray\nfrom dagster_pipes import open_dagster_pipes\n\n\n@ray.remote\ndef train_ml_model(partition_id: int):\n    \"\"\"Dummy ML training function.\"\"\"\n    import time\n\n    time.sleep(1)  # Simulate work\n    return {\"partition_id\": partition_id, \"accuracy\": 0.95}\n\n\ndef main():\n    with open_dagster_pipes() as context:\n        context.log.info(\"Starting distributed ML training\")\n\n        # Get configuration from Dagster\n        num_partitions = context.get_extra(\"num_partitions\", 4)\n\n        # Submit training jobs\n        futures = [train_ml_model.remote(i) for i in range(num_partitions)]\n        results = ray.get(futures)\n\n        context.log.info(f\"Training complete on {len(results)} partitions\")\n\n        # Report results\n        context.report_asset_materialization(\n            metadata={\"num_partitions\": len(results), \"results\": results},\n            data_version=\"alpha\",\n        )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorial/external/#dagster-asset-using-pipes","title":"Dagster Asset Using Pipes","text":"<p>Now, let's define a Dagster asset that will be calling the above external script via Dagster Pipes.</p> <pre><code>import dagster as dg\nfrom dagster_ray import PipesRayJobClient\nfrom ray.job_submission import JobSubmissionClient\n\n\nclass MLTrainingConfig(dg.Config):\n    num_partitions: int = 4\n\n\n@dg.asset\ndef distributed_ml_training(\n    context: dg.AssetExecutionContext,\n    ray_client: PipesRayJobClient,\n    config: MLTrainingConfig,\n) -&gt; dict:\n    \"\"\"Run distributed ML training using Ray Pipes.\"\"\"\n\n    return ray_client.run(\n        context=context,\n        submit_job_params={\n            \"entrypoint\": \"python ml_training.py\",\n            \"runtime_env\": {\n                \"pip\": [\"dagster-pipes\", \"torch\"],  # (1)!\n            },\n        },\n        extras={\n            \"num_partitions\": config.num_partitions,\n        },\n    )\n\n\ndefinitions = dg.Definitions(\n    assets=[distributed_ml_training],\n    resources={\n        \"ray_client\": PipesRayJobClient(\n            client=JobSubmissionClient(),\n            timeout=1800,\n        )\n    },\n)\n</code></pre> <ol> <li> <code>dagster-pipes</code> have to be installed in the remote environment!</li> </ol> <p>When materializing the asset, the <code>PipesRayJobClient</code> will submit the script as a Ray job, monitor its status, and stream back logs and Dagster metadata.</p>"},{"location":"tutorial/external/#conclusion","title":"Conclusion","text":"<p>That's it! You now have a comprehensive understanding of how to use dagster-ray with external Ray clusters, from local development with <code>LocalRay</code> to production deployments with <code>PipesRayJobClient</code>.</p>"},{"location":"tutorial/kuberay/","title":"Dagster + KubeRay","text":"<p>This tutorial shows how to use dagster-ray with KubeRay to automatically manage Ray clusters on Kubernetes. KubeRay integration allows you to create and manage Ray clusters directly from your Dagster pipelines without manual cluster management.</p>"},{"location":"tutorial/kuberay/#prerequisites","title":"Prerequisites","text":"<p>Before getting started, you'll need:</p> <ul> <li>A Kubernetes cluster with KubeRay Operator installed</li> <li>A <code>kubectl</code> configured to access your cluster or a kubeconfig file (resources can be configured to use it)</li> <li>dagster-ray installed with KubeRay support:   <pre><code>pip install 'dagster-ray[kuberay]'\n</code></pre></li> </ul>"},{"location":"tutorial/kuberay/#kuberayinteractivejob","title":"KubeRayInteractiveJob","text":"<p><code>KubeRayInteractiveJob</code> is the recommended way to run Ray workloads with automatic cluster management. It creates a <code>RayJob</code>, connects to it in client mode and sets the <code>jobId</code> field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.</p> <p>Warning</p> <p>KubeRay Operator 1.3.0 is required for this feature.</p>"},{"location":"tutorial/kuberay/#basic-example","title":"Basic Example","text":"<p>Here's a simple example that creates a Ray cluster and runs distributed computation:</p> <pre><code>import dagster as dg\nfrom dagster_ray.kuberay import KubeRayInteractiveJob, RayResource\nimport ray\n\n\n@ray.remote\ndef compute_pi_slice(start: int, num_samples: int) -&gt; int:\n    \"\"\"Compute a slice of pi using Monte Carlo method.\"\"\"\n    import random\n\n    count = 0\n    for _ in range(num_samples):\n        x, y = random.random(), random.random()\n        if x * x + y * y &lt;= 1:\n            count += 1\n    return count\n\n\n@dg.asset\ndef estimate_pi(ray_cluster: RayResource) -&gt; float:\n    \"\"\"Estimate pi using distributed Ray computation.\"\"\"\n    num_samples = 10_000_000\n    num_workers = 10\n    samples_per_worker = num_samples // num_workers\n\n    # Submit work to Ray cluster\n    futures = [\n        compute_pi_slice.remote(i * samples_per_worker, samples_per_worker)\n        for i in range(num_workers)\n    ]\n\n    # Collect results\n    total_inside = sum(ray.get(futures))\n    pi_estimate = 4 * total_inside / num_samples\n\n    return pi_estimate\n\n\ndefinitions = dg.Definitions(\n    assets=[estimate_pi], resources={\"ray_cluster\": KubeRayInteractiveJob()}\n)\n</code></pre> <p>Note</p> <p><code>RayResource</code> is the common interface for all <code>dagster-ray</code> Ray resource which can be used as backend-agnostic type annotation</p> <p>By default, the image will be inherited from the <code>dagster/image</code> Run tag. Alternatively, you can specify it using the <code>image</code> parameter.</p> <p><code>RayJob</code>'s <code>.metadata.name</code> will be generated automatically if not provided.</p>"},{"location":"tutorial/kuberay/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can customize the Ray cluster configuration:</p> <pre><code>from dagster_ray.kuberay import KubeRayInteractiveJob\nfrom dagster_ray.kuberay.configs import RayJobConfig, RayJobSpec, RayClusterSpec\n\nray_cluster = KubeRayInteractiveJob(\n    ray_job=RayJobConfig(\n        metadata={\n            \"namespace\": \"my-custom-namespace\",\n            \"labels\": {\"team\": \"my-team\"},\n            \"annotations\": {\"example\": \"annotation\"},\n        },\n        spec=RayJobSpec(\n            ttl_seconds_after_finished=3600,\n            deletion_strategy={\n                \"onSuccess\": {\"policy\": \"DeleteSelf\"},\n                \"onFailure\": {\"policy\": \"DeleteSelf\"},\n            },\n            ray_cluster_spec=RayClusterSpec(\n                worker_group_specs=[\n                    {\n                        \"groupName\": \"workers\",\n                        \"replicas\": 0,\n                        \"minReplicas\": 0,\n                        \"maxReplicas\": 10,\n                        \"rayStartParams\": {},\n                        \"template\": {\n                            \"metadata\": {\"labels\": {}, \"annotations\": {}},\n                            \"spec\": {\n                                \"imagePullSecrets\": [],\n                                \"containers\": [\n                                    {\n                                        \"volumeMounts\": [],\n                                        \"name\": \"worker\",\n                                        \"imagePullPolicy\": \"Always\",\n                                    }\n                                ],\n                                \"volumes\": [],\n                                \"affinity\": {},\n                                \"tolerations\": [],\n                                \"nodeSelector\": {},\n                            },\n                        },\n                    }\n                ]\n            ),\n        ),\n    ),\n    lifecycle=Lifecycle(cleanup=\"always\"),\n    timeout=600.0,\n)\n</code></pre>"},{"location":"tutorial/kuberay/#kuberaycluster-alternative","title":"KubeRayCluster Alternative","text":"<p>While <code>KubeRayInteractiveJob</code> is recommended for most use cases, you can also use <code>KubeRayCluster</code> for more persistent clusters:</p> <pre><code>from dagster_ray.kuberay import KubeRayCluster\nfrom dagster_ray.kuberay.configs import RayClusterConfig\n\n# KubeRayCluster creates a persistent RayCluster CR\nray_cluster = KubeRayCluster(\n    ray_cluster=RayClusterConfig(\n        # Cluster configuration\n        metadata={\"name\": \"my-persistent-cluster\"},\n    )\n)\n</code></pre> <p>Note</p> <p><code>KubeRayCluster</code> is generally a weaker alternative to <code>KubeRayInteractiveJob</code> because:</p> <ul> <li>It creates persistent clusters that may not get cleaned up properly, for example if something happens to the Dagster pod</li> <li>It lacks <code>RayJob</code>'s features such as timeouts and existing cluster selection</li> </ul>"},{"location":"tutorial/kuberay/#pipeskuberayjobclient","title":"PipesKubeRayJobClient","text":"<p><code>PipesKubeRayJobClient</code> allows you to submit external Python scripts as Ray jobs with automatic cluster management. This is ideal when you want to decouple your Ray workload from your Dagster orchestration code or Python environment.</p>"},{"location":"tutorial/kuberay/#basic-pipes-example","title":"Basic Pipes Example","text":"<p>First, create a Ray script that will run on the cluster:</p> ray_workload.py<pre><code># ml_training.py - External Ray script\nimport ray\nfrom dagster_pipes import open_dagster_pipes\n\n\n@ray.remote\ndef train_ml_model(partition_id: int):\n    \"\"\"Dummy ML training function.\"\"\"\n    import time\n\n    time.sleep(1)  # Simulate work\n    return {\"partition_id\": partition_id, \"accuracy\": 0.95}\n\n\ndef main():\n    with open_dagster_pipes() as context:\n        context.log.info(\"Starting distributed ML training\")\n\n        # Get configuration from Dagster\n        num_partitions = context.get_extra(\"num_partitions\", 4)\n\n        # Submit training jobs\n        futures = [train_ml_model.remote(i) for i in range(num_partitions)]\n        results = ray.get(futures)\n\n        context.log.info(f\"Training complete on {len(results)} partitions\")\n\n        # Report results\n        context.report_asset_materialization(\n            metadata={\"num_partitions\": len(results), \"results\": results},\n            data_version=\"alpha\",\n        )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Now create a Dagster asset that uses <code>PipesKubeRayJobClient</code>:</p> <pre><code>import dagster as dg\nfrom dagster_ray.kuberay import PipesKubeRayJobClient\n\n\nclass MLTrainingConfig(dg.Config):\n    num_partitions: int = 4\n\n\n@dg.asset\ndef distributed_computation(\n    context: dg.AssetExecutionContext,\n    ray_pipes_client: PipesKubeRayJobClient,\n) -&gt; None:\n    \"\"\"Run distributed computation using Pipes + KubeRay.\"\"\"\n\n    # Submit the external Ray script\n    return ray_pipes_client.run(\n        context=context,\n        ray_job={\n            \"entrypoint\": \"python ray_workload.py\",\n            \"runtime_env\": {\n                \"pip\": [\"dagster-pipes\", \"torch\"],  # (1)!\n            },\n            \"entrypoint_num_cpus\": 1.0,\n            \"entrypoint_memory\": 2 * 1024 * 1024 * 1024,  # 2GB\n        },\n        extras={\n            \"num_partitions\": config.num_partitions,\n        },\n    )\n\n\ndefinitions = dg.Definitions(\n    assets=[distributed_computation],\n    resources={\"ray_pipes_client\": PipesKubeRayJobClient()},\n)\n</code></pre> <ol> <li> <code>dagster-pipes</code> have to be installed in the remote environment!</li> </ol> <p>When materializing the asset, the <code>PipesKubeRayJobClient</code> will submit the script as a <code>RayJob</code> custom resource, monitor its status, and stream back logs and Dagster metadata.</p>"}]}