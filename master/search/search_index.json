{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to <code>dagster-ray</code> docs","text":"<p>Ray integration for Dagster.</p> <p><code>dagster-ray</code> enables working with distributed Ray compute from Dagster pipelines, combining Dagster's excellent orchestration capabilities and Ray's distributed computing power together.</p> <p>Note</p> <p>This project is ready for production use, but some APIs may change between minor releases.</p>"},{"location":"#key-features","title":"\ud83d\ude80 Key Features","text":"<ul> <li>\ud83c\udfaf Run Launchers &amp; Executors: Submit Dagster runs or individual steps by submitting Ray jobs</li> <li>\ud83d\udd27 Ray Resources: Automatically create and destroy ephemeral Ray clusters and connect to them in client mode</li> <li>\ud83d\udce1 Dagster Pipes Integration: Submit external scripts as Ray jobs, stream back logs and rich Dagster metadata</li> <li>\u2638\ufe0f KubeRay Support: Utilize <code>RayJob</code> and <code>RayCluster</code> custom resources in client or job submission mode (tutorial)</li> <li>\ud83c\udfed Production Ready: Tested against a matrix of core dependencies, integrated with Dagster+</li> <li>\u26a1 Instant Startup: Leverage <code>RayCluster</code> with Cluster Sharing for lightning-fast development cycles with zero cold start times (intended for development environments)</li> </ul>"},{"location":"#quick-start","title":"\u26a1 Quick Start","text":""},{"location":"#installation","title":"Installation","text":"BasicWith KubeRay <pre><code>pip install dagster-ray\n</code></pre> <p>Tip</p> <p>See external cluster tutorial</p> <pre><code>pip install 'dagster-ray[kuberay]'\n</code></pre> <p>Tip</p> <p>See KubeRay tutorial</p>"},{"location":"#basic-usage","title":"Basic Usage","text":""},{"location":"#execute-dagster-steps-on-an-existing-ray-cluster","title":"Execute Dagster steps on an existing Ray cluster","text":"<p>Example</p> <pre><code>import dagster as dg\nfrom dagster_ray import ray_executor\n\ndefs = dg.Definitions(..., executor=ray_executor)\n</code></pre>"},{"location":"#execute-an-asset-on-ray-in-client-mode","title":"Execute an asset on Ray in client mode","text":"<p>Example</p> <p>Define a Dagster asset that uses Ray in client mode <pre><code>import dagster as dg\nfrom dagster_ray import RayResource\nimport ray\n\n\n@ray.remote\ndef compute_square(x: int) -&gt; int:\n    return x**2\n\n\n@dg.asset\ndef my_distributed_computation(ray_cluster: RayResource) -&gt; int:  # (2)!\n    futures = [compute_square.remote(i) for i in range(10)]  # (1)!\n    return sum(ray.get(futures))\n</code></pre></p> <ol> <li> I am already running in Ray!</li> <li> <code>RayResource</code> is a type annotation that provides a common interface for Ray resources</li> </ol> <p>Now use <code>LocalRay</code> for development and swap it with a thick cluster in Kubernetes!</p> <pre><code>from dagster_ray import LocalRay\nfrom dagster_ray.kuberay import in_k8s, KubeRayInteractiveJob\n\nray_cluster = LocalRay() if not in_k8s else KubeRayInteractiveJob()\n\ndefinitions = dg.Definitions(\n    assets=[my_distributed_computation],\n    resources={\"ray_cluster\": ray_cluster},\n)\n</code></pre> <p><code>KubeRayInteractiveJob</code> will create a <code>RayJob</code>, connect to it, and optionally perform cleanup according to the configured policy.</p> <p>Learn more by reading the tutorials.</p>"},{"location":"#choosing-your-integration","title":"\ud83d\udee0\ufe0f Choosing Your Integration","text":"<p><code>dagster-ray</code> offers multiple ways to integrate Ray with your Dagster pipelines. The right choice depends on your deployment setup and use case:</p>"},{"location":"#key-questions-to-consider","title":"\ud83e\udd14 Key Questions to Consider","text":"<ul> <li>Do you want to manage Ray clusters automatically? If yes, use KubeRay components</li> <li>Do you prefer to submit external scripts or run code directly? External scripts offer better separation of concerns and environments, but interactive code is more convenient</li> <li>Do you need per-asset configuration? Some components allow fine-grained control per asset</li> </ul>"},{"location":"#feature-comparison","title":"\ud83d\udcca Feature Comparison","text":"Feature <code>RayRunLauncher</code> <code>ray_executor</code> <code>PipesRayJobClient</code> <code>PipesKubeRayJobClient</code> <code>KubeRayCluster</code> <code>KubeRayInteractiveJob</code> Manages the cluster \u274c \u274c \u274c \u2705 \u2705 \u2705 Uses Ray Jobs API \u2705 \u2705 \u2705 \u2705 \u274c \u274c Enabled per-asset \u274c \u274c \u2705 \u2705 \u2705 \u2705 Configurable per-asset \u274c \u2705 \u2705 \u2705 \u2705 \u2705 No external script needed \u2705 \u2705 \u274c \u274c \u2705 \u2705 No Dagster DB access needed \u274c \u274c \u2705 \u2705 \u2705 \u2705"},{"location":"#which-one-should-you-use","title":"\ud83c\udfaf Which One Should You Use?","text":"\ud83c\udfe2 External Ray Cluster\u2638\ufe0f Dagster-owned Ray Cluster (KubeRay) <p>You have a Ray cluster already running</p> <ul> <li>Use <code>RayRunLauncher</code> to run the entire Dagster deployment on Ray</li> <li>Use <code>ray_executor</code> to run specific jobs on Ray</li> <li>Use <code>PipesRayJobClient</code> to submit external Python scripts as Ray jobs</li> </ul> <p>Tip</p> <p>See external cluster tutorial</p> <p>You want <code>dagster-ray</code> to handle cluster lifecycle</p> <p><code>dagster-ray</code> supports running Ray on Kubernetes with KubeRay.</p> <ul> <li>Use <code>KubeRayInteractiveJob</code> to create a <code>RayJob</code> and connect in client mode (recommended for production)</li> <li>Use <code>KubeRayCluster</code> with cluster sharing enabled to create a new <code>RayCluster</code> or immediately connect to an existing one (recommended for dev environments)</li> <li>Use <code>PipesKubeRayJobClient</code> to submit external scripts as <code>RayJob</code></li> </ul> <p>Tip</p> <p>See KubeRay tutorial</p>"},{"location":"#whats-next","title":"\ud83d\udcda What's Next?","text":"<ul> <li> <p> Tutorial</p> <p>Step-by-step guide with practical examples to get you started with <code>dagster-ray</code></p> </li> <li> <p> API Reference</p> <p>Complete documentation of all classes, methods, and configuration options</p> </li> </ul>"},{"location":"api/","title":"API Reference","text":"<p>Complete API documentation for <code>dagster-ray</code> components, organized by functionality. Learn how to use <code>dagster-ray</code> here.</p>"},{"location":"api/#key-components","title":"Key Components","text":""},{"location":"api/#core","title":"Core","text":"<ul> <li>RayResource</li> <li>LocalRay</li> <li>RayRunLauncher</li> <li>ray_executor</li> <li>PipesRayJobClient</li> <li>PipesRayJobMessageReader</li> <li>RayIOManager</li> </ul>"},{"location":"api/#kuberay","title":"KubeRay","text":"<ul> <li>KubeRayInteractiveJob</li> <li>PipesKubeRayJobClient</li> </ul>"},{"location":"api/#configs","title":"Configs","text":"<ul> <li>Lifecycle</li> <li>RayDataExecutionOptions</li> <li>ExecutionOptionsConfig</li> </ul>"},{"location":"api/#types","title":"Types","text":"<ul> <li>AnyDagsterContext</li> <li>OpOrAssetExecutionContext</li> </ul>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable user-facing changes to <code>dagster-ray</code> will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li><code>worker_process_setup_hook</code> parameter of <code>RuntimeEnv</code> is now supported (only as a string module path)</li> </ul>"},{"location":"changelog/#fixes","title":"Fixes","text":"<ul> <li>fixed <code>env_vars</code> not being used by <code>KubeRayInteractiveJob</code></li> </ul>"},{"location":"changelog/#041","title":"0.4.1","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li><code>RayCluster</code>'s head pod logs are now displayed on startup timeout or failure</li> </ul>"},{"location":"changelog/#fixes_1","title":"Fixes","text":"<ul> <li>Prevent the <code>RayCluster</code> cleanup sensor from targeting clusters with <code>.metadata.ownerReferences</code> set.</li> <li><code>address</code> config value can now be omitted for <code>ray_executor</code>, making it use Ray's default cluster address resolution. Thanks @cornettew!</li> <li>Fixed race condition with cluster sharing: previously multiple steps running in parallel could create different <code>RayCluster</code> instances at the same time (that were supposed to be shared). <code>dagster-ray</code> now uses Kubernetes Lease-based leader election to coordinate shared cluster creation, which guarantees that only one of the running steps creates the shared <code>RayCluster</code>.</li> <li><code>runtimeEnvYAML</code> now has all strings fully quoted which fixes passing values such as <code>1e-5</code> as <code>runtime_env</code> values. Thanks @JosefNagelschmidt!</li> <li><code>ray_address</code> is now optional for <code>RunLauncherConfig</code>. Thanks @cornettew!</li> </ul>"},{"location":"changelog/#040","title":"0.4.0","text":"<p>This release introduces a new feature that is very useful in dev environments: Cluster Sharing. Cluster sharing allows reusing existing <code>RayCluster</code> resources created by previous Dagster steps. It's implemented for <code>KubeRayCluster</code> Dagster resource. This feature enables faster iteration speed and reduced infrastructure costs (at the expense of job isolation). Therefore <code>KubeRayCluster</code> is now recommended over <code>KubeRayInteractiveJob</code> for use in dev environments.</p> <p>Learn more in Cluster Sharing docs.</p>"},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li><code>KubeRayCluster.cluster_sharing</code> parameter that controls cluster sharing behavior.</li> <li><code>dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters</code> sensor that cleans up expired clusters (both shared and non-shared). Learn more in docs.</li> <li><code>dagster-ray</code> entry now appears in the Dagster libraries list in the web UI.</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>[ breaking] - removed <code>cleanup_kuberay_clusters_op</code> and other associated definitions in favor of <code>dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters</code> sensor that is more flexible.</li> </ul>"},{"location":"changelog/#031","title":"0.3.1","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li><code>failure_tolerance_timeout</code> configuration parameter for <code>KubeRayInteractiveJob</code> and <code>KubeRayCluster</code>. It can be set to a positive value to give the cluster some time to transition out of <code>failed</code> state (which can be transient in some scenarios) before raising an error.</li> </ul>"},{"location":"changelog/#fixes_2","title":"Fixes","text":"<ul> <li>ensure both <code>.head.serviceIP</code> and <code>.head.serviceName</code> are set on the <code>RayCluster</code> while waiting for cluster readiness.</li> </ul>"},{"location":"changelog/#030","title":"0.3.0","text":"<p>This release includes massive docs improvements and drops support for Python 3.9.</p>"},{"location":"changelog/#changes","title":"Changes","text":"<ul> <li>[ breaking] dropped Python 3.9 support (EOL October 2025).</li> <li>[internal] most of the general, backend-agnostic code has been moved to <code>dagster_ray.core</code> (top-level imports still work).</li> </ul>"},{"location":"changelog/#021","title":"0.2.1","text":""},{"location":"changelog/#fixes_3","title":"Fixes","text":"<ul> <li>Fixed broken wheel on PyPI.</li> </ul>"},{"location":"changelog/#020","title":"0.2.0","text":""},{"location":"changelog/#changed_1","title":"Changed","text":"<ul> <li><code>KubeRayInteractiveJob.deletion_strategy</code> now defaults to <code>DeleteCluster</code> for both successful and failed executions. This is a reasonable default for the use case.</li> <li><code>KubeRayInteractiveJob.ttl_seconds_after_finished</code> now defaults to <code>600</code> seconds.</li> <li><code>KubeRayCluster.lifecycle.cleanup</code> now defaults to <code>always</code>.</li> <li>[ breaking] <code>RayJob</code> and <code>RayCluster</code> clients and resources Kubernetes init parameters have been renamed to <code>kube_config</code> and <code>kube_context</code>.</li> </ul>"},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li><code>enable_legacy_debugger</code> configuration parameter to subclasses of <code>RayResource</code></li> <li><code>on_exception</code> option for <code>lifecycle.cleanup</code> policy. It's triggered during resource setup/cleanup (including <code>KeyboardInterrupt</code>), but not by user <code>@op</code>/<code>@asset</code> code.</li> <li><code>KubeRayInteractiveJob</code> now respects <code>lifecycle.cleanup</code>. It defaults to <code>on_exception</code>. Users are advised to rely on built-in <code>RayJob</code> cleanup mechanisms, such as <code>ttlSecondsAfterFinished</code> and <code>deletionStrategy</code>.</li> </ul>"},{"location":"changelog/#fixes_4","title":"Fixes","text":"<ul> <li>removed <code>ignore_reinit_error</code> from <code>RayResource</code> init options: it's potentially dangerous, for example in case the user has accidentally connected to another Ray cluster (including local ray) before initializing the resource.</li> </ul>"},{"location":"changelog/#010","title":"0.1.0","text":""},{"location":"changelog/#changed_2","title":"Changed","text":"<ul> <li>[ breaking] <code>RayResource</code>: top-level <code>skip_init</code> and <code>skip_setup</code> configuration parameters have been removed. The <code>lifecycle</code> field is the new way of configuring steps performed during resource initialization. <code>KubeRayCluster</code>'s <code>skip_cleanup</code> has been moved to <code>lifecycle</code> as well.</li> <li>[ breaking] injected <code>dagster.io/run_id</code> Kubernetes label has been renamed to <code>dagster/run-id</code>. Keys starting with <code>dagster.io/</code> have been converted to <code>dagster/</code> to match how <code>dagster-k8s</code> does it.</li> <li>[ breaking] <code>dagster_ray.kuberay</code> Configurations have been unified with KubeRay APIs.</li> <li><code>dagster-ray</code> now populates Kubernetes labels with more values (including some useful Dagster Cloud values such as <code>git-sha</code>).</li> </ul>"},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li><code>KubeRayInteractiveJob</code> -- a resource that utilizes the new <code>InteractiveMode</code> for <code>RayJob</code>. It can be used to connect to Ray in Client mode -- like <code>KubeRayCluster</code> -- but gives access to <code>RayJob</code> features, such as automatic cleanup (<code>ttlSecondsAfterFinished</code>), retries (<code>backoffLimit</code>) and timeouts (<code>activeDeadlineSeconds</code>).</li> <li><code>RayResource</code> setup lifecycle has been overhauled: resources now has an <code>actions</code> parameter with 3 configuration options: <code>create</code>, <code>wait</code> and <code>connect</code>. The user can disable them and run <code>.create()</code>, <code>.wait()</code> and <code>.connect()</code> manually if needed.</li> </ul>"},{"location":"api/configs/","title":"Configuration API Reference","text":"<p>Configuration classes for Ray execution and data processing options.</p>"},{"location":"api/configs/#dagster_ray.configs.Lifecycle","title":"dagster_ray.configs.Lifecycle  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"create\": {\n      \"default\": true,\n      \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n      \"title\": \"Create\",\n      \"type\": \"boolean\"\n    },\n    \"wait\": {\n      \"default\": true,\n      \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n      \"title\": \"Wait\",\n      \"type\": \"boolean\"\n    },\n    \"connect\": {\n      \"default\": true,\n      \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n      \"title\": \"Connect\",\n      \"type\": \"boolean\"\n    },\n    \"cleanup\": {\n      \"default\": \"always\",\n      \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n      \"enum\": [\n        \"never\",\n        \"always\",\n        \"on_exception\"\n      ],\n      \"title\": \"Cleanup\",\n      \"type\": \"string\"\n    }\n  },\n  \"title\": \"Lifecycle\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>create</code>                 (<code>bool</code>)             </li> <li> <code>wait</code>                 (<code>bool</code>)             </li> <li> <code>connect</code>                 (<code>bool</code>)             </li> <li> <code>cleanup</code>                 (<code>Literal['never', 'always', 'on_exception']</code>)             </li> </ul>"},{"location":"api/configs/#dagster_ray.configs.Lifecycle-attributes","title":"Attributes","text":""},{"location":"api/configs/#dagster_ray.configs.Lifecycle.create","title":"create  <code>pydantic-field</code>","text":"<pre><code>create: bool = True\n</code></pre> <p>Whether to create the resource. If set to <code>False</code>, the user can manually call <code>.create</code> instead.</p>"},{"location":"api/configs/#dagster_ray.configs.Lifecycle.wait","title":"wait  <code>pydantic-field</code>","text":"<pre><code>wait: bool = True\n</code></pre> <p>Whether to wait for the remote Ray cluster to become ready to accept connections. If set to <code>False</code>, the user can manually call <code>.wait</code> instead.</p>"},{"location":"api/configs/#dagster_ray.configs.Lifecycle.connect","title":"connect  <code>pydantic-field</code>","text":"<pre><code>connect: bool = True\n</code></pre> <p>Whether to run <code>ray.init</code> against the remote Ray cluster. If set to <code>False</code>, the user can manually call <code>.connect</code> instead.</p>"},{"location":"api/configs/#dagster_ray.configs.Lifecycle.cleanup","title":"cleanup  <code>pydantic-field</code>","text":"<pre><code>cleanup: Literal['never', 'always', 'on_exception'] = 'always'\n</code></pre> <p>Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.</p>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions","title":"dagster_ray.configs.RayDataExecutionOptions  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"execution_options\": {\n      \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n    },\n    \"cpu_limit\": {\n      \"default\": 5000,\n      \"title\": \"Cpu Limit\",\n      \"type\": \"integer\"\n    },\n    \"gpu_limit\": {\n      \"default\": 0,\n      \"title\": \"Gpu Limit\",\n      \"type\": \"integer\"\n    },\n    \"verbose_progress\": {\n      \"default\": true,\n      \"title\": \"Verbose Progress\",\n      \"type\": \"boolean\"\n    },\n    \"use_polars\": {\n      \"default\": true,\n      \"title\": \"Use Polars\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"RayDataExecutionOptions\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>execution_options</code>                 (<code>ExecutionOptionsConfig</code>)             </li> <li> <code>cpu_limit</code>                 (<code>int</code>)             </li> <li> <code>gpu_limit</code>                 (<code>int</code>)             </li> <li> <code>verbose_progress</code>                 (<code>bool</code>)             </li> <li> <code>use_polars</code>                 (<code>bool</code>)             </li> </ul>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions-attributes","title":"Attributes","text":""},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.execution_options","title":"execution_options  <code>pydantic-field</code>","text":"<pre><code>execution_options: ExecutionOptionsConfig\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.cpu_limit","title":"cpu_limit  <code>pydantic-field</code>","text":"<pre><code>cpu_limit: int = 5000\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.gpu_limit","title":"gpu_limit  <code>pydantic-field</code>","text":"<pre><code>gpu_limit: int = 0\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.verbose_progress","title":"verbose_progress  <code>pydantic-field</code>","text":"<pre><code>verbose_progress: bool = True\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.use_polars","title":"use_polars  <code>pydantic-field</code>","text":"<pre><code>use_polars: bool = True\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions-functions","title":"Functions","text":""},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.apply","title":"apply","text":"<pre><code>apply()\n</code></pre> Source code in <code>src/dagster_ray/configs.py</code> <pre><code>def apply(self):\n    import ray\n    from ray.data import ExecutionResources\n\n    ctx = ray.data.DatasetContext.get_current()\n\n    ctx.execution_options.resource_limits = ExecutionResources.for_limits(\n        cpu=self.execution_options.cpu,\n        gpu=self.execution_options.gpu,\n        object_store_memory=self.execution_options.object_store_memory,\n    )\n\n    ctx.verbose_progress = self.verbose_progress\n    ctx.use_polars = self.use_polars\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.RayDataExecutionOptions.apply_remote","title":"apply_remote","text":"<pre><code>apply_remote()\n</code></pre> Source code in <code>src/dagster_ray/configs.py</code> <pre><code>def apply_remote(self):\n    import ray\n\n    @ray.remote\n    def apply():\n        self.apply()\n\n    ray.get(apply.remote())\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.ExecutionOptionsConfig","title":"dagster_ray.configs.ExecutionOptionsConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"cpu\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Cpu\"\n    },\n    \"gpu\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Gpu\"\n    },\n    \"object_store_memory\": {\n      \"anyOf\": [\n        {\n          \"type\": \"integer\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Object Store Memory\"\n    }\n  },\n  \"title\": \"ExecutionOptionsConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>cpu</code>                 (<code>int | None</code>)             </li> <li> <code>gpu</code>                 (<code>int | None</code>)             </li> <li> <code>object_store_memory</code>                 (<code>int | None</code>)             </li> </ul>"},{"location":"api/configs/#dagster_ray.configs.ExecutionOptionsConfig-attributes","title":"Attributes","text":""},{"location":"api/configs/#dagster_ray.configs.ExecutionOptionsConfig.cpu","title":"cpu  <code>pydantic-field</code>","text":"<pre><code>cpu: int | None = None\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.ExecutionOptionsConfig.gpu","title":"gpu  <code>pydantic-field</code>","text":"<pre><code>gpu: int | None = None\n</code></pre>"},{"location":"api/configs/#dagster_ray.configs.ExecutionOptionsConfig.object_store_memory","title":"object_store_memory  <code>pydantic-field</code>","text":"<pre><code>object_store_memory: int | None = None\n</code></pre>"},{"location":"api/core/","title":"Core API Reference","text":"<p>Core <code>dagster-ray</code> APIs for using external Ray clusters. Learn how to use it here.</p>"},{"location":"api/core/#ray-resources","title":"Ray Resources","text":"<p><code>RayResource</code> can be used to connect to external Ray clusters when provided as a Dagster resource, or as a type annotation (all other Ray resources in <code>dagster-ray</code> inherit from <code>RayResource</code>)</p> <p>The <code>LocalRay</code> can be used to connect to a local Ray cluster.</p>"},{"location":"api/core/#dagster_ray.RayResource","title":"dagster_ray.RayResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource</code>, <code>ABC</code></p> <p>Base class for Ray Resources providing a common interface for Ray cluster management.</p> <p>This abstract base class defines the interface that all Ray resources must implement, providing a backend-agnostic way to interact with Ray clusters. Concrete implementations include LocalRay for local development and KubeRay resources for Kubernetes deployments.</p> <p>The RayResource handles the lifecycle of Ray clusters including creation, connection, and cleanup, with configurable policies for each stage.</p> Example <p>Use as a type annotation for backend-agnostic code <pre><code>import dagster as dg\nfrom dagster_ray import RayResource\n\n@dg.asset\ndef my_asset(ray_cluster: RayResource):\n    # Works with any Ray backend\n    import ray\n    return ray.get(ray.put(\"hello\"))\n</code></pre></p> Example <p>Manual lifecycle management <pre><code>from dagster_ray import Lifecycle\n\nray_resource = SomeRayResource(\n    lifecycle=Lifecycle(\n        create=False,  # Don't auto-create\n        connect=False  # Don't auto-connect\n    )\n)\n</code></pre></p> Note <p>This is an abstract class and cannot be instantiated directly. Use concrete implementations like LocalRay or KubeRayCluster instead.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Base class for Ray Resources providing a common interface for Ray cluster management.\\n\\nThis abstract base class defines the interface that all Ray resources must implement,\\nproviding a backend-agnostic way to interact with Ray clusters. Concrete implementations\\ninclude LocalRay for local development and KubeRay resources for Kubernetes deployments.\\n\\nThe RayResource handles the lifecycle of Ray clusters including creation, connection,\\nand cleanup, with configurable policies for each stage.\\n\\nExample:\\n    Use as a type annotation for backend-agnostic code\\n    ```python\\n    import dagster as dg\\n    from dagster_ray import RayResource\\n\\n    @dg.asset\\n    def my_asset(ray_cluster: RayResource):\\n        # Works with any Ray backend\\n        import ray\\n        return ray.get(ray.put(\\\"hello\\\"))\\n    ```\\n\\nExample:\\n    Manual lifecycle management\\n    ```python\\n    from dagster_ray import Lifecycle\\n\\n    ray_resource = SomeRayResource(\\n        lifecycle=Lifecycle(\\n            create=False,  # Don't auto-create\\n            connect=False  # Don't auto-connect\\n        )\\n    )\\n    ```\\n\\nNote:\\n    This is an abstract class and cannot be instantiated directly. Use concrete\\n    implementations like LocalRay or KubeRayCluster instead.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline)\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html)\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger)\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"worker_process_setup_hook\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.runtime_env.RuntimeEnv.html).\",\n      \"title\": \"Worker Process Setup Hook\"\n    }\n  },\n  \"title\": \"RayResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>worker_process_setup_hook</code>                 (<code>str | None</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>_creation_verb</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.RayResource-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.RayResource.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/core/#dagster_ray.RayResource.timeout","title":"timeout  <code>pydantic-field</code>","text":"<pre><code>timeout: float = 600.0\n</code></pre> <p>Timeout for Ray readiness in seconds</p>"},{"location":"api/core/#dagster_ray.RayResource.ray_init_options","title":"ray_init_options  <code>pydantic-field</code>","text":"<pre><code>ray_init_options: dict[str, Any]\n</code></pre> <p>Additional keyword arguments to pass to <code>ray.init()</code> call, such as <code>runtime_env</code>, <code>num_cpus</code>, etc. Dagster's <code>EnvVar</code> is supported. More details in Ray docs.</p>"},{"location":"api/core/#dagster_ray.RayResource.data_execution_options","title":"data_execution_options  <code>pydantic-field</code>","text":"<pre><code>data_execution_options: RayDataExecutionOptions\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.redis_port","title":"redis_port  <code>pydantic-field</code>","text":"<pre><code>redis_port: int = 10001\n</code></pre> <p>Redis port for connection. Make sure to match with the actual available port.</p>"},{"location":"api/core/#dagster_ray.RayResource.dashboard_port","title":"dashboard_port  <code>pydantic-field</code>","text":"<pre><code>dashboard_port: int = 8265\n</code></pre> <p>Dashboard port for connection. Make sure to match with the actual available port.</p>"},{"location":"api/core/#dagster_ray.RayResource.env_vars","title":"env_vars  <code>pydantic-field</code>","text":"<pre><code>env_vars: dict[str, str] | None\n</code></pre> <p>Environment variables to pass to the Ray cluster.</p>"},{"location":"api/core/#dagster_ray.RayResource.enable_tracing","title":"enable_tracing  <code>pydantic-field</code>","text":"<pre><code>enable_tracing: bool = False\n</code></pre> <p>Enable tracing: inject <code>RAY_PROFILING=1</code> and <code>RAY_task_events_report_interval_ms=0</code> into the Ray cluster configuration. This allows using <code>ray.timeline()</code> to fetch recorded task events. Learn more: KubeRay docs</p>"},{"location":"api/core/#dagster_ray.RayResource.enable_actor_task_logging","title":"enable_actor_task_logging  <code>pydantic-field</code>","text":"<pre><code>enable_actor_task_logging: bool = False\n</code></pre> <p>Enable actor task logging: inject <code>RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1</code> into the Ray cluster configuration.</p>"},{"location":"api/core/#dagster_ray.RayResource.enable_debug_post_mortem","title":"enable_debug_post_mortem  <code>pydantic-field</code>","text":"<pre><code>enable_debug_post_mortem: bool = False\n</code></pre> <p>Enable post-mortem debugging: inject <code>RAY_DEBUG_POST_MORTEM=1</code> into the Ray cluster configuration. Learn more: KubeRay docs</p>"},{"location":"api/core/#dagster_ray.RayResource.enable_legacy_debugger","title":"enable_legacy_debugger  <code>pydantic-field</code>","text":"<pre><code>enable_legacy_debugger: bool = False\n</code></pre> <p>Enable legacy debugger: inject <code>RAY_DEBUG=legacy</code> into the Ray cluster configuration. Learn more: KubeRay docs</p>"},{"location":"api/core/#dagster_ray.RayResource.worker_process_setup_hook","title":"worker_process_setup_hook  <code>pydantic-field</code>","text":"<pre><code>worker_process_setup_hook: str | None = None\n</code></pre> <p>A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in Ray docs.</p>"},{"location":"api/core/#dagster_ray.RayResource._context","title":"_context  <code>pydantic-field</code>","text":"<pre><code>_context: BaseContext | None\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource._creation_verb","title":"_creation_verb  <code>pydantic-field</code>","text":"<pre><code>_creation_verb: str = 'Created'\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.resource_uid","title":"resource_uid  <code>cached</code> <code>property</code>","text":"<pre><code>resource_uid: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.context","title":"context  <code>property</code>","text":"<pre><code>context: BaseContext\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.host","title":"host  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>host: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.name","title":"name  <code>abstractmethod</code> <code>property</code>","text":"<pre><code>name: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.display_name","title":"display_name  <code>property</code>","text":"<pre><code>display_name: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.ray_address","title":"ray_address  <code>property</code>","text":"<pre><code>ray_address: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.dashboard_url","title":"dashboard_url  <code>property</code>","text":"<pre><code>dashboard_url: str\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.runtime_job_id","title":"runtime_job_id  <code>property</code>","text":"<pre><code>runtime_job_id: str\n</code></pre> <p>Returns the Ray Job ID for the current job which was created with <code>ray.init()</code>. :return:</p>"},{"location":"api/core/#dagster_ray.RayResource.created","title":"created  <code>property</code>","text":"<pre><code>created: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.ready","title":"ready  <code>property</code>","text":"<pre><code>ready: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.connected","title":"connected  <code>property</code>","text":"<pre><code>connected: bool\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource-functions","title":"Functions","text":""},{"location":"api/core/#dagster_ray.RayResource.yield_for_execution","title":"yield_for_execution","text":"<pre><code>yield_for_execution(context: InitResourceContext) -&gt; Generator[Self, None, None]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>@contextlib.contextmanager\ndef yield_for_execution(self, context: dg.InitResourceContext) -&gt; Generator[Self, None, None]:\n    exception_occurred = None\n    try:\n        if self.lifecycle.create:\n            self._create(context)\n            if self.lifecycle.wait:\n                self._wait(context)\n                if self.lifecycle.connect:\n                    self._connect(context)\n        yield self\n    except BaseException as e:\n        exception_occurred = e\n        raise\n    finally:\n        self.cleanup(context, exception_occurred)\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource._create","title":"_create","text":"<pre><code>_create(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _create(self, context: AnyDagsterContext):\n    assert context.log is not None\n    if not self.created:\n        try:\n            self.create(context)\n            context.log.info(f\"{self._creation_verb} {self.display_name}.\")\n        except BaseException:\n            context.log.exception(f\"Failed to create {self.display_name}\")\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource._wait","title":"_wait","text":"<pre><code>_wait(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _wait(self, context: AnyDagsterContext):\n    assert context.log is not None\n    self._create(context)\n    if not self.ready:\n        context.log.info(f\"Waiting for {self.display_name} to become ready (timeout={self.timeout:.0f}s)...\")\n        try:\n            self.wait(context)\n        except BaseException:\n            context.log.exception(f\"Failed to wait for {self.display_name} readiness\")\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource._connect","title":"_connect","text":"<pre><code>_connect(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def _connect(self, context: AnyDagsterContext):\n    assert context.log is not None\n    self._wait(context)\n    if not self.connected:\n        try:\n            self.connect(context)\n        except BaseException:\n            context.log.exception(f\"Failed to connect to {self.display_name}\")\n            raise\n        context.log.info(f\"Initialized Ray Client with {self.display_name}\")\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.create","title":"create","text":"<pre><code>create(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def create(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.wait","title":"wait","text":"<pre><code>wait(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def wait(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.connect","title":"connect","text":"<pre><code>connect(context: AnyDagsterContext) -&gt; BaseContext\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>@retry(stop=stop_after_delay(120), retry=retry_if_exception_type(ConnectionError), reraise=True)\ndef connect(self, context: AnyDagsterContext) -&gt; RayBaseContext:\n    assert context.log is not None\n\n    import ray\n\n    init_options = _process_dagster_env_vars(self.ray_init_options.copy())\n\n    # cleanup None values from runtime_env.env_vars since Ray doesn't like them\n\n    if \"runtime_env\" in init_options and \"env_vars\" in init_options[\"runtime_env\"]:\n        init_options[\"runtime_env\"][\"env_vars\"] = {\n            k: v for k, v in init_options[\"runtime_env\"][\"env_vars\"].items() if v is not None\n        }\n\n    init_options[\"runtime_env\"] = init_options.get(\"runtime_env\", {})\n    init_options[\"runtime_env\"][\"env_vars\"] = init_options[\"runtime_env\"].get(\"env_vars\", {})\n\n    for var, value in self.get_env_vars_to_inject().items():\n        init_options[\"runtime_env\"][\"env_vars\"][var] = value\n\n    if self.worker_process_setup_hook is not None:\n        init_options[\"runtime_env\"][\"worker_process_setup_hook\"] = self.worker_process_setup_hook\n\n    self.data_execution_options.apply()\n\n    self._context = ray.init(\n        address=self.ray_address,\n        **init_options,\n    )\n    self.data_execution_options.apply()\n    self.data_execution_options.apply_remote()\n    context.log.info(\"Initialized Ray in client mode!\")\n    return cast(\"RayBaseContext\", self._context)\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.delete","title":"delete","text":"<pre><code>delete(context: AnyDagsterContext)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def delete(self, context: AnyDagsterContext):\n    pass\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.cleanup","title":"cleanup","text":"<pre><code>cleanup(context: AnyDagsterContext, exception: BaseException | None)\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def cleanup(self, context: AnyDagsterContext, exception: BaseException | None):  # noqa: UP007\n    assert context.log is not None\n\n    if self.lifecycle.cleanup == \"never\":\n        to_delete = False\n    elif not self.created:\n        to_delete = False\n    elif self.lifecycle.cleanup == \"always\":\n        to_delete = True\n    elif self.lifecycle.cleanup == \"on_exception\":\n        to_delete = exception is not None\n    else:\n        to_delete = False\n\n    if to_delete:\n        self.delete(context)\n        context.log.info(f'Deleted {self.display_name} according to cleanup policy \"{self.lifecycle.cleanup}\"')\n\n    if self.connected and hasattr(self, \"_context\") and self._context is not None:\n        self._context.disconnect()\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.get_dagster_tags","title":"get_dagster_tags","text":"<pre><code>get_dagster_tags(context: AnyDagsterContext) -&gt; dict[str, str]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def get_dagster_tags(self, context: AnyDagsterContext) -&gt; dict[str, str]:\n    tags = get_dagster_tags(context)\n    return tags\n</code></pre>"},{"location":"api/core/#dagster_ray.RayResource.get_env_vars_to_inject","title":"get_env_vars_to_inject","text":"<pre><code>get_env_vars_to_inject() -&gt; dict[str, str]\n</code></pre> Source code in <code>src/dagster_ray/_base/resources.py</code> <pre><code>def get_env_vars_to_inject(self) -&gt; dict[str, str]:\n    vars: dict[str, str] = self.env_vars or {}\n    if self.enable_debug_post_mortem:\n        vars[\"RAY_DEBUG_POST_MORTEM\"] = \"1\"\n    if self.enable_tracing:\n        vars[\"RAY_PROFILING\"] = \"1\"\n        vars[\"RAY_task_events_report_interval_ms\"] = \"0\"\n    if self.enable_actor_task_logging:\n        vars[\"RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING\"] = \"1\"\n    if self.enable_legacy_debugger:\n        vars[\"RAY_DEBUG\"] = \"legacy\"\n    return vars\n</code></pre>"},{"location":"api/core/#dagster_ray.core.resources.LocalRay","title":"dagster_ray.core.resources.LocalRay  <code>pydantic-model</code>","text":"<p>               Bases: <code>RayResource</code></p> <p>Dummy Resource. Is useful for testing and local development. Provides the same interface as actual Resources.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Dummy Resource.\\nIs useful for testing and local development.\\nProvides the same interface as actual Resources.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline)\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html)\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger)\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"worker_process_setup_hook\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.runtime_env.RuntimeEnv.html).\",\n      \"title\": \"Worker Process Setup Hook\"\n    }\n  },\n  \"title\": \"LocalRay\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>worker_process_setup_hook</code>                 (<code>str | None</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>_creation_verb</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/core/#dagster_ray.core.resources.LocalRay-attributes","title":"Attributes","text":""},{"location":"api/core/#dagster_ray.core.resources.LocalRay.host","title":"host  <code>property</code>","text":"<pre><code>host: str\n</code></pre>"},{"location":"api/core/#dagster_ray.core.resources.LocalRay.ray_address","title":"ray_address  <code>property</code>","text":"<pre><code>ray_address: None\n</code></pre>"},{"location":"api/core/#run-launcher","title":"Run Launcher","text":""},{"location":"api/core/#dagster_ray.core.run_launcher.RayRunLauncher","title":"dagster_ray.core.run_launcher.RayRunLauncher","text":"<pre><code>RayRunLauncher(\n    address: str,\n    metadata: dict[str, Any] | None = None,\n    headers: dict[str, Any] | None = None,\n    cookies: dict[str, Any] | None = None,\n    env_vars: list[str] | None = None,\n    runtime_env: dict[str, Any] | None = None,\n    num_cpus: int | None = None,\n    num_gpus: int | None = None,\n    memory: int | None = None,\n    resources: dict[str, float] | None = None,\n    worker_process_setup_hook: str | None = None,\n    inst_data: ConfigurableClassData | None = None,\n)\n</code></pre> <p>               Bases: <code>RunLauncher</code>, <code>ConfigurableClass</code></p> <p>RunLauncher that submits Dagster runs as isolated Ray jobs to a Ray cluster.</p> <p>Configuration can be provided via <code>dagster.yaml</code> and individual runs can override settings using the <code>dagster-ray/config</code> tag.</p> Example <p>Configure via <code>dagster.yaml</code> <pre><code>run_launcher:\n  module: dagster_ray\n  class: RayRunLauncher\n  config:\n    address: \"ray://head-node:10001\"\n    num_cpus: 2\n    num_gpus: 0\n</code></pre></p> Example <p>Override settings per job <pre><code>import dagster as dg\n\n@dg.job(\n    tags={\n        \"dagster-ray/config\": {\n            \"num_cpus\": 16,\n            \"num_gpus\": 1,\n            \"runtime_env\": {\"pip\": {\"packages\": [\"torch\"]}},\n        }\n    }\n)\ndef my_job():\n    return my_op()\n</code></pre></p> Source code in <code>src/dagster_ray/core/run_launcher.py</code> <pre><code>def __init__(\n    self,\n    address: str,\n    metadata: dict[str, Any] | None = None,\n    headers: dict[str, Any] | None = None,\n    cookies: dict[str, Any] | None = None,\n    env_vars: list[str] | None = None,\n    runtime_env: dict[str, Any] | None = None,\n    num_cpus: int | None = None,\n    num_gpus: int | None = None,\n    memory: int | None = None,\n    resources: dict[str, float] | None = None,\n    worker_process_setup_hook: str | None = None,\n    inst_data: ConfigurableClassData | None = None,\n):\n    self._inst_data = dg._check.opt_inst_param(inst_data, \"inst_data\", ConfigurableClassData)\n\n    self.address = address\n    self.metadata = metadata\n    self.headers = headers\n    self.cookies = cookies\n    self.env_vars = env_vars\n    self.runtime_env = runtime_env\n    self.num_cpus = num_cpus\n    self.num_gpus = num_gpus\n    self.memory = memory\n    self.resources = resources\n    self.worker_process_setup_hook = worker_process_setup_hook\n\n    super().__init__()\n</code></pre>"},{"location":"api/core/#dagster_ray.core.run_launcher.RayRunLauncher-functions","title":"Functions","text":""},{"location":"api/core/#executor","title":"Executor","text":""},{"location":"api/core/#dagster_ray.core.executor.ray_executor","title":"dagster_ray.core.executor.ray_executor","text":"<pre><code>ray_executor(init_context: InitExecutorContext) -&gt; Executor\n</code></pre> <p>Executes steps by submitting them as Ray jobs.</p> <p>The steps are started inside the Ray cluster directly. When used together with <code>RayRunLauncher</code>, the executor can inherit the job submission client configuration. This behavior can be disabled by setting <code>inherit_job_submission_client_from_ray_run_launcher</code> to <code>False</code>.</p> Example <p>Use <code>ray_executor</code> for the entire code location <pre><code>import dagster as dg\nfrom dagster_ray import ray_executor\n\nray_executor = ray_executor.configured(\n    {\"address\": EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n)\n\ndefs = dg.Definitions(..., executor=ray_executor])\n</code></pre></p> Example <p>Override configuration for a specific asset <pre><code>import dagster as dg\n\n@dg.asset(\n    op_tags={\"dagster-ray/config\": {\"num_cpus\": 2}}\n)\ndef my_asset(): ...\n</code></pre></p> Source code in <code>src/dagster_ray/core/executor.py</code> <pre><code>@dg.executor(\n    name=\"ray\",\n    config_schema=_RAY_EXECUTOR_CONFIG_SCHEMA,\n    requirements=multiple_process_executor_requirements(),\n)\ndef ray_executor(init_context: InitExecutorContext) -&gt; Executor:\n    \"\"\"Executes steps by submitting them as Ray jobs.\n\n    The steps are started inside the Ray cluster directly.\n    When used together with [`RayRunLauncher`][dagster_ray.core.run_launcher.RayRunLauncher], the executor can inherit the job submission client configuration.\n    This behavior can be disabled by setting `inherit_job_submission_client_from_ray_run_launcher` to `False`.\n\n    Example:\n        Use `ray_executor` for the entire code location\n        ```python\n        import dagster as dg\n        from dagster_ray import ray_executor\n\n        ray_executor = ray_executor.configured(\n            {\"address\": EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n        )\n\n        defs = dg.Definitions(..., executor=ray_executor])\n        ```\n\n    Example:\n        Override configuration for a specific asset\n        ```python\n        import dagster as dg\n\n        @dg.asset(\n            op_tags={\"dagster-ray/config\": {\"num_cpus\": 2}}\n        )\n        def my_asset(): ...\n        ```\n    \"\"\"\n    from ray.job_submission import JobSubmissionClient\n\n    exc_cfg = init_context.executor_config\n    ray_cfg = RayExecutorConfig(**exc_cfg[\"ray\"])  # type: ignore\n\n    if ray_cfg.inherit_job_submission_client_from_ray_run_launcher and isinstance(\n        init_context.instance.run_launcher, RayRunLauncher\n    ):\n        # TODO: some RunLauncher config values can be automatically passed to the executor\n        client = init_context.instance.run_launcher.client\n    else:\n        client = JobSubmissionClient(\n            ray_cfg.address, metadata=ray_cfg.metadata, headers=ray_cfg.headers, cookies=ray_cfg.cookies\n        )\n\n    return StepDelegatingExecutor(\n        RayStepHandler(\n            client=client,\n            env_vars=ray_cfg.env_vars,\n            runtime_env=ray_cfg.runtime_env,\n            num_cpus=ray_cfg.num_cpus,\n            num_gpus=ray_cfg.num_gpus,\n            memory=ray_cfg.memory,\n            resources=ray_cfg.resources,\n            worker_process_setup_hook=ray_cfg.worker_process_setup_hook,\n        ),\n        retries=RetryMode.from_config(exc_cfg[\"retries\"]),  # type: ignore\n        max_concurrent=dg._check.opt_int_elem(exc_cfg, \"max_concurrent\"),\n        tag_concurrency_limits=dg._check.opt_list_elem(exc_cfg, \"tag_concurrency_limits\"),\n        should_verify_step=True,\n    )\n</code></pre>"},{"location":"api/core/#pipes","title":"Pipes","text":"<p>Run external Ray scripts as Ray jobs while streaming back logs and metadata into Dagster with Dagster Pipes.</p>"},{"location":"api/core/#dagster_ray.core.pipes.PipesRayJobClient","title":"dagster_ray.core.pipes.PipesRayJobClient","text":"<pre><code>PipesRayJobClient(\n    client: JobSubmissionClient,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n)\n</code></pre> <p>               Bases: <code>PipesClient</code>, <code>TreatAsResourceParam</code></p> <p>A Pipes client for running Ray jobs on remote clusters.</p> <p>Starts the job directly on the Ray cluster and reads the logs from the job.</p> <p>Parameters:</p> <ul> <li> <code>client</code>               (<code>JobSubmissionClient</code>)           \u2013            <p>The Ray job submission client</p> </li> <li> <code>context_injector</code>               (<code>Optional[PipesContextInjector]</code>, default:                   <code>None</code> )           \u2013            <p>A context injector to use to inject context into the Ray job. Defaults to <code>PipesEnvContextInjector</code>.</p> </li> <li> <code>message_reader</code>               (<code>Optional[PipesMessageReader]</code>, default:                   <code>None</code> )           \u2013            <p>A message reader to use to read messages from the glue job run. Defaults to <code>PipesRayJobMessageReader</code>.</p> </li> <li> <code>forward_termination</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to cancel the Ray job run when the Dagster process receives a termination signal.</p> </li> <li> <code>timeout</code>               (<code>int</code>, default:                   <code>600</code> )           \u2013            <p>Timeout for various internal interactions with the Kubernetes RayJob.</p> </li> <li> <code>poll_interval</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Interval at which to poll Kubernetes for status updates. Is useful when running in a local environment.</p> </li> </ul> Source code in <code>src/dagster_ray/core/pipes.py</code> <pre><code>def __init__(\n    self,\n    client: JobSubmissionClient,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n):\n    self.client = client\n    self._context_injector = context_injector or PipesEnvContextInjector()\n    self._message_reader = message_reader or PipesRayJobMessageReader()\n\n    self.forward_termination = check.bool_param(forward_termination, \"forward_termination\")\n    self.timeout = check.int_param(timeout, \"timeout\")\n    self.poll_interval = check.int_param(poll_interval, \"poll_interval\")\n\n    self._job_submission_client: JobSubmissionClient | None = None\n</code></pre>"},{"location":"api/core/#dagster_ray.core.pipes.PipesRayJobClient-functions","title":"Functions","text":""},{"location":"api/core/#dagster_ray.core.pipes.PipesRayJobClient.run","title":"run","text":"<pre><code>run(\n    *, context: OpOrAssetExecutionContext, submit_job_params: SubmitJobParams, extras: PipesExtras | None = None\n) -&gt; PipesClientCompletedInvocation\n</code></pre> <p>Execute a RayJob, enriched with the Pipes protocol.</p> <p>Parameters:</p> <ul> <li> <code>context</code>               (<code>OpExecutionContext</code>)           \u2013            <p>Current Dagster op or asset context.</p> </li> <li> <code>submit_job_params</code>               (<code>Dict[str, Any]</code>)           \u2013            <p>RayJob specification. <code>API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;</code>_.</p> </li> <li> <code>extras</code>               (<code>Optional[Dict[str, Any]]</code>, default:                   <code>None</code> )           \u2013            <p>Additional information to pass to the Pipes session.</p> </li> </ul> Source code in <code>src/dagster_ray/core/pipes.py</code> <pre><code>def run(  # type: ignore\n    self,\n    *,\n    context: OpOrAssetExecutionContext,\n    submit_job_params: SubmitJobParams,\n    extras: PipesExtras | None = None,\n) -&gt; PipesClientCompletedInvocation:\n    \"\"\"\n    Execute a RayJob, enriched with the Pipes protocol.\n\n    Args:\n        context (OpExecutionContext): Current Dagster op or asset context.\n        submit_job_params (Dict[str, Any]): RayJob specification. `API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;`_.\n        extras (Optional[Dict[str, Any]]): Additional information to pass to the Pipes session.\n    \"\"\"\n\n    with open_pipes_session(\n        context=context,\n        message_reader=self._message_reader,\n        context_injector=self._context_injector,\n        extras=extras,\n    ) as session:\n        enriched_submit_job_params = self._enrich_submit_job_params(context, session, submit_job_params)\n\n        job_id = self._start(context, session, enriched_submit_job_params)\n\n        try:\n            # self._read_messages(context, job_id)\n            self._wait_for_completion(context, job_id)\n            return PipesClientCompletedInvocation(session, metadata={\"Ray Job ID\": job_id})\n\n        except DagsterExecutionInterruptedError:\n            if self.forward_termination:\n                context.log.warning(f\"[pipes] Dagster process interrupted! Will terminate RayJob {job_id}.\")\n                self._terminate(context, job_id)\n            raise\n</code></pre>"},{"location":"api/core/#dagster_ray.core.pipes.PipesRayJobMessageReader","title":"dagster_ray.core.pipes.PipesRayJobMessageReader","text":"<pre><code>PipesRayJobMessageReader(job_submission_client_kwargs: dict[str, Any] | None = None)\n</code></pre> <p>               Bases: <code>PipesMessageReader</code></p> Source code in <code>src/dagster_ray/core/pipes.py</code> <pre><code>def __init__(self, job_submission_client_kwargs: dict[str, Any] | None = None):\n    self._job_submission_client_kwargs = job_submission_client_kwargs\n    self._thread: threading.Thread | None = None\n    self.session_closed = threading.Event()\n    self._job_id = None\n    self._client = None\n    self.thread_ready = threading.Event()\n\n    self.completed = threading.Event()\n</code></pre>"},{"location":"api/core/#dagster_ray.core.pipes.PipesRayJobMessageReader-functions","title":"Functions","text":""},{"location":"api/core/#io-manager","title":"IO Manager","text":"<p>Send data between Dagster steps while they are running inside a Ray cluster.</p>"},{"location":"api/core/#dagster_ray.core.io_manager.RayIOManager","title":"dagster_ray.core.io_manager.RayIOManager","text":"<p>               Bases: <code>ConfigurableIOManager</code></p> <p>IO Manager that stores intermediate values in Ray's object store.</p> <p>The RayIOManager allows storing and retrieving intermediate values in Ray's distributed object store, making it ideal for use with RayRunLauncher and ray_executor. It works by storing Dagster step keys in a global Ray actor that maintains a mapping between step keys and Ray ObjectRefs.</p> <p>Attributes:</p> <ul> <li> <code>address</code>               (<code>str | None</code>)           \u2013            <p>Ray cluster address. If provided, will initialize Ray connection. If None, assumes Ray is already initialized.</p> </li> </ul> Example <p>Basic usage <pre><code>import dagster as dg\nfrom dagster_ray import RayIOManager\n\n@dg.asset(io_manager_key=\"ray_io_manager\")\ndef upstream() -&gt; int:\n    return 42\n\n@dg.asset\ndef downstream(upstream: int):\n    return upstream * 2\n\ndefinitions = dg.Definitions(\n    assets=[upstream, downstream],\n    resources={\"ray_io_manager\": RayIOManager()}\n)\n</code></pre></p> Example <p>With Ray cluster address <pre><code>ray_io_manager = RayIOManager(address=\"ray://head-node:10001\")\n</code></pre></p> Info <ul> <li>Works with picklable Python objects</li> <li>Supports partitioned assets and partition mappings</li> <li>Uses Ray's automatic object movement for fault tolerance</li> <li>Objects are stored with the Ray actor as owner for lifecycle management</li> </ul>"},{"location":"api/kuberay/","title":"KubeRay API Reference","text":"<p>KubeRay integration components for running Ray on Kubernetes.  Learn how to use it here.</p>"},{"location":"api/kuberay/#client-mode-resources","title":"Client Mode Resources","text":"<p>These resources initialize Ray client connection with a remote cluster.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob","title":"dagster_ray.kuberay.KubeRayInteractiveJob  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseKubeRayResource</code></p> <p>Provides a Ray Job for Dagster steps.</p> <p>Is the recommended way to run Ray workloads with automatic cluster management. It creates a Ray Job, connects to it in client mode and sets the <code>jobId</code> field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.</p> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"InteractiveRayJobConfig\": {\n      \"description\": \"Same as [`RayJobConfig`][dagster_ray.kuberay.configs.RayJobConfig], but `spec.submission_mode` mode has to be `InteractiveMode`\",\n      \"properties\": {\n        \"kind\": {\n          \"default\": \"RayJob\",\n          \"title\": \"Kind\",\n          \"type\": \"string\"\n        },\n        \"api_version\": {\n          \"default\": \"ray.io/v1\",\n          \"title\": \"Api Version\",\n          \"type\": \"string\"\n        },\n        \"metadata\": {\n          \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n          \"title\": \"Metadata\",\n          \"type\": \"object\"\n        },\n        \"spec\": {\n          \"$ref\": \"#/$defs/InteractiveRayJobSpec\"\n        }\n      },\n      \"title\": \"InteractiveRayJobConfig\",\n      \"type\": \"object\"\n    },\n    \"InteractiveRayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"Same as [`RayJobSpec`][dagster_ray.kuberay.configs.RayJobSpec], but `mode` has to be `InteractiveMode`\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"const\": \"InteractiveMode\",\n          \"default\": \"InteractiveMode\",\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"InteractiveRayJobSpec\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Provides a Ray Job for Dagster steps.\\n\\nIs the recommended way to run Ray workloads with automatic cluster management. It creates a Ray Job, connects to it in client mode and sets the `jobId` field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.\\n\\nInfo:\\n    Image defaults to `dagster/image` run tag.\\n\\nTip:\\n    Make sure `ray[full]` is available in the image.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline)\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html)\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger)\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"worker_process_setup_hook\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.runtime_env.RuntimeEnv.html).\",\n      \"title\": \"Worker Process Setup Hook\"\n    },\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"failure_tolerance_timeout\": {\n      \"default\": 0.0,\n      \"description\": \"The period in seconds to wait for the cluster to transition out of `failed` state if it reaches it. This state can be transient under certain conditions. With the default value of 0, the first `failed` state appearance will raise an exception immediately.\",\n      \"title\": \"Failure Tolerance Timeout\",\n      \"type\": \"number\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    },\n    \"ray_job\": {\n      \"$ref\": \"#/$defs/InteractiveRayJobConfig\",\n      \"description\": \"Configuration for the Kubernetes `RayJob` CR\"\n    },\n    \"client\": {\n      \"description\": \"Kubernetes `RayJob` client\",\n      \"title\": \"Client\"\n    },\n    \"log_cluster_conditions\": {\n      \"default\": true,\n      \"description\": \"Whether to log `RayCluster` conditions while waiting for the RayCluster to become ready. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions).\",\n      \"title\": \"Log Cluster Conditions\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"KubeRayInteractiveJob\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>worker_process_setup_hook</code>                 (<code>str | None</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>_creation_verb</code>                 (<code>str</code>)             </li> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>failure_tolerance_timeout</code>                 (<code>float</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>ray_job</code>                 (<code>InteractiveRayJobConfig</code>)             </li> <li> <code>client</code>                 (<code>ResourceDependency[RayJobClient]</code>)             </li> <li> <code>log_cluster_conditions</code>                 (<code>bool</code>)             </li> <li> <code>_name</code>                 (<code>str</code>)             </li> <li> <code>_cluster_name</code>                 (<code>str</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.ray_job","title":"ray_job  <code>pydantic-field</code>","text":"<pre><code>ray_job: InteractiveRayJobConfig\n</code></pre> <p>Configuration for the Kubernetes <code>RayJob</code> CR</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.client","title":"client  <code>pydantic-field</code>","text":"<pre><code>client: ResourceDependency[RayJobClient]\n</code></pre> <p>Kubernetes <code>RayJob</code> client</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.failure_tolerance_timeout","title":"failure_tolerance_timeout  <code>pydantic-field</code>","text":"<pre><code>failure_tolerance_timeout: float = 0.0\n</code></pre> <p>The period in seconds to wait for the cluster to transition out of <code>failed</code> state if it reaches it. This state can be transient under certain conditions. With the default value of 0, the first <code>failed</code> state appearance will raise an exception immediately.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayInteractiveJob.log_cluster_conditions","title":"log_cluster_conditions  <code>pydantic-field</code>","text":"<pre><code>log_cluster_conditions: bool = True\n</code></pre> <p>Whether to log <code>RayCluster</code> conditions while waiting for the RayCluster to become ready. Learn more: KubeRay docs.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster","title":"dagster_ray.kuberay.KubeRayCluster  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseKubeRayResource</code></p> <p>Provides a Ray Cluster for Dagster steps.</p> <p>It is advised to use <code>KubeRayInteractiveJob</code> with KubeRay &gt;= 1.3.0 instead.</p> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ClusterSharing\": {\n      \"description\": \"Defines the strategy for sharing `RayCluster` resources with other Dagster steps.\\n\\nBy default, the cluster is expected to be created by Dagster during one of the previously executed steps.\",\n      \"properties\": {\n        \"enabled\": {\n          \"default\": false,\n          \"description\": \"Whether to enable sharing of RayClusters.\",\n          \"title\": \"Enabled\",\n          \"type\": \"boolean\"\n        },\n        \"match_dagster_labels\": {\n          \"$ref\": \"#/$defs/MatchDagsterLabels\",\n          \"description\": \"Configuration for matching on Dagster-generated labels.\"\n        },\n        \"match_labels\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"description\": \"Additional user-provided labels to match on.\",\n          \"title\": \"Match Labels\"\n        },\n        \"ttl_seconds\": {\n          \"default\": 1800.0,\n          \"description\": \"Time to live for the lock placed on the `RayCluster` resource, marking it as in use by the current Dagster step.\",\n          \"title\": \"Ttl Seconds\",\n          \"type\": \"number\"\n        }\n      },\n      \"title\": \"ClusterSharing\",\n      \"type\": \"object\"\n    },\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"MatchDagsterLabels\": {\n      \"properties\": {\n        \"cluster_sharing\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/cluster-sharing=true` label.\",\n          \"title\": \"Cluster Sharing\",\n          \"type\": \"boolean\"\n        },\n        \"code_location\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/code-location` label. The value will be taken from the current Dagster code location.\",\n          \"title\": \"Code Location\",\n          \"type\": \"boolean\"\n        },\n        \"resource_key\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/resource-key` label. The value will be taken from the current Dagster resource key.\",\n          \"title\": \"Resource Key\",\n          \"type\": \"boolean\"\n        },\n        \"git_sha\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/git-sha` label. The value will be taken from `DAGSTER_CLOUD_GIT_SHA` environment variable.\",\n          \"title\": \"Git Sha\",\n          \"type\": \"boolean\"\n        },\n        \"run_id\": {\n          \"default\": false,\n          \"description\": \"Whether to match on `dagster/run-id` label. The value will be taken from the current Dagster run ID.\",\n          \"title\": \"Run Id\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"MatchDagsterLabels\",\n      \"type\": \"object\"\n    },\n    \"RayClusterConfig\": {\n      \"properties\": {\n        \"kind\": {\n          \"default\": \"RayCluster\",\n          \"title\": \"Kind\",\n          \"type\": \"string\"\n        },\n        \"api_version\": {\n          \"default\": \"ray.io/v1\",\n          \"title\": \"Api Version\",\n          \"type\": \"string\"\n        },\n        \"metadata\": {\n          \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n          \"title\": \"Metadata\",\n          \"type\": \"object\"\n        },\n        \"spec\": {\n          \"$ref\": \"#/$defs/RayClusterSpec\"\n        }\n      },\n      \"title\": \"RayClusterConfig\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Provides a Ray Cluster for Dagster steps.\\n\\nIt is advised to use [`KubeRayInteractiveJob`][dagster_ray.kuberay.resources.KubeRayInteractiveJob] with KubeRay &gt;= 1.3.0 instead.\\n\\nInfo:\\n    Image defaults to `dagster/image` run tag.\\n\\nTip:\\n    Make sure `ray[full]` is available in the image.\",\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline)\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html)\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger)\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"worker_process_setup_hook\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.runtime_env.RuntimeEnv.html).\",\n      \"title\": \"Worker Process Setup Hook\"\n    },\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"failure_tolerance_timeout\": {\n      \"default\": 0.0,\n      \"description\": \"The period in seconds to wait for the cluster to transition out of `failed` state if it reaches it. This state can be transient under certain conditions. With the default value of 0, the first `failed` state appearance will raise an exception immediately.\",\n      \"title\": \"Failure Tolerance Timeout\",\n      \"type\": \"number\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    },\n    \"cluster_sharing\": {\n      \"$ref\": \"#/$defs/ClusterSharing\",\n      \"description\": \"Configuration for sharing the `RayCluster` across Dagster steps. Existing clusters matching this configuration will be reused without recreating them. A `dagster/sharing=true` label will be applied to the `RayCluster`, and a `dagster/lock-&lt;run-id&gt;-&lt;step-id&gt;=&lt;lock&gt;` annotation will be placed on the `RayCluster` to mark it as being used by this step. Cleanup will only proceed if the `RayCluster` is not being used by any other steps, therefore cluster sharing should be used in conjunction with [dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters][] sensor.\"\n    },\n    \"ray_cluster\": {\n      \"$ref\": \"#/$defs/RayClusterConfig\",\n      \"description\": \"Kubernetes `RayCluster` CR configuration.\"\n    },\n    \"client\": {\n      \"description\": \"Kubernetes `RayCluster` client\",\n      \"title\": \"Client\"\n    },\n    \"log_cluster_conditions\": {\n      \"default\": true,\n      \"description\": \"Whether to log RayCluster conditions while waiting for the RayCluster to become ready. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/cluster/kubernetes/user-guides/observability.html#raycluster-status-conditions).\",\n      \"title\": \"Log Cluster Conditions\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"KubeRayCluster\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>worker_process_setup_hook</code>                 (<code>str | None</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>_creation_verb</code>                 (<code>str</code>)             </li> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>failure_tolerance_timeout</code>                 (<code>float</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>cluster_sharing</code>                 (<code>ClusterSharing</code>)             </li> <li> <code>ray_cluster</code>                 (<code>RayClusterConfig</code>)             </li> <li> <code>client</code>                 (<code>ResourceDependency[RayClusterClient]</code>)             </li> <li> <code>log_cluster_conditions</code>                 (<code>bool</code>)             </li> <li> <code>_name</code>                 (<code>str</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.cluster_sharing","title":"cluster_sharing  <code>pydantic-field</code>","text":"<pre><code>cluster_sharing: ClusterSharing\n</code></pre> <p>Configuration for sharing the <code>RayCluster</code> across Dagster steps. Existing clusters matching this configuration will be reused without recreating them. A <code>dagster/sharing=true</code> label will be applied to the <code>RayCluster</code>, and a <code>dagster/lock-&lt;run-id&gt;-&lt;step-id&gt;=&lt;lock&gt;</code> annotation will be placed on the <code>RayCluster</code> to mark it as being used by this step. Cleanup will only proceed if the <code>RayCluster</code> is not being used by any other steps, therefore cluster sharing should be used in conjunction with dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters sensor.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.lifecycle","title":"lifecycle  <code>pydantic-field</code>","text":"<pre><code>lifecycle: Lifecycle\n</code></pre> <p>Actions to perform during resource setup.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.ray_cluster","title":"ray_cluster  <code>pydantic-field</code>","text":"<pre><code>ray_cluster: RayClusterConfig\n</code></pre> <p>Kubernetes <code>RayCluster</code> CR configuration.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.client","title":"client  <code>pydantic-field</code>","text":"<pre><code>client: ResourceDependency[RayClusterClient]\n</code></pre> <p>Kubernetes <code>RayCluster</code> client</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.failure_tolerance_timeout","title":"failure_tolerance_timeout  <code>pydantic-field</code>","text":"<pre><code>failure_tolerance_timeout: float = 0.0\n</code></pre> <p>The period in seconds to wait for the cluster to transition out of <code>failed</code> state if it reaches it. This state can be transient under certain conditions. With the default value of 0, the first <code>failed</code> state appearance will raise an exception immediately.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayCluster.log_cluster_conditions","title":"log_cluster_conditions  <code>pydantic-field</code>","text":"<pre><code>log_cluster_conditions: bool = True\n</code></pre> <p>Whether to log RayCluster conditions while waiting for the RayCluster to become ready. Learn more: KubeRay docs.</p>"},{"location":"api/kuberay/#pipes","title":"Pipes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient","title":"dagster_ray.kuberay.PipesKubeRayJobClient","text":"<pre><code>PipesKubeRayJobClient(\n    client: RayJobClient | None = None,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n    port_forward: bool = False,\n)\n</code></pre> <p>               Bases: <code>PipesClient</code>, <code>TreatAsResourceParam</code></p> <p>A pipes client for running <code>RayJob</code> on Kubernetes.</p> <p>Parameters:</p> <ul> <li> <code>context_injector</code>               (<code>Optional[PipesContextInjector]</code>, default:                   <code>None</code> )           \u2013            <p>A context injector to use to inject context into the <code>RayJob</code>. Defaults to <code>PipesEnvContextInjector</code>.</p> </li> <li> <code>message_reader</code>               (<code>Optional[PipesMessageReader]</code>, default:                   <code>None</code> )           \u2013            <p>A message reader to use to read messages from the glue job run. Defaults to <code>PipesRayJobMessageReader</code>.</p> </li> <li> <code>client</code>               (<code>Optional[client]</code>, default:                   <code>None</code> )           \u2013            <p>The Kubernetes API client.</p> </li> <li> <code>forward_termination</code>               (<code>bool</code>, default:                   <code>True</code> )           \u2013            <p>Whether to terminate the Ray job when the Dagster process receives a termination signal, or if the startup timeout is reached. Defaults to <code>True</code>.</p> </li> <li> <code>timeout</code>               (<code>int</code>, default:                   <code>600</code> )           \u2013            <p>Timeout for various internal interactions with the Kubernetes RayJob.</p> </li> <li> <code>poll_interval</code>               (<code>int</code>, default:                   <code>1</code> )           \u2013            <p>Interval at which to poll Kubernetes for status updates.</p> </li> <li> <code>port_forward</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to use Kubernetes port-forwarding to connect to the KubeRay cluster. Is useful when running in a local environment.</p> </li> </ul> Info <p>Image defaults to <code>dagster/image</code> run tag.</p> Tip <p>Make sure <code>ray[full]</code> is available in the image.</p> Source code in <code>src/dagster_ray/kuberay/pipes.py</code> <pre><code>def __init__(\n    self,\n    client: RayJobClient | None = None,\n    context_injector: PipesContextInjector | None = None,\n    message_reader: PipesMessageReader | None = None,\n    forward_termination: bool = True,\n    timeout: float = 600,\n    poll_interval: float = 1,\n    port_forward: bool = False,\n):\n    self.client: RayJobClient = client or RayJobClient()\n\n    self._context_injector = context_injector or PipesEnvContextInjector()\n    self._message_reader = message_reader or PipesRayJobMessageReader()\n\n    self.forward_termination = check.bool_param(forward_termination, \"forward_termination\")\n    self.timeout = check.int_param(timeout, \"timeout\")\n    self.poll_interval = check.int_param(poll_interval, \"poll_interval\")\n    self.port_forward = check.bool_param(port_forward, \"port_forward\")\n\n    self._job_submission_client: JobSubmissionClient | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.PipesKubeRayJobClient.run","title":"run","text":"<pre><code>run(\n    *, context: OpOrAssetExecutionContext, ray_job: dict[str, Any], extras: PipesExtras | None = None\n) -&gt; PipesClientCompletedInvocation\n</code></pre> <p>Execute a RayJob, enriched with the Pipes protocol.</p> <p>Parameters:</p> <ul> <li> <code>context</code>               (<code>OpExecutionContext</code>)           \u2013            <p>Current Dagster op or asset context.</p> </li> <li> <code>ray_job</code>               (<code>Dict[str, Any]</code>)           \u2013            <p>RayJob specification. <code>API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;</code>_.</p> </li> <li> <code>extras</code>               (<code>Optional[Dict[str, Any]]</code>, default:                   <code>None</code> )           \u2013            <p>Additional information to pass to the Pipes session.</p> </li> </ul> Source code in <code>src/dagster_ray/kuberay/pipes.py</code> <pre><code>def run(  # type: ignore\n    self,\n    *,\n    context: OpOrAssetExecutionContext,\n    ray_job: dict[str, Any],\n    extras: PipesExtras | None = None,\n) -&gt; PipesClientCompletedInvocation:\n    \"\"\"\n    Execute a RayJob, enriched with the Pipes protocol.\n\n    Args:\n        context (OpExecutionContext): Current Dagster op or asset context.\n        ray_job (Dict[str, Any]): RayJob specification. `API reference &lt;https://ray-project.github.io/kuberay/reference/api/#rayjob&gt;`_.\n        extras (Optional[Dict[str, Any]]): Additional information to pass to the Pipes session.\n    \"\"\"\n    with open_pipes_session(\n        context=context,\n        message_reader=self._message_reader,\n        context_injector=self._context_injector,\n        extras=extras,\n    ) as session:\n        ray_job = self._enrich_ray_job(context, session, ray_job)\n        start_response = self._start(context, session, ray_job)\n        start_status = cast(RayJobStatus, start_response[\"status\"])\n        ray_job_id = start_status[\"jobId\"]  # pyright: ignore[reportTypedDictNotRequiredAccess]\n\n        name = ray_job[\"metadata\"][\"name\"]\n        namespace = ray_job[\"metadata\"][\"namespace\"]\n\n        with self.client.ray_cluster_client.job_submission_client(\n            name=self.client.get_ray_cluster_name(\n                name=name, namespace=namespace, timeout=self.timeout, poll_interval=self.poll_interval\n            ),\n            namespace=namespace,\n            port_forward=self.port_forward,\n        ) as job_submission_client:\n            self._job_submission_client = job_submission_client\n\n            session.report_launched(\n                {\n                    \"extras\": {\n                        PIPES_LAUNCHED_EXTRAS_RAY_JOB_ID_KEY: ray_job_id,\n                        PIPES_LAUNCHED_EXTRAS_RAY_ADDRESS_KEY: job_submission_client.get_address(),\n                    }\n                }\n            )\n\n            try:\n                self._wait_for_completion(context, start_response)\n\n                if isinstance(self._message_reader, PipesRayJobMessageReader) and self.port_forward:\n                    # in this case the message reader will fail once port forwarding is finished\n                    # TODO: merge https://github.com/danielgafni/dagster-ray/pull/123\n                    # to avoid this work-around\n                    self._message_reader.thread_ready.wait()\n                    context.log.debug(\n                        \"[pipes] waiting for PipesRayJobMessageReader to complete before stopping port-forwarding\"\n                    )\n                    self._message_reader.session_closed.set()\n                    self._message_reader.completed.wait()\n\n                return PipesClientCompletedInvocation(\n                    session, metadata={\"RayJob\": f\"{namespace}/{name}\", \"Ray Job ID\": ray_job_id}\n                )\n\n            except DagsterExecutionInterruptedError:\n                if self.forward_termination:\n                    context.log.warning(\n                        f\"[pipes] Dagster process interrupted! Will terminate RayJob {namespace}/{name}.\"\n                    )\n                    self._terminate(context, start_response)\n                raise\n</code></pre>"},{"location":"api/kuberay/#configuration-and-types","title":"Configuration and Types","text":"<p>--</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig","title":"dagster_ray.kuberay.configs.RayJobConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    },\n    \"RayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayJob spec](https://ray-project.github.io/kuberay/reference/api/#rayjobspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"default\": \"K8sJobMode\",\n          \"enum\": [\n            \"K8sJobMode\",\n            \"HTTPMode\",\n            \"InteractiveMode\"\n          ],\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"RayJobSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayJob\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/RayJobSpec\"\n    }\n  },\n  \"title\": \"RayJobConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>RayJobSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: RayJobSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(\n            context=context,\n            image=image,\n            env_vars=env_vars,\n        ),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec","title":"dagster_ray.kuberay.configs.RayJobSpec","text":"<p>               Bases: <code>PermissiveConfig</code></p> <p>RayJob spec configuration options. A few sensible defaults are provided for convenience.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.ray_cluster_spec","title":"ray_cluster_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_cluster_spec: RayClusterSpec | None = Field(default_factory=RayClusterSpec)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_num_cpus","title":"entrypoint_num_cpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_cpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_num_gpus","title":"entrypoint_num_gpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_gpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_memory","title":"entrypoint_memory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_memory: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.entrypoint_resources","title":"entrypoint_resources  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_resources: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayJobSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n    return remove_none_from_dict(\n        {\n            \"activeDeadlineSeconds\": self.active_deadline_seconds,\n            \"backoffLimit\": self.backoff_limit,\n            \"submitterPodTemplate\": self.submitter_pod_template,\n            \"metadata\": self.metadata,\n            \"clusterSelector\": self.cluster_selector,\n            \"managedBy\": self.managed_by,\n            \"deletionStrategy\": self.deletion_strategy,\n            \"runtimeEnvYAML\": self.runtime_env_yaml,\n            \"jobId\": self.job_id,\n            \"submissionMode\": self.submission_mode,\n            \"entrypointResources\": self.entrypoint_resources,\n            \"entrypointNumCpus\": self.entrypoint_num_cpus,\n            \"entrypointMemory\": self.entrypoint_memory,\n            \"entrypointNumGpus\": self.entrypoint_num_gpus,\n            \"ttlSecondsAfterFinished\": self.ttl_seconds_after_finished,\n            \"shutdownAfterJobFinishes\": self.shutdown_after_job_finishes,\n            \"suspend\": self.suspend,\n            \"rayClusterSpec\": self.ray_cluster_spec.to_k8s(context=context, image=image, env_vars=env_vars)\n            if self.ray_cluster_spec is not None\n            else None,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig","title":"dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>RayJobConfig</code></p> <p>Same as <code>RayJobConfig</code>, but <code>spec.submission_mode</code> mode has to be <code>InteractiveMode</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"InteractiveRayJobSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"Same as [`RayJobSpec`][dagster_ray.kuberay.configs.RayJobSpec], but `mode` has to be `InteractiveMode`\",\n      \"properties\": {\n        \"active_deadline_seconds\": {\n          \"default\": 86400,\n          \"title\": \"Active Deadline Seconds\",\n          \"type\": \"integer\"\n        },\n        \"backoff_limit\": {\n          \"default\": 0,\n          \"title\": \"Backoff Limit\",\n          \"type\": \"integer\"\n        },\n        \"ray_cluster_spec\": {\n          \"anyOf\": [\n            {\n              \"$ref\": \"#/$defs/RayClusterSpec\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ]\n        },\n        \"submitter_pod_template\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Submitter Pod Template\"\n        },\n        \"metadata\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Metadata\"\n        },\n        \"cluster_selector\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cluster Selector\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"deletion_strategy\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"title\": \"Deletion Strategy\"\n        },\n        \"runtime_env_yaml\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Runtime Env Yaml\"\n        },\n        \"job_id\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Job Id\"\n        },\n        \"submission_mode\": {\n          \"const\": \"InteractiveMode\",\n          \"default\": \"InteractiveMode\",\n          \"title\": \"Submission Mode\",\n          \"type\": \"string\"\n        },\n        \"entrypoint_resources\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Resources\"\n        },\n        \"entrypoint_num_cpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Cpus\"\n        },\n        \"entrypoint_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Memory\"\n        },\n        \"entrypoint_num_gpus\": {\n          \"anyOf\": [\n            {\n              \"type\": \"number\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Entrypoint Num Gpus\"\n        },\n        \"ttl_seconds_after_finished\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": 300,\n          \"title\": \"Ttl Seconds After Finished\"\n        },\n        \"shutdown_after_job_finishes\": {\n          \"default\": true,\n          \"title\": \"Shutdown After Job Finishes\",\n          \"type\": \"boolean\"\n        },\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        }\n      },\n      \"title\": \"InteractiveRayJobSpec\",\n      \"type\": \"object\"\n    },\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Same as [`RayJobConfig`][dagster_ray.kuberay.configs.RayJobConfig], but `spec.submission_mode` mode has to be `InteractiveMode`\",\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayJob\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/InteractiveRayJobSpec\"\n    }\n  },\n  \"title\": \"InteractiveRayJobConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>InteractiveRayJobSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: InteractiveRayJobSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(\n            context=context,\n            image=image,\n            env_vars=env_vars,\n        ),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec","title":"dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec","text":"<p>               Bases: <code>RayJobSpec</code></p> <p>Same as <code>RayJobSpec</code>, but <code>mode</code> has to be <code>InteractiveMode</code></p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.submission_mode","title":"submission_mode  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>submission_mode: Literal['InteractiveMode'] = 'InteractiveMode'\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.active_deadline_seconds","title":"active_deadline_seconds  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>active_deadline_seconds: int = 60 * 60 * 24\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.backoff_limit","title":"backoff_limit  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>backoff_limit: int = 0\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.ray_cluster_spec","title":"ray_cluster_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_cluster_spec: RayClusterSpec | None = Field(default_factory=RayClusterSpec)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.submitter_pod_template","title":"submitter_pod_template  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>submitter_pod_template: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.metadata","title":"metadata  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>metadata: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.cluster_selector","title":"cluster_selector  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>cluster_selector: dict[str, str] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.managed_by","title":"managed_by  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>managed_by: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.deletion_strategy","title":"deletion_strategy  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>deletion_strategy: dict[str, Any] | None = Field(\n    default_factory=lambda: {\"onFailure\": {\"policy\": \"DeleteCluster\"}, \"onSuccess\": {\"policy\": \"DeleteCluster\"}}\n)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.runtime_env_yaml","title":"runtime_env_yaml  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>runtime_env_yaml: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.job_id","title":"job_id  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>job_id: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_resources","title":"entrypoint_resources  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_resources: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_num_cpus","title":"entrypoint_num_cpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_cpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_memory","title":"entrypoint_memory  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_memory: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.entrypoint_num_gpus","title":"entrypoint_num_gpus  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>entrypoint_num_gpus: float | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.ttl_seconds_after_finished","title":"ttl_seconds_after_finished  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ttl_seconds_after_finished: int | None = 5 * 60\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.shutdown_after_job_finishes","title":"shutdown_after_job_finishes  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>shutdown_after_job_finishes: bool = True\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.suspend","title":"suspend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>suspend: bool | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.rayjob.InteractiveRayJobSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n    return remove_none_from_dict(\n        {\n            \"activeDeadlineSeconds\": self.active_deadline_seconds,\n            \"backoffLimit\": self.backoff_limit,\n            \"submitterPodTemplate\": self.submitter_pod_template,\n            \"metadata\": self.metadata,\n            \"clusterSelector\": self.cluster_selector,\n            \"managedBy\": self.managed_by,\n            \"deletionStrategy\": self.deletion_strategy,\n            \"runtimeEnvYAML\": self.runtime_env_yaml,\n            \"jobId\": self.job_id,\n            \"submissionMode\": self.submission_mode,\n            \"entrypointResources\": self.entrypoint_resources,\n            \"entrypointNumCpus\": self.entrypoint_num_cpus,\n            \"entrypointMemory\": self.entrypoint_memory,\n            \"entrypointNumGpus\": self.entrypoint_num_gpus,\n            \"ttlSecondsAfterFinished\": self.ttl_seconds_after_finished,\n            \"shutdownAfterJobFinishes\": self.shutdown_after_job_finishes,\n            \"suspend\": self.suspend,\n            \"rayClusterSpec\": self.ray_cluster_spec.to_k8s(context=context, image=image, env_vars=env_vars)\n            if self.ray_cluster_spec is not None\n            else None,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig","title":"dagster_ray.kuberay.configs.RayClusterConfig  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"RayClusterSpec\": {\n      \"additionalProperties\": true,\n      \"description\": \"[RayCluster spec](https://ray-project.github.io/kuberay/reference/api/#rayclusterspec) configuration options. A few sensible defaults are provided for convenience.\",\n      \"properties\": {\n        \"suspend\": {\n          \"anyOf\": [\n            {\n              \"type\": \"boolean\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Suspend\"\n        },\n        \"managed_by\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Managed By\"\n        },\n        \"autoscaler_options\": {\n          \"default\": {\n            \"upscalingMode\": \"Default\",\n            \"idleTimeoutSeconds\": 60,\n            \"env\": [],\n            \"envFrom\": [],\n            \"resources\": {\n              \"limits\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              },\n              \"requests\": {\n                \"cpu\": \"50m\",\n                \"memory\": \"0.1Gi\"\n              }\n            }\n          },\n          \"title\": \"Autoscaler Options\",\n          \"type\": \"object\"\n        },\n        \"head_service_annotations\": {\n          \"anyOf\": [\n            {\n              \"additionalProperties\": {\n                \"type\": \"string\"\n              },\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Head Service Annotations\"\n        },\n        \"enable_in_tree_autoscaling\": {\n          \"default\": false,\n          \"title\": \"Enable In Tree Autoscaling\",\n          \"type\": \"boolean\"\n        },\n        \"gcs_fault_tolerance_options\": {\n          \"anyOf\": [\n            {\n              \"type\": \"object\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gcs Fault Tolerance Options\"\n        },\n        \"head_group_spec\": {\n          \"default\": {\n            \"serviceType\": \"ClusterIP\",\n            \"rayStartParams\": {},\n            \"metadata\": {\n              \"annotations\": {},\n              \"labels\": {}\n            },\n            \"template\": {\n              \"spec\": {\n                \"affinity\": {},\n                \"containers\": [\n                  {\n                    \"imagePullPolicy\": \"Always\",\n                    \"name\": \"head\",\n                    \"volumeMounts\": [\n                      {\n                        \"mountPath\": \"/tmp/ray\",\n                        \"name\": \"ray-logs\"\n                      }\n                    ]\n                  }\n                ],\n                \"imagePullSecrets\": [],\n                \"nodeSelector\": {},\n                \"tolerations\": [],\n                \"volumes\": [\n                  {\n                    \"emptyDir\": {},\n                    \"name\": \"ray-logs\"\n                  }\n                ]\n              }\n            }\n          },\n          \"title\": \"Head Group Spec\",\n          \"type\": \"object\"\n        },\n        \"ray_version\": {\n          \"anyOf\": [\n            {\n              \"type\": \"string\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Ray Version\"\n        },\n        \"worker_group_specs\": {\n          \"default\": [\n            {\n              \"groupName\": \"workers\",\n              \"replicas\": 0,\n              \"minReplicas\": 0,\n              \"maxReplicas\": 1,\n              \"rayStartParams\": {},\n              \"template\": {\n                \"metadata\": {\n                  \"annotations\": {},\n                  \"labels\": {}\n                },\n                \"spec\": {\n                  \"affinity\": {},\n                  \"containers\": [\n                    {\n                      \"imagePullPolicy\": \"Always\",\n                      \"name\": \"worker\",\n                      \"volumeMounts\": [\n                        {\n                          \"mountPath\": \"/tmp/ray\",\n                          \"name\": \"ray-logs\"\n                        }\n                      ]\n                    }\n                  ],\n                  \"imagePullSecrets\": [],\n                  \"nodeSelector\": {},\n                  \"tolerations\": [],\n                  \"volumes\": [\n                    {\n                      \"emptyDir\": {},\n                      \"name\": \"ray-logs\"\n                    }\n                  ]\n                }\n              }\n            }\n          ],\n          \"items\": {\n            \"type\": \"object\"\n          },\n          \"title\": \"Worker Group Specs\",\n          \"type\": \"array\"\n        }\n      },\n      \"title\": \"RayClusterSpec\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"kind\": {\n      \"default\": \"RayCluster\",\n      \"title\": \"Kind\",\n      \"type\": \"string\"\n    },\n    \"api_version\": {\n      \"default\": \"ray.io/v1\",\n      \"title\": \"Api Version\",\n      \"type\": \"string\"\n    },\n    \"metadata\": {\n      \"description\": \"Kubernetes metadata, except the name field can be omitted. In this case it will be generated by `dagster-ray`.\",\n      \"title\": \"Metadata\",\n      \"type\": \"object\"\n    },\n    \"spec\": {\n      \"$ref\": \"#/$defs/RayClusterSpec\"\n    }\n  },\n  \"title\": \"RayClusterConfig\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kind</code>                 (<code>str</code>)             </li> <li> <code>api_version</code>                 (<code>str</code>)             </li> <li> <code>metadata</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>spec</code>                 (<code>RayClusterSpec</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.metadata","title":"metadata  <code>pydantic-field</code>","text":"<pre><code>metadata: dict[str, Any]\n</code></pre> <p>Kubernetes metadata, except the name field can be omitted. In this case it will be generated by <code>dagster-ray</code>.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.spec","title":"spec  <code>pydantic-field</code>","text":"<pre><code>spec: RayClusterSpec\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterConfig.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext,\n    image: str | None = None,\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    labels: Mapping[str, str] | None = None,\n    annotations: Mapping[str, str] | None = None,\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    assert context.log is not None\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    labels = labels or {}\n    annotations = annotations or {}\n\n    return {\n        \"apiVersion\": self.api_version,\n        \"kind\": self.kind,\n        \"metadata\": remove_none_from_dict(\n            {\n                \"name\": self.metadata.get(\"name\"),\n                \"labels\": {**(self.metadata.get(\"labels\", {}) or {}), **labels},\n                \"annotations\": {**self.metadata.get(\"annotations\", {}), **annotations},\n            }\n        ),\n        \"spec\": self.spec.to_k8s(context=context, image=image, env_vars=env_vars),\n    }\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec","title":"dagster_ray.kuberay.configs.RayClusterSpec","text":"<p>               Bases: <code>PermissiveConfig</code></p> <p>RayCluster spec configuration options. A few sensible defaults are provided for convenience.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.suspend","title":"suspend  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>suspend: bool | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.managed_by","title":"managed_by  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>managed_by: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.autoscaler_options","title":"autoscaler_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>autoscaler_options: dict[str, Any] = DEFAULT_AUTOSCALER_OPTIONS\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.head_service_annotations","title":"head_service_annotations  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>head_service_annotations: dict[str, str] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.enable_in_tree_autoscaling","title":"enable_in_tree_autoscaling  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>enable_in_tree_autoscaling: bool = False\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.gcs_fault_tolerance_options","title":"gcs_fault_tolerance_options  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>gcs_fault_tolerance_options: dict[str, Any] | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.head_group_spec","title":"head_group_spec  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>head_group_spec: dict[str, Any] = DEFAULT_HEAD_GROUP_SPEC\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.ray_version","title":"ray_version  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>ray_version: str | None = None\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.worker_group_specs","title":"worker_group_specs  <code>class-attribute</code> <code>instance-attribute</code>","text":"<pre><code>worker_group_specs: list[dict[str, Any]] = DEFAULT_WORKER_GROUP_SPECS\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.RayClusterSpec.to_k8s","title":"to_k8s","text":"<pre><code>to_k8s(\n    context: AnyDagsterContext, image: str | None = None, env_vars: Mapping[str, str] | None = None\n) -&gt; dict[str, Any]\n</code></pre> <p>Convert into Kubernetes manifests in camelCase format and inject additional information</p> Source code in <code>src/dagster_ray/kuberay/configs.py</code> <pre><code>def to_k8s(\n    self,\n    context: AnyDagsterContext,\n    image: str | None = None,  # is injected into headgroup and workergroups, unless already specified there\n    env_vars: Mapping[str, str] | None = None,\n) -&gt; dict[str, Any]:\n    \"\"\"Convert into Kubernetes manifests in camelCase format and inject additional information\"\"\"\n\n    assert context.log is not None\n\n    # TODO: inject self.redis_port and self.dashboard_port into the RayCluster configuration\n    # TODO: auto-apply some tags from dagster-k8s/config\n\n    head_group_spec = self.head_group_spec.copy()\n    worker_group_specs = self.worker_group_specs.copy()\n\n    k8s_env_vars: list[dict[str, Any]] = []\n\n    if env_vars:\n        for key, value in env_vars.items():\n            k8s_env_vars.append({\"name\": key, \"value\": value})\n\n    def update_group_spec(group_spec: dict[str, Any]):\n        # TODO: only inject if the container has a `dagster.io/inject-image` annotation or smth\n        if group_spec[\"template\"][\"spec\"][\"containers\"][0].get(\"image\") is None:\n            if image is None:\n                raise ValueError(MISSING_IMAGE_MESSAGE)\n            else:\n                group_spec[\"template\"][\"spec\"][\"containers\"][0][\"image\"] = image\n\n        for container in group_spec[\"template\"][\"spec\"][\"containers\"]:\n            container[\"env\"] = container.get(\"env\", []) + k8s_env_vars\n\n    update_group_spec(head_group_spec)\n    for worker_group_spec in worker_group_specs:\n        update_group_spec(worker_group_spec)\n\n    return remove_none_from_dict(\n        {\n            \"enableInTreeAutoscaling\": self.enable_in_tree_autoscaling,\n            \"autoscalerOptions\": self.autoscaler_options,\n            \"headGroupSpec\": head_group_spec,\n            \"workerGroupSpecs\": worker_group_specs,\n            \"suspend\": self.suspend,\n            \"managedBy\": self.managed_by,\n            \"headServiceAnnotations\": self.head_service_annotations,\n            \"gcsFaultToleranceOptions\": self.gcs_fault_tolerance_options,\n            \"rayVersion\": self.ray_version,\n        }\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels","title":"dagster_ray.kuberay.configs.MatchDagsterLabels  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> Show JSON schema: <pre><code>{\n  \"properties\": {\n    \"cluster_sharing\": {\n      \"default\": true,\n      \"description\": \"Whether to match on `dagster/cluster-sharing=true` label.\",\n      \"title\": \"Cluster Sharing\",\n      \"type\": \"boolean\"\n    },\n    \"code_location\": {\n      \"default\": true,\n      \"description\": \"Whether to match on `dagster/code-location` label. The value will be taken from the current Dagster code location.\",\n      \"title\": \"Code Location\",\n      \"type\": \"boolean\"\n    },\n    \"resource_key\": {\n      \"default\": true,\n      \"description\": \"Whether to match on `dagster/resource-key` label. The value will be taken from the current Dagster resource key.\",\n      \"title\": \"Resource Key\",\n      \"type\": \"boolean\"\n    },\n    \"git_sha\": {\n      \"default\": true,\n      \"description\": \"Whether to match on `dagster/git-sha` label. The value will be taken from `DAGSTER_CLOUD_GIT_SHA` environment variable.\",\n      \"title\": \"Git Sha\",\n      \"type\": \"boolean\"\n    },\n    \"run_id\": {\n      \"default\": false,\n      \"description\": \"Whether to match on `dagster/run-id` label. The value will be taken from the current Dagster run ID.\",\n      \"title\": \"Run Id\",\n      \"type\": \"boolean\"\n    }\n  },\n  \"title\": \"MatchDagsterLabels\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>cluster_sharing</code>                 (<code>bool</code>)             </li> <li> <code>code_location</code>                 (<code>bool</code>)             </li> <li> <code>resource_key</code>                 (<code>bool</code>)             </li> <li> <code>git_sha</code>                 (<code>bool</code>)             </li> <li> <code>run_id</code>                 (<code>bool</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels.cluster_sharing","title":"cluster_sharing  <code>pydantic-field</code>","text":"<pre><code>cluster_sharing: bool = True\n</code></pre> <p>Whether to match on <code>dagster/cluster-sharing=true</code> label.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels.code_location","title":"code_location  <code>pydantic-field</code>","text":"<pre><code>code_location: bool = True\n</code></pre> <p>Whether to match on <code>dagster/code-location</code> label. The value will be taken from the current Dagster code location.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels.resource_key","title":"resource_key  <code>pydantic-field</code>","text":"<pre><code>resource_key: bool = True\n</code></pre> <p>Whether to match on <code>dagster/resource-key</code> label. The value will be taken from the current Dagster resource key.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels.git_sha","title":"git_sha  <code>pydantic-field</code>","text":"<pre><code>git_sha: bool = True\n</code></pre> <p>Whether to match on <code>dagster/git-sha</code> label. The value will be taken from <code>DAGSTER_CLOUD_GIT_SHA</code> environment variable.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.MatchDagsterLabels.run_id","title":"run_id  <code>pydantic-field</code>","text":"<pre><code>run_id: bool = False\n</code></pre> <p>Whether to match on <code>dagster/run-id</code> label. The value will be taken from the current Dagster run ID.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing","title":"dagster_ray.kuberay.configs.ClusterSharing  <code>pydantic-model</code>","text":"<p>               Bases: <code>Config</code></p> <p>Defines the strategy for sharing <code>RayCluster</code> resources with other Dagster steps.</p> <p>By default, the cluster is expected to be created by Dagster during one of the previously executed steps.</p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"MatchDagsterLabels\": {\n      \"properties\": {\n        \"cluster_sharing\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/cluster-sharing=true` label.\",\n          \"title\": \"Cluster Sharing\",\n          \"type\": \"boolean\"\n        },\n        \"code_location\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/code-location` label. The value will be taken from the current Dagster code location.\",\n          \"title\": \"Code Location\",\n          \"type\": \"boolean\"\n        },\n        \"resource_key\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/resource-key` label. The value will be taken from the current Dagster resource key.\",\n          \"title\": \"Resource Key\",\n          \"type\": \"boolean\"\n        },\n        \"git_sha\": {\n          \"default\": true,\n          \"description\": \"Whether to match on `dagster/git-sha` label. The value will be taken from `DAGSTER_CLOUD_GIT_SHA` environment variable.\",\n          \"title\": \"Git Sha\",\n          \"type\": \"boolean\"\n        },\n        \"run_id\": {\n          \"default\": false,\n          \"description\": \"Whether to match on `dagster/run-id` label. The value will be taken from the current Dagster run ID.\",\n          \"title\": \"Run Id\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"MatchDagsterLabels\",\n      \"type\": \"object\"\n    }\n  },\n  \"description\": \"Defines the strategy for sharing `RayCluster` resources with other Dagster steps.\\n\\nBy default, the cluster is expected to be created by Dagster during one of the previously executed steps.\",\n  \"properties\": {\n    \"enabled\": {\n      \"default\": false,\n      \"description\": \"Whether to enable sharing of RayClusters.\",\n      \"title\": \"Enabled\",\n      \"type\": \"boolean\"\n    },\n    \"match_dagster_labels\": {\n      \"$ref\": \"#/$defs/MatchDagsterLabels\",\n      \"description\": \"Configuration for matching on Dagster-generated labels.\"\n    },\n    \"match_labels\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Additional user-provided labels to match on.\",\n      \"title\": \"Match Labels\"\n    },\n    \"ttl_seconds\": {\n      \"default\": 1800.0,\n      \"description\": \"Time to live for the lock placed on the `RayCluster` resource, marking it as in use by the current Dagster step.\",\n      \"title\": \"Ttl Seconds\",\n      \"type\": \"number\"\n    }\n  },\n  \"title\": \"ClusterSharing\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>enabled</code>                 (<code>bool</code>)             </li> <li> <code>match_dagster_labels</code>                 (<code>MatchDagsterLabels</code>)             </li> <li> <code>match_labels</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>ttl_seconds</code>                 (<code>float</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing.enabled","title":"enabled  <code>pydantic-field</code>","text":"<pre><code>enabled: bool = False\n</code></pre> <p>Whether to enable sharing of RayClusters.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing.match_dagster_labels","title":"match_dagster_labels  <code>pydantic-field</code>","text":"<pre><code>match_dagster_labels: MatchDagsterLabels\n</code></pre> <p>Configuration for matching on Dagster-generated labels.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing.match_labels","title":"match_labels  <code>pydantic-field</code>","text":"<pre><code>match_labels: dict[str, str] | None = None\n</code></pre> <p>Additional user-provided labels to match on.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.configs.ClusterSharing.ttl_seconds","title":"ttl_seconds  <code>pydantic-field</code>","text":"<pre><code>ttl_seconds: float = DEFAULT_CLUSTER_SHARING_TTL_SECONDS\n</code></pre> <p>Time to live for the lock placed on the <code>RayCluster</code> resource, marking it as in use by the current Dagster step.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResource","title":"dagster_ray.kuberay.resources.base.BaseKubeRayResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>RayResource</code>, <code>ABC</code></p> Show JSON schema: <pre><code>{\n  \"$defs\": {\n    \"ExecutionOptionsConfig\": {\n      \"properties\": {\n        \"cpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Cpu\"\n        },\n        \"gpu\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Gpu\"\n        },\n        \"object_store_memory\": {\n          \"anyOf\": [\n            {\n              \"type\": \"integer\"\n            },\n            {\n              \"type\": \"null\"\n            }\n          ],\n          \"default\": null,\n          \"title\": \"Object Store Memory\"\n        }\n      },\n      \"title\": \"ExecutionOptionsConfig\",\n      \"type\": \"object\"\n    },\n    \"Lifecycle\": {\n      \"properties\": {\n        \"create\": {\n          \"default\": true,\n          \"description\": \"Whether to create the resource. If set to `False`, the user can manually call `.create` instead.\",\n          \"title\": \"Create\",\n          \"type\": \"boolean\"\n        },\n        \"wait\": {\n          \"default\": true,\n          \"description\": \"Whether to wait for the remote Ray cluster to become ready to accept connections. If set to `False`, the user can manually call `.wait` instead.\",\n          \"title\": \"Wait\",\n          \"type\": \"boolean\"\n        },\n        \"connect\": {\n          \"default\": true,\n          \"description\": \"Whether to run `ray.init` against the remote Ray cluster. If set to `False`, the user can manually call `.connect` instead.\",\n          \"title\": \"Connect\",\n          \"type\": \"boolean\"\n        },\n        \"cleanup\": {\n          \"default\": \"always\",\n          \"description\": \"Resource cleanup policy. Determines when the resource should be deleted after Dagster step execution or during interruption.\",\n          \"enum\": [\n            \"never\",\n            \"always\",\n            \"on_exception\"\n          ],\n          \"title\": \"Cleanup\",\n          \"type\": \"string\"\n        }\n      },\n      \"title\": \"Lifecycle\",\n      \"type\": \"object\"\n    },\n    \"RayDataExecutionOptions\": {\n      \"properties\": {\n        \"execution_options\": {\n          \"$ref\": \"#/$defs/ExecutionOptionsConfig\"\n        },\n        \"cpu_limit\": {\n          \"default\": 5000,\n          \"title\": \"Cpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"gpu_limit\": {\n          \"default\": 0,\n          \"title\": \"Gpu Limit\",\n          \"type\": \"integer\"\n        },\n        \"verbose_progress\": {\n          \"default\": true,\n          \"title\": \"Verbose Progress\",\n          \"type\": \"boolean\"\n        },\n        \"use_polars\": {\n          \"default\": true,\n          \"title\": \"Use Polars\",\n          \"type\": \"boolean\"\n        }\n      },\n      \"title\": \"RayDataExecutionOptions\",\n      \"type\": \"object\"\n    }\n  },\n  \"properties\": {\n    \"lifecycle\": {\n      \"$ref\": \"#/$defs/Lifecycle\",\n      \"description\": \"Actions to perform during resource setup.\"\n    },\n    \"timeout\": {\n      \"default\": 600.0,\n      \"description\": \"Timeout for Ray readiness in seconds\",\n      \"title\": \"Timeout\",\n      \"type\": \"number\"\n    },\n    \"ray_init_options\": {\n      \"description\": \"Additional keyword arguments to pass to `ray.init()` call, such as `runtime_env`, `num_cpus`, etc. Dagster's `EnvVar` is supported. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.init.html).\",\n      \"title\": \"Ray Init Options\",\n      \"type\": \"object\"\n    },\n    \"data_execution_options\": {\n      \"$ref\": \"#/$defs/RayDataExecutionOptions\"\n    },\n    \"redis_port\": {\n      \"default\": 10001,\n      \"description\": \"Redis port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Redis Port\",\n      \"type\": \"integer\"\n    },\n    \"dashboard_port\": {\n      \"default\": 8265,\n      \"description\": \"Dashboard port for connection. Make sure to match with the actual available port.\",\n      \"title\": \"Dashboard Port\",\n      \"type\": \"integer\"\n    },\n    \"env_vars\": {\n      \"anyOf\": [\n        {\n          \"additionalProperties\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"object\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"description\": \"Environment variables to pass to the Ray cluster.\",\n      \"title\": \"Env Vars\"\n    },\n    \"enable_tracing\": {\n      \"default\": false,\n      \"description\": \"Enable tracing: inject `RAY_PROFILING=1` and `RAY_task_events_report_interval_ms=0` into the Ray cluster configuration. This allows using `ray.timeline()` to fetch recorded task events. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.timeline.html#ray-timeline)\",\n      \"title\": \"Enable Tracing\",\n      \"type\": \"boolean\"\n    },\n    \"enable_actor_task_logging\": {\n      \"default\": false,\n      \"description\": \"Enable actor task logging: inject `RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1` into the Ray cluster configuration.\",\n      \"title\": \"Enable Actor Task Logging\",\n      \"type\": \"boolean\"\n    },\n    \"enable_debug_post_mortem\": {\n      \"default\": false,\n      \"description\": \"Enable post-mortem debugging: inject `RAY_DEBUG_POST_MORTEM=1` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/ray-distributed-debugger.html)\",\n      \"title\": \"Enable Debug Post Mortem\",\n      \"type\": \"boolean\"\n    },\n    \"enable_legacy_debugger\": {\n      \"default\": false,\n      \"description\": \"Enable legacy debugger: inject `RAY_DEBUG=legacy` into the Ray cluster configuration. Learn more: [KubeRay docs](https://docs.ray.io/en/latest/ray-observability/user-guides/debug-apps/ray-debugging.html#using-the-ray-debugger)\",\n      \"title\": \"Enable Legacy Debugger\",\n      \"type\": \"boolean\"\n    },\n    \"worker_process_setup_hook\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"A module path to a function that will be called on each worker process after it starts, but before tasks/actors are scheduled. Must be importable by Ray workers. More details in [Ray docs](https://docs.ray.io/en/latest/ray-core/api/doc/ray.runtime_env.RuntimeEnv.html).\",\n      \"title\": \"Worker Process Setup Hook\"\n    },\n    \"image\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"description\": \"Image to inject into the `RayCluster` spec. Defaults to `dagster/image` run tag. Images already provided in the `RayCluster` spec won't be overridden.\",\n      \"title\": \"Image\"\n    },\n    \"deployment_name\": {\n      \"default\": \"dev\",\n      \"description\": \"Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.\",\n      \"title\": \"Deployment Name\",\n      \"type\": \"string\"\n    },\n    \"failure_tolerance_timeout\": {\n      \"default\": 0.0,\n      \"description\": \"The period in seconds to wait for the cluster to transition out of `failed` state if it reaches it. This state can be transient under certain conditions. With the default value of 0, the first `failed` state appearance will raise an exception immediately.\",\n      \"title\": \"Failure Tolerance Timeout\",\n      \"type\": \"number\"\n    },\n    \"poll_interval\": {\n      \"default\": 1.0,\n      \"description\": \"Poll interval for various API requests\",\n      \"title\": \"Poll Interval\",\n      \"type\": \"number\"\n    }\n  },\n  \"title\": \"BaseKubeRayResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>lifecycle</code>                 (<code>Lifecycle</code>)             </li> <li> <code>timeout</code>                 (<code>float</code>)             </li> <li> <code>ray_init_options</code>                 (<code>dict[str, Any]</code>)             </li> <li> <code>data_execution_options</code>                 (<code>RayDataExecutionOptions</code>)             </li> <li> <code>redis_port</code>                 (<code>int</code>)             </li> <li> <code>dashboard_port</code>                 (<code>int</code>)             </li> <li> <code>env_vars</code>                 (<code>dict[str, str] | None</code>)             </li> <li> <code>enable_tracing</code>                 (<code>bool</code>)             </li> <li> <code>enable_actor_task_logging</code>                 (<code>bool</code>)             </li> <li> <code>enable_debug_post_mortem</code>                 (<code>bool</code>)             </li> <li> <code>enable_legacy_debugger</code>                 (<code>bool</code>)             </li> <li> <code>worker_process_setup_hook</code>                 (<code>str | None</code>)             </li> <li> <code>_context</code>                 (<code>BaseContext | None</code>)             </li> <li> <code>_creation_verb</code>                 (<code>str</code>)             </li> <li> <code>image</code>                 (<code>str | None</code>)             </li> <li> <code>deployment_name</code>                 (<code>str</code>)             </li> <li> <code>failure_tolerance_timeout</code>                 (<code>float</code>)             </li> <li> <code>poll_interval</code>                 (<code>float</code>)             </li> <li> <code>_host</code>                 (<code>str</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResource-attributes","title":"Attributes","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResource.image","title":"image  <code>pydantic-field</code>","text":"<pre><code>image: str | None = None\n</code></pre> <p>Image to inject into the <code>RayCluster</code> spec. Defaults to <code>dagster/image</code> run tag. Images already provided in the <code>RayCluster</code> spec won't be overridden.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResource.deployment_name","title":"deployment_name  <code>pydantic-field</code>","text":"<pre><code>deployment_name: str = DEFAULT_DEPLOYMENT_NAME\n</code></pre> <p>Dagster deployment name. Is used as a prefix for the Kubernetes resource name. Dagster Cloud variables are used to determine the default value.</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.resources.base.BaseKubeRayResource.poll_interval","title":"poll_interval  <code>pydantic-field</code>","text":"<pre><code>poll_interval: float = 1.0\n</code></pre> <p>Poll interval for various API requests</p>"},{"location":"api/kuberay/#resources","title":"Resources","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayJobClientResource","title":"dagster_ray.kuberay.KubeRayJobClientResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource[RayJobClient]</code></p> <p>This configurable resource provides a dagster_ray.kuberay.client.RayJobClient.</p> Show JSON schema: <pre><code>{\n  \"description\": \"This configurable resource provides a [dagster_ray.kuberay.client.RayJobClient][].\",\n  \"properties\": {\n    \"kube_context\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Context\"\n    },\n    \"kube_config\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Config\"\n    }\n  },\n  \"title\": \"KubeRayJobClientResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kube_context</code>                 (<code>str | None</code>)             </li> <li> <code>kube_config</code>                 (<code>str | None</code>)             </li> </ul>"},{"location":"api/kuberay/#dagster_ray.kuberay.KubeRayClusterClientResource","title":"dagster_ray.kuberay.KubeRayClusterClientResource  <code>pydantic-model</code>","text":"<p>               Bases: <code>ConfigurableResource[RayClusterClient]</code></p> <p>This configurable resource provides a dagster_ray.kuberay.client.RayClusterClient.</p> Show JSON schema: <pre><code>{\n  \"description\": \"This configurable resource provides a [dagster_ray.kuberay.client.RayClusterClient][].\",\n  \"properties\": {\n    \"kube_context\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Context\"\n    },\n    \"kube_config\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Kube Config\"\n    }\n  },\n  \"title\": \"KubeRayClusterClientResource\",\n  \"type\": \"object\"\n}\n</code></pre> <p>Fields:</p> <ul> <li> <code>kube_context</code>                 (<code>str | None</code>)             </li> <li> <code>kube_config</code>                 (<code>str | None</code>)             </li> </ul>"},{"location":"api/kuberay/#sensors","title":"Sensors","text":"<p>A Dagster sensor that monitors shared <code>RayCluster</code> resources created by the current Dagster code location (with a <code>dagster/code-location=&lt;current-code-location&gt;</code> label selector) and submits jobs to delete clusters either: - use Cluster Sharing (<code>dagster/cluster-sharing=true</code>) and have expired - are older than <code>DAGSTER_RAY_CLUSTER_EXPIRATION_SECONDS</code> (defaults to 4 hours)</p> <p>By default it monitors the <code>ray</code> namespace. This can be configured by setting <code>DAGSTER_RAY_NAMESPACES</code> (accepts a comma-separated list of namespaces).</p>"},{"location":"api/kuberay/#dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters","title":"dagster_ray.kuberay.sensors.cleanup_expired_kuberay_clusters","text":"<pre><code>cleanup_expired_kuberay_clusters(\n    context: SensorEvaluationContext, raycluster_client: ResourceParam[RayClusterClient]\n) -&gt; Generator[RunRequest | SkipReason, None, None]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/sensors.py</code> <pre><code>@dg.sensor(job=delete_kuberay_clusters, minimum_interval_seconds=5 * 60)\ndef cleanup_expired_kuberay_clusters(\n    context: dg.SensorEvaluationContext,\n    raycluster_client: dg.ResourceParam[RayClusterClient],\n) -&gt; Generator[dg.RunRequest | dg.SkipReason, None, None]:\n    f\"\"\"A Dagster sensor that monitors shared `RayCluster` resources created by the current code location and submits jobs to delete clusters that either:\n        - use [Cluster Sharing](../tutorial/#cluster-sharing) (`dagster/cluster-sharing=true`) and have expired\n        - are older than `DAGSTER_RAY_CLUSTER_EXPIRATION_SECONDS` (defaults to 4 hours)\n\n    By default it monitors the `ray` namespace. This can be configured by setting `{DAGSTER_RAY_NAMESPACES_ENV_VAR}` (accepts a comma-separated list of namespaces).\"\"\"\n    assert context.code_location_origin is not None\n\n    found_any = False\n    namespaces = os.environ.get(DAGSTER_RAY_NAMESPACES_ENV_VAR, \"ray\").split(\",\")\n    expiration_seconds = int(\n        os.environ.get(\n            DAGSTER_RAY_CLUSTER_EXPIRATION_SECONDS_ENV_VAR, DAGSTER_RAY_CLUSTER_EXPIRATION_SECONDS_DEFAULT_VALUE\n        )\n    )\n\n    for namespace in namespaces:\n        cluster_names = []\n        for cluster in raycluster_client.list(\n            namespace=namespace,\n            label_selector=f\"dagster/code-location={context.code_location_origin.location_name}\",\n        ).get(\"items\", []):\n            if cluster[\"metadata\"].get(\"labels\", {}).get(\"dagster/cluster-sharing\") == \"true\":\n                locks = ClusterSharingLock.parse_all_locks(\n                    cast(dict[str, str], cluster.get(\"metadata\", {}).get(\"annotations\", {}))\n                )\n                alive_locks = ClusterSharingLock.get_alive_locks(locks)\n                if not alive_locks:\n                    context.log.info(\n                        f\"Found expired RayCluster with cluster sharing enabled: {cluster['metadata']['namespace']}/{cluster['metadata']['name']}\"\n                    )\n                    cluster_names.append(cluster[\"metadata\"][\"name\"])\n            else:\n                # check if the cluster age since creation time exceeds expiration_seconds\n\n                # early exit for clusters with owners\n                if cluster.get(\"metadata\", {}).get(\"ownerReferences\"):\n                    continue\n\n                if cluster.get(\"metadata\", {}).get(\"creationTimestamp\"):\n                    cluster_age = datetime.now(timezone.utc) - datetime.strptime(\n                        cluster[\"metadata\"][\"creationTimestamp\"], \"%Y-%m-%dT%H:%M:%SZ\"\n                    ).replace(tzinfo=timezone.utc)\n                    if cluster_age.total_seconds() &gt;= expiration_seconds:\n                        context.log.info(\n                            f\"Found expired RayCluster (time since creation exceeds {expiration_seconds} seconds): {cluster['metadata']['namespace']}/{cluster['metadata']['name']}\"\n                        )\n                        cluster_names.append(cluster[\"metadata\"][\"name\"])\n\n        if len(cluster_names) &gt; 0:\n            found_any = True\n            yield dg.RunRequest(\n                run_config=dg.RunConfig(\n                    ops={\n                        \"delete_kuberay_clusters_op\": DeleteKubeRayClustersConfig(\n                            namespace=namespace,\n                            clusters=[RayClusterRef(name=name) for name in cluster_names],\n                        )\n                    }\n                )\n            )\n\n    if not found_any:\n        yield dg.SkipReason(f\"No expired RayClusters found in namespaces: {namespaces}\")\n</code></pre>"},{"location":"api/kuberay/#kubernetes-api-clients","title":"Kubernetes API Clients","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient","title":"dagster_ray.kuberay.client.RayClusterClient","text":"<pre><code>RayClusterClient(kube_config: str | None = None, kube_context: str | None = None, api_client: ApiClient | None = None)\n</code></pre> <p>               Bases: <code>BaseKubeRayClient[RayClusterStatus]</code></p> Source code in <code>src/dagster_ray/kuberay/client/raycluster/client.py</code> <pre><code>def __init__(\n    self,\n    kube_config: str | None = None,\n    kube_context: str | None = None,\n    api_client: ApiClient | None = None,\n) -&gt; None:\n    self.kube_config = kube_config\n    self.kube_context = kube_context\n\n    # note: this call must happen BEFORE creating the api clients\n    if api_client is None:\n        load_kubeconfig(context=self.kube_context, config_file=self.kube_config)\n\n    super().__init__(group=GROUP, version=VERSION, kind=KIND, plural=PLURAL, api_client=api_client)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.create","title":"create","text":"<pre><code>create(body: dict[str, Any], namespace: str) -&gt; Any\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def create(self, body: dict[str, Any], namespace: str) -&gt; Any:\n    return self._api.create_namespaced_custom_object(\n        group=self.group,\n        version=body.get(\"apiVersion\", f\"{self.group}/{self.version}\").split(\"/\")[1],\n        plural=self.plural,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.delete","title":"delete","text":"<pre><code>delete(name: str, namespace: str)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def delete(self, name: str, namespace: str):\n    return self._api.delete_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.get","title":"get","text":"<pre><code>get(name: str, namespace: str) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def get(self, name: str, namespace: str) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.get_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            name=name,\n            namespace=namespace,\n        )\n        return resource\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.list","title":"list","text":"<pre><code>list(namespace: str, label_selector: str = '', async_req: bool = False) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def list(self, namespace: str, label_selector: str = \"\", async_req: bool = False) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.list_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            namespace=namespace,\n            label_selector=label_selector,\n            async_req=async_req,\n        )\n        if \"items\" in resource:\n            return resource\n        else:\n            return {}\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayClusterClient.update","title":"update","text":"<pre><code>update(name: str, namespace: str, body: Any)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def update(self, name: str, namespace: str, body: Any):\n    return self._api.patch_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient","title":"dagster_ray.kuberay.client.RayJobClient","text":"<pre><code>RayJobClient(kube_config: str | None = None, kube_context: str | None = None, api_client: ApiClient | None = None)\n</code></pre> <p>               Bases: <code>BaseKubeRayClient[RayJobStatus]</code></p> Source code in <code>src/dagster_ray/kuberay/client/rayjob/client.py</code> <pre><code>def __init__(\n    self,\n    kube_config: str | None = None,\n    kube_context: str | None = None,\n    api_client: ApiClient | None = None,\n) -&gt; None:\n    self.kube_config = kube_config\n    self.kube_context = kube_context\n\n    # this call must happen BEFORE creating K8s apis\n    if api_client is None:\n        load_kubeconfig(config_file=kube_config, context=kube_context)\n\n    super().__init__(group=GROUP, version=VERSION, kind=KIND, plural=PLURAL, api_client=api_client)\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient-functions","title":"Functions","text":""},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.create","title":"create","text":"<pre><code>create(body: dict[str, Any], namespace: str) -&gt; Any\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def create(self, body: dict[str, Any], namespace: str) -&gt; Any:\n    return self._api.create_namespaced_custom_object(\n        group=self.group,\n        version=body.get(\"apiVersion\", f\"{self.group}/{self.version}\").split(\"/\")[1],\n        plural=self.plural,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.delete","title":"delete","text":"<pre><code>delete(name: str, namespace: str)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def delete(self, name: str, namespace: str):\n    return self._api.delete_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.get","title":"get","text":"<pre><code>get(name: str, namespace: str) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def get(self, name: str, namespace: str) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.get_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            name=name,\n            namespace=namespace,\n        )\n        return resource\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.list","title":"list","text":"<pre><code>list(namespace: str, label_selector: str = '', async_req: bool = False) -&gt; dict[str, Any]\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def list(self, namespace: str, label_selector: str = \"\", async_req: bool = False) -&gt; dict[str, Any]:\n    from kubernetes.client import ApiException\n\n    try:\n        resource: Any = self._api.list_namespaced_custom_object(\n            group=self.group,\n            version=self.version,\n            plural=self.plural,\n            namespace=namespace,\n            label_selector=label_selector,\n            async_req=async_req,\n        )\n        if \"items\" in resource:\n            return resource\n        else:\n            return {}\n    except ApiException as e:\n        if e.status == 404:\n            return {}\n\n        raise\n</code></pre>"},{"location":"api/kuberay/#dagster_ray.kuberay.client.RayJobClient.update","title":"update","text":"<pre><code>update(name: str, namespace: str, body: Any)\n</code></pre> Source code in <code>src/dagster_ray/kuberay/client/base.py</code> <pre><code>def update(self, name: str, namespace: str, body: Any):\n    return self._api.patch_namespaced_custom_object(\n        group=self.group,\n        version=self.version,\n        plural=self.plural,\n        name=name,\n        body=body,\n        namespace=namespace,\n    )\n</code></pre>"},{"location":"api/types/","title":"Types API Reference","text":"<p>Type definitions and base classes used throughout <code>dagster-ray</code>.</p>"},{"location":"api/types/#dagster_ray.types.AnyDagsterContext","title":"dagster_ray.types.AnyDagsterContext  <code>module-attribute</code>","text":"<pre><code>AnyDagsterContext: TypeAlias = OpExecutionContext | AssetExecutionContext | InitResourceContext\n</code></pre>"},{"location":"api/types/#dagster_ray.types.OpOrAssetExecutionContext","title":"dagster_ray.types.OpOrAssetExecutionContext  <code>module-attribute</code>","text":"<pre><code>OpOrAssetExecutionContext: TypeAlias = OpExecutionContext | AssetExecutionContext\n</code></pre>"},{"location":"tutorial/","title":"Tutorial","text":""},{"location":"tutorial/#dagster-external-ray-clusters","title":"Dagster + External Ray Clusters","text":"<p>Check out External Ray Clusters tutorial if you want to run Ray jobs on existing external Ray clusters.</p>"},{"location":"tutorial/#dagster-kuberay","title":"Dagster + KubeRay","text":"<p>See KubeRay tutorial if you want to use KubeRay's <code>RayJob</code> and <code>RayCluster</code> managed from Dagster</p>"},{"location":"tutorial/external/","title":"Dagster + External Ray Clusters Tutorial","text":"<p>This tutorial covers how to use dagster-ray with external Ray clusters - clusters that are managed outside of Dagster. This approach is ideal when you have existing Ray infrastructure or want to separate cluster management from your data pipelines.</p>"},{"location":"tutorial/external/#when-to-use-each-approach","title":"When to Use Each Approach","text":""},{"location":"tutorial/external/#use-localray-when","title":"Use <code>LocalRay</code> when:","text":"<ul> <li>Developing and testing locally</li> </ul>"},{"location":"tutorial/external/#use-rayrunlauncher-when","title":"Use <code>RayRunLauncher</code> when:","text":"<ul> <li>You want to run all Dagster pipelines on Ray</li> <li>You want very fast Dagster run submission</li> </ul>"},{"location":"tutorial/external/#use-ray_executor-when","title":"Use <code>ray_executor</code> when:","text":"<ul> <li>You want selective Ray execution for specific assets</li> <li>You want very fast Dagster step submission</li> </ul>"},{"location":"tutorial/external/#use-pipesrayjobclient-when","title":"Use <code>PipesRayJobClient</code> when:","text":"<ul> <li>You want to decouple Ray workloads from orchestration code</li> <li>You have existing Ray scripts you want to integrate</li> <li>You want full separation between Dagster and Ray environments</li> </ul>"},{"location":"tutorial/external/#prerequisites","title":"Prerequisites","text":"<p>Before getting started, you'll need:</p> <ul> <li>A Ray cluster (can be local Ray for development, or remote Ray cluster for production)</li> <li>dagster-ray installed:   <pre><code>pip install dagster-ray\n</code></pre></li> <li>For remote clusters: Ray cluster address and appropriate network access</li> </ul>"},{"location":"tutorial/external/#localray-development-and-testing","title":"LocalRay - Development and Testing","text":"<p><code>LocalRay</code> is perfect for local development and testing. It provides the same interface as other Ray resources but runs Ray locally on your machine.</p> <pre><code>import dagster as dg\nfrom dagster_ray import LocalRay\nimport ray\n\n\n@dg.asset\ndef batch_processing_results(ray_cluster: LocalRay) -&gt; dict:\n    \"\"\"Process multiple batches in parallel using local Ray.\"\"\"\n    refs = [process_batch.remote(i, size) for i, size in enumerate(batch_sizes)]\n\n    # Collect results\n    results = ray.get(refs)\n\n    return aggregate(results)\n\n\ndefinitions = dg.Definitions(\n    assets=[batch_processing_results], resources={\"ray_cluster\": LocalRay()}\n)\n</code></pre> <p>You can customize the local Ray configuration:</p> <pre><code>from dagster_ray import LocalRay\n\nlocal_ray = LocalRay(\n    # Ray initialization options\n    ray_init_options={\n        \"num_cpus\": 8,\n        \"num_gpus\": 1,\n        \"object_store_memory\": 1000000000,  # 1GB\n        \"runtime_env\": {\"pip\": [\"numpy\", \"polars\", \"scikit-learn\"]},\n    },\n)\n</code></pre>"},{"location":"tutorial/external/#rayrunlauncher","title":"RayRunLauncher","text":"<p><code>RayRunLauncher</code> executes entire Dagster runs as Ray jobs. This is useful for Dagster deployments that need to be fully executed on Ray.</p> <p>Tip</p> <p>Make sure the Ray cluster has access to Dagster's metadata database!</p>"},{"location":"tutorial/external/#usage","title":"Usage","text":"<p>Configure the run launcher in your <code>dagster.yaml</code>:</p> <pre><code>run_launcher:\n  module: dagster_ray\n  class: RayRunLauncher\n  config:\n    address:\n      env: RAY_ADDRESS\n    timeout: 1800\n    metadata:\n      foo: bar\n      runtime_env:\n      env_vars:\n        FOO: bar\n      pip:\n        - polars\n</code></pre> <p>With <code>RayRunLauncher</code> enabled, your regular Dagster assets will automatically run on Ray:</p> <pre><code>import dagster as dg\n\n\n@dg.asset\ndef regular_asset():\n    \"\"\"This asset will be submitted as a Ray job.\"\"\"\n    ...\n</code></pre> <p>All the steps will be executed in a single Ray job, unless a custom executor is used.</p> <p>It's possible to provide additional runtime configuration via the <code>dagster-ray/config</code> run tag.</p>"},{"location":"tutorial/external/#ray_executor","title":"ray_executor","text":"<p><code>ray_executor</code> runs Dagster steps (ops or assets) as Ray jobs (in parallel).</p> <p>Tip</p> <p>Make sure the Ray cluster has access to Dagster's metadata database!</p>"},{"location":"tutorial/external/#usage_1","title":"Usage","text":"<p>The executor can be enabled at <code>Definitions</code> level:</p> <pre><code>import dagster as dg\nfrom dagster_ray import ray_executor\n\n\ndefinitions = dg.Definitions(\n    executor=ray_executor.configured(\n        {\"address\": dg.EnvVar(\"RAY_ADDRESS\"), \"runtime_env\": {\"pip\": [\"polars\"]}}\n    )\n)\n</code></pre> <p>It's possible to configure individual assets via the <code>dagster-ray/config</code> op tag:</p> <pre><code>@dg.asset(\n    op_tags={\n        \"dagster-ray/config\": {\n            \"num_cpus\": 2,\n        }\n    }\n)\ndef my_asset(): ...\n</code></pre>"},{"location":"tutorial/external/#pipesrayjobclient-external-script-execution","title":"PipesRayJobClient - External Script Execution","text":"<p><code>PipesRayJobClient</code> lets you submit external Python scripts to Ray clusters as Ray jobs. This is perfect for decoupling your Ray workloads from Dagster orchestration code and Python environment.</p>"},{"location":"tutorial/external/#external-ray-script","title":"External Ray Script","text":"<p>First, create a script that will run on the Ray cluster:</p> ml_training.py<pre><code># ml_training.py - External Ray script\nimport ray\nfrom dagster_pipes import open_dagster_pipes\n\n\n@ray.remote\ndef train_ml_model(partition_id: int):\n    \"\"\"Dummy ML training function.\"\"\"\n    import time\n\n    time.sleep(1)  # Simulate work\n    return {\"partition_id\": partition_id, \"accuracy\": 0.95}\n\n\ndef main():\n    with open_dagster_pipes() as context:\n        context.log.info(\"Starting distributed ML training\")\n\n        # Get configuration from Dagster\n        num_partitions = context.get_extra(\"num_partitions\", 4)\n\n        # Submit training jobs\n        futures = [train_ml_model.remote(i) for i in range(num_partitions)]\n        results = ray.get(futures)\n\n        context.log.info(f\"Training complete on {len(results)} partitions\")\n\n        # Report results\n        context.report_asset_materialization(\n            metadata={\"num_partitions\": len(results), \"results\": results},\n            data_version=\"alpha\",\n        )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre>"},{"location":"tutorial/external/#dagster-asset-using-pipes","title":"Dagster Asset Using Pipes","text":"<p>Now, let's define a Dagster asset that will be calling the above external script via Dagster Pipes.</p> <pre><code>import dagster as dg\nfrom dagster_ray import PipesRayJobClient\nfrom ray.job_submission import JobSubmissionClient\n\n\nclass MLTrainingConfig(dg.Config):\n    num_partitions: int = 4\n\n\n@dg.asset\ndef distributed_ml_training(\n    context: dg.AssetExecutionContext,\n    ray_client: PipesRayJobClient,\n    config: MLTrainingConfig,\n) -&gt; dict:\n    \"\"\"Run distributed ML training using Ray Pipes.\"\"\"\n\n    return ray_client.run(\n        context=context,\n        submit_job_params={\n            \"entrypoint\": \"python ml_training.py\",\n            \"runtime_env\": {\n                \"pip\": [\"dagster-pipes\", \"torch\"],  # (1)!\n            },\n        },\n        extras={\n            \"num_partitions\": config.num_partitions,\n        },\n    )\n\n\ndefinitions = dg.Definitions(\n    assets=[distributed_ml_training],\n    resources={\n        \"ray_client\": PipesRayJobClient(\n            client=JobSubmissionClient(),\n            timeout=1800,\n        )\n    },\n)\n</code></pre> <ol> <li> <code>dagster-pipes</code> has to be installed in the remote environment!</li> </ol> <p>When materializing the asset, the <code>PipesRayJobClient</code> will submit the script as a Ray job, monitor its status, and stream back logs and Dagster metadata.</p>"},{"location":"tutorial/external/#conclusion","title":"Conclusion","text":"<p>That's it! You now have a comprehensive understanding of how to use dagster-ray with external Ray clusters, from local development with <code>LocalRay</code> to production deployments with <code>PipesRayJobClient</code>.</p>"},{"location":"tutorial/kuberay/","title":"Dagster + KubeRay","text":"<p>This tutorial explains how to use <code>dagster-ray</code> with KubeRay to automatically create and manage Ray clusters for Dagster steps.</p>"},{"location":"tutorial/kuberay/#prerequisites","title":"Prerequisites","text":"<p>Before getting started, you'll need:</p> <ul> <li>A Kubernetes cluster with KubeRay Operator installed</li> <li>A <code>kubectl</code> configured to access your cluster or a kubeconfig file (resources can be configured to use it)</li> <li><code>dagster-ray</code> installed with KubeRay support:   <pre><code>pip install 'dagster-ray[kuberay]'\n</code></pre></li> </ul>"},{"location":"tutorial/kuberay/#kuberayinteractivejob","title":"KubeRayInteractiveJob","text":"<p><code>KubeRayInteractiveJob</code> is the recommended way to run Ray workloads with automatic cluster management. It creates a <code>RayJob</code>, connects to it in client mode and sets the <code>jobId</code> field. Cleanup is handled by the KubeRay controller or by the resource lifecycle logic.</p> <p>Warning</p> <p>KubeRay Operator 1.3.0 is required for this feature.</p>"},{"location":"tutorial/kuberay/#basic-example","title":"Basic Example","text":"<p>Here's a simple example that creates a Ray cluster and runs a distributed computation:</p> <pre><code>import dagster as dg\nfrom dagster_ray.kuberay import KubeRayInteractiveJob, RayResource\nimport ray\n\n\n@ray.remote\ndef sum_of_squares_in_slice(start: int, end: int) -&gt; int:\n    return sum(i**2 for i in range(start, end))\n\n\n@dg.asset\ndef sum_of_squares(ray_cluster: RayResource) -&gt; int:\n    # Split work across workers\n    num_workers = 4\n    chunk_size = 1000 // num_workers\n\n    futures = [\n        sum_of_squares_in_slice.remote(i * chunk_size + 1, (i + 1) * chunk_size + 1)\n        for i in range(num_workers)\n    ]\n\n    # Sum results from all workers\n    return sum(ray.get(futures))\n\n\ndefinitions = dg.Definitions(\n    assets=[compute_sum_of_squares], resources={\"ray_cluster\": KubeRayInteractiveJob()}\n)\n</code></pre> <p>Note</p> <p><code>RayResource</code> is the common interface for all <code>dagster-ray</code> Ray resource which can be used as backend-agnostic type annotation</p> <p>By default, the image will be inherited from the <code>dagster/image</code> Run tag. Alternatively, you can specify it using the <code>image</code> parameter.</p> <p><code>RayJob</code>'s <code>.metadata.name</code> will be generated automatically if not provided.</p>"},{"location":"tutorial/kuberay/#advanced-configuration","title":"Advanced Configuration","text":"<p>You can customize the Ray cluster configuration:</p> <pre><code>from dagster_ray.kuberay import (\n    InteractiveRayJobConfig,\n    InteractiveRayJobSpec,\n    KubeRayInteractiveJob,\n)\nfrom dagster_ray.kuberay.configs import RayClusterSpec\n\nray_cluster = KubeRayInteractiveJob(\n    ray_job=InteractiveRayJobConfig(\n        metadata={\n            \"namespace\": \"my-custom-namespace\",\n            \"labels\": {\"team\": \"my-team\"},\n            \"annotations\": {\"example\": \"annotation\"},\n        },\n        spec=InteractiveRayJobSpec(\n            ttl_seconds_after_finished=3600,\n            deletion_strategy={\n                \"onSuccess\": {\"policy\": \"DeleteSelf\"},\n                \"onFailure\": {\"policy\": \"DeleteSelf\"},\n            },\n            ray_cluster_spec=RayClusterSpec(\n                worker_group_specs=[\n                    {\n                        \"groupName\": \"workers\",\n                        \"replicas\": 0,\n                        \"minReplicas\": 0,\n                        \"maxReplicas\": 10,\n                        \"rayStartParams\": {},\n                        \"template\": {\n                            \"metadata\": {\"labels\": {}, \"annotations\": {}},\n                            \"spec\": {\n                                \"imagePullSecrets\": [],\n                                \"containers\": [\n                                    {\n                                        \"volumeMounts\": [],\n                                        \"name\": \"worker\",\n                                        \"imagePullPolicy\": \"Always\",\n                                    }\n                                ],\n                                \"volumes\": [],\n                                \"affinity\": {},\n                                \"tolerations\": [],\n                                \"nodeSelector\": {},\n                            },\n                        },\n                    }\n                ]\n            ),\n        ),\n    ),\n    lifecycle=Lifecycle(cleanup=\"always\"),\n    timeout=600.0,\n)\n</code></pre>"},{"location":"tutorial/kuberay/#kuberaycluster","title":"KubeRayCluster","text":"<p>While <code>KubeRayInteractiveJob</code> is recommended for production environments, <code>KubeRayCluster</code> might be a better alternative for dev environments.</p> <p>Unlike <code>KubeRayInteractiveJob</code>, which can outsource garbage collection to the KubeRay controller, <code>KubeRayCluster</code> is entirely responsible for cluster management. This is bad for production environments (may result in dangling <code>RayCluster</code> instances if the Dagster step pod fails unexpectedly), but good for dev environments, because it allows <code>dagster-ray</code> to implement cluster sharing.</p>"},{"location":"tutorial/kuberay/#cluster-sharing","title":"Cluster Sharing","text":"<p>With cluster sharing, <code>dagster-ray</code> can reuse existing <code>RayCluster</code> instances left from previous Dagster steps, making <code>KubeRayCluster</code> startup immediate.</p> <p>Therefore, <code>KubeRayCluster</code> is a good choice for dev environments as it can speed up iteration cycles and reduce infrastructure costs at the cost of lower job isolation/stability.</p> <p>Cluster sharing has to be enabled explicitly.</p> <pre><code>from dagster_ray.kuberay import KubeRayCluster\nfrom dagster_ray.kuberay.configs import RayClusterConfig, ClusterSharing\n\nray_cluster = KubeRayCluster(\n    ray_cluster=RayClusterConfig(\n        cluster_sharing=ClusterSharing(enabled=True, ttl_seconds=3600)\n    )\n)\n</code></pre> <p>When enabled, <code>dagster-ray</code> will use configured user-provided and dagster-generated labels to select appropriate clusters from the available ones. By default <code>dagster-ray</code> will match on the following labels:</p> <ul> <li><code>dagster/cluster-sharing</code></li> <li><code>dagster/code-location</code></li> <li><code>dagster/git-sha</code></li> <li><code>dagster/resource-key</code></li> </ul> <p>Each time a cluster is chosen for a step, <code>dagster-ray</code> will apply an annotation to the selected cluster to indicate that it's being used by the current step. This annotation effectively extends the cluster sharing TTL by the configured <code>ttl_seconds</code> amount. Note that the countdown for the TTL starts from the time the annotation is applied, not from the time when the Ray job starts.</p> <p>Configuration options for cluster sharing can be found here.</p>"},{"location":"tutorial/kuberay/#raycluster-garbage-collection","title":"<code>RayCluster</code> Garbage Collection","text":"<p>A <code>RayCluster</code> created by <code>dagster-ray</code> may become dangling for two reasons: - the Dagster step process exits unexpectedly (e.g. OOM), missing the change to run cleanup - if Cluster Sharing is used and the cluster did not expire at the time of the Dagster step completion</p> <p>Since <code>RayCluster</code> doesn't support native garbage collection yet (see TTL and idle termination feature requests), <code>dagster-ray</code> provides a custom garbage collection Dagster sensor.</p> <pre><code>import dagster as dg\nfrom dagster_ray.kuberay import cleanup_expired_rayclusters\n\ndefs = dg.Definitions(\n    sensors=[cleanup_expired_rayclusters],\n)\n</code></pre> <p>It's not recommended for production environments as it will interrupt active long-running jobs and is not safe by any means. It's intended to be used with short-running development environments where job interruption is acceptable.</p>"},{"location":"tutorial/kuberay/#pipeskuberayjobclient","title":"PipesKubeRayJobClient","text":"<p><code>PipesKubeRayJobClient</code> allows you to submit external Python scripts as Ray jobs with automatic cluster management. This is ideal when you want to decouple your Ray workload from your Dagster orchestration code or Python environment.</p>"},{"location":"tutorial/kuberay/#basic-pipes-example","title":"Basic Pipes Example","text":"<p>First, create a Ray script that will run on the cluster:</p> ray_workload.py<pre><code># ml_training.py - External Ray script\nimport ray\nfrom dagster_pipes import open_dagster_pipes\n\n\n@ray.remote\ndef train_ml_model(partition_id: int):\n    \"\"\"Dummy ML training function.\"\"\"\n    import time\n\n    time.sleep(1)  # Simulate work\n    return {\"partition_id\": partition_id, \"accuracy\": 0.95}\n\n\ndef main():\n    with open_dagster_pipes() as context:\n        context.log.info(\"Starting distributed ML training\")\n\n        # Get configuration from Dagster\n        num_partitions = context.get_extra(\"num_partitions\", 4)\n\n        # Submit training jobs\n        futures = [train_ml_model.remote(i) for i in range(num_partitions)]\n        results = ray.get(futures)\n\n        context.log.info(f\"Training complete on {len(results)} partitions\")\n\n        accuracy = sum(result[\"accuracy\"] for result in results) / len(results)\n\n        # Report results\n        context.report_asset_materialization(\n            metadata={\"num_partitions\": len(results), \"accuracy\": accuracy},\n            data_version=\"alpha\",\n        )\n\n\nif __name__ == \"__main__\":\n    main()\n</code></pre> <p>Now create a Dagster asset that uses <code>PipesKubeRayJobClient</code>:</p> <pre><code>import dagster as dg\nfrom dagster_ray.kuberay import PipesKubeRayJobClient\n\n\nclass MLTrainingConfig(dg.Config):\n    num_partitions: int = 4\n\n\n@dg.asset\ndef distributed_computation(\n    context: dg.AssetExecutionContext,\n    config: MLTrainingConfig,\n    ray_pipes_client: PipesKubeRayJobClient,\n) -&gt; None:\n    \"\"\"Run distributed computation using Pipes + KubeRay.\"\"\"\n\n    # Submit the external Ray script\n    return ray_pipes_client.run(\n        context=context,\n        ray_job={\n            \"entrypoint\": \"python ray_workload.py\",\n            \"runtime_env\": {\n                \"pip\": [\"dagster-pipes\", \"torch\"],  # (1)!\n            },\n            \"entrypoint_num_cpus\": 1.0,\n            \"entrypoint_memory\": 2 * 1024 * 1024 * 1024,  # 2GB\n        },\n        extras={\n            \"num_partitions\": config.num_partitions,\n        },\n    )\n\n\ndefinitions = dg.Definitions(\n    assets=[distributed_computation],\n    resources={\"ray_pipes_client\": PipesKubeRayJobClient()},\n)\n</code></pre> <ol> <li> <code>dagster-pipes</code> has to be installed in the remote environment!</li> </ol> <p>When materializing the asset, <code>PipesKubeRayJobClient</code> will submit the script as a <code>RayJob</code> custom resource, monitor its status, and stream back logs and Dagster metadata.</p>"}]}